{
    "rates": [
        0.43002334637894885,
        233.41316345313874,
        241.21490201607304,
        238.9068148331846,
        239.96703986544793,
        241.03646723787088,
        240.29742266477345,
        237.8979012554919,
        239.5176719791352,
        240.9817234772945,
        224.94103703226992,
        242.52108570250738,
        242.6940305292135,
        243.28029122142536,
        242.4351387689347,
        243.40257619333275,
        244.87084469171165,
        243.95974514839432,
        242.82928933404003,
        243.15816863743777
    ],
    "model_config": {
        "block_size": 1024,
        "vocab_size": 50304,
        "n_layer": 12,
        "n_head": 12,
        "n_embd": 768
    },
    "args": {
        "log_level": "INFO",
        "model": "gpt2",
        "device": "cuda:3",
        "max_length": 100,
        "top_k": 50,
        "seed": 42,
        "prompt": "Einstein's Theory of Relativity states that",
        "torch_compile": true,
        "torch_jit": false,
        "torch_compile_fullgraph": true,
        "torch_compile_reduce_overhead": false,
        "torch_compile_max_autotune": true,
        "generate_slim": true,
        "rounds": 20,
        "wrap": 60,
        "note": "Explicit @torch.compile decorator on GPT.generate_slim"
    },
    "start_timestamp": "2025-02-09T20:02:59.437118",
    "end_timestamp": "2025-02-09T20:07:00.991946",
    "elapsed": "241.555",
    "device_name": "Tesla V100-DGXS-32GB",
    "conda_env_name": "py313",
    "is_gil_enabled": true,
    "note": "Explicit @torch.compile decorator on GPT.generate_slim"
}