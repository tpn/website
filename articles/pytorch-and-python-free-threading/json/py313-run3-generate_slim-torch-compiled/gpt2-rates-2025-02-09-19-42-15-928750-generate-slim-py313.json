{
    "rates": [
        0.42784195614335035,
        242.57544191387723,
        246.6387448961628,
        233.94757319210208,
        252.6386534655579,
        254.77290212311866,
        252.6565344014805,
        254.04099325817418,
        255.83882331143886,
        253.91320426179337,
        254.1448870926913,
        253.13765516678433,
        254.6806262187339,
        252.6652316054656,
        255.1414224520685,
        254.7517402877824,
        252.0643102375799,
        254.7570614323148,
        254.98206457936408,
        255.27833400224938
    ],
    "model_config": {
        "block_size": 1024,
        "vocab_size": 50304,
        "n_layer": 12,
        "n_head": 12,
        "n_embd": 768
    },
    "args": {
        "log_level": "INFO",
        "model": "gpt2",
        "device": "cuda:3",
        "max_length": 100,
        "top_k": 50,
        "seed": 42,
        "prompt": "Einstein's Theory of Relativity states that",
        "torch_compile": false,
        "torch_jit": false,
        "torch_compile_fullgraph": false,
        "torch_compile_reduce_overhead": false,
        "torch_compile_max_autotune": false,
        "generate_slim": true,
        "rounds": 20,
        "wrap": 60,
        "note": "Explicit @torch.compile decorator on GPT.generate_slim"
    },
    "start_timestamp": "2025-02-09T19:38:13.516783",
    "end_timestamp": "2025-02-09T19:42:15.928809",
    "elapsed": "242.412",
    "device_name": "Tesla V100-DGXS-32GB",
    "conda_env_name": "py313",
    "is_gil_enabled": true,
    "note": "Explicit @torch.compile decorator on GPT.generate_slim"
}