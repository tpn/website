<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Trent Nelson">
<meta name="description" content="This post examines multi-threaded parallel inference on PyTorch models using the new No-GIL, free-threaded version of Python. Using a simple 124M parameter GPT2 model that we train from scratch, we explore the novel new territory unlocked by free-threaded Python: parallel PyTorch model inference, where multiple threads, unimpeded by the Python GIL, attempt to generate text from a transformer-based model in parallel.">

<title>DRAFT: PyTorch and Python Free-Threading – Trent Nelson</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-fad9f07c6447c7e618f17e3bec6a2d81.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-fad9f07c6447c7e618f17e3bec6a2d81.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-e1dca550fcec1e1c7934dca98c281342.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-30d7f8590d48599e5b2d2a1d86e332d2.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": true,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-8RPR4XKPEW"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-8RPR4XKPEW', { 'anonymize_ip': false});
</script>
<meta name="quarto:status" content="draft">


<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="DRAFT: PyTorch and Python Free-Threading – Trent Nelson">
<meta property="og:description" content="This post examines multi-threaded parallel inference on PyTorch models using the new No-GIL, free-threaded version of Python. Using a simple 124M parameter GPT2 model that we train from scratch, we explore the novel new territory unlocked by free-threaded Python: parallel PyTorch model inference, where multiple threads, unimpeded by the Python GIL, attempt to generate text from a transformer-based model in parallel.">
<meta property="og:image" content="https://trent.me/blog/posts/2025-xx-xx-pytorch-and-python-free-threading/images/pytorch-and-python-free-threading.png">
<meta property="og:site_name" content="Trent Nelson">
<meta property="og:image:height" content="1024">
<meta property="og:image:width" content="1024">
<meta name="twitter:title" content="DRAFT: PyTorch and Python Free-Threading – Trent Nelson">
<meta name="twitter:description" content="This post examines multi-threaded parallel inference on PyTorch models using the new No-GIL, free-threaded version of Python. Using a simple 124M parameter GPT2 model that we train from scratch, we explore the novel new territory unlocked by free-threaded Python: parallel PyTorch model inference, where multiple threads, unimpeded by the Python GIL, attempt to generate text from a transformer-based model in parallel.">
<meta name="twitter:image" content="https://trent.me/blog/posts/2025-xx-xx-pytorch-and-python-free-threading/images/pytorch-and-python-free-threading.png">
<meta name="twitter:image-height" content="1024">
<meta name="twitter:image-width" content="1024">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Trent Nelson</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../articles/index.html"> 
<span class="menu-text">Articles</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../projects/index.html"> 
<span class="menu-text">Projects &amp; Repos</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../tools/index.html"> 
<span class="menu-text">Tools</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://twitter.com/trentnelson" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
    <a href="https://github.com/tpn" title="GitHub" class="quarto-navigation-tool px-1" aria-label="GitHub"><i class="bi bi-github"></i></a>
    <a href="https://www.linkedin.com/in/trent-p-nelson" title="LinkedIn" class="quarto-navigation-tool px-1" aria-label="LinkedIn"><i class="bi bi-linkedin"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#getting-started" id="toc-getting-started" class="nav-link" data-scroll-target="#getting-started">Getting Started</a>
  <ul>
  <li><a href="#environments" id="toc-environments" class="nav-link" data-scroll-target="#environments">Environments</a>
  <ul>
  <li><a href="#free-threaded-3.13-env-py313t" id="toc-free-threaded-3.13-env-py313t" class="nav-link" data-scroll-target="#free-threaded-3.13-env-py313t">Free-Threaded 3.13 Env (py313t)</a>
  <ul class="collapse">
  <li><a href="#tiktoken" id="toc-tiktoken" class="nav-link" data-scroll-target="#tiktoken">TikToken</a></li>
  <li><a href="#torch" id="toc-torch" class="nav-link" data-scroll-target="#torch">Torch</a></li>
  <li><a href="#ipython-kernel" id="toc-ipython-kernel" class="nav-link" data-scroll-target="#ipython-kernel">IPython Kernel</a></li>
  <li><a href="#datrie-and-cython" id="toc-datrie-and-cython" class="nav-link" data-scroll-target="#datrie-and-cython">Datrie and Cython</a></li>
  </ul></li>
  <li><a href="#normal-3.13-env-py313" id="toc-normal-3.13-env-py313" class="nav-link" data-scroll-target="#normal-3.13-env-py313">Normal 3.13 Env (py313)</a></li>
  </ul></li>
  <li><a href="#parallelopedia" id="toc-parallelopedia" class="nav-link" data-scroll-target="#parallelopedia">Parallelopedia</a></li>
  </ul></li>
  <li><a href="#pytorch-and-llm-crash-course" id="toc-pytorch-and-llm-crash-course" class="nav-link" data-scroll-target="#pytorch-and-llm-crash-course">PyTorch and LLM Crash Course</a>
  <ul>
  <li><a href="#training-gpt-2-124m-locally" id="toc-training-gpt-2-124m-locally" class="nav-link" data-scroll-target="#training-gpt-2-124m-locally">Training GPT-2 (124M) Locally</a></li>
  </ul></li>
  <li><a href="#pytorch-gpt-2-implementation" id="toc-pytorch-gpt-2-implementation" class="nav-link" data-scroll-target="#pytorch-gpt-2-implementation">PyTorch GPT-2 Implementation</a>
  <ul>
  <li><a href="#first-version" id="toc-first-version" class="nav-link" data-scroll-target="#first-version">First Version</a></li>
  <li><a href="#loading-the-model" id="toc-loading-the-model" class="nav-link" data-scroll-target="#loading-the-model">Loading the Model</a></li>
  <li><a href="#generating-text" id="toc-generating-text" class="nav-link" data-scroll-target="#generating-text">Generating Text</a></li>
  <li><a href="#tweaked-version" id="toc-tweaked-version" class="nav-link" data-scroll-target="#tweaked-version">Tweaked Version</a></li>
  </ul></li>
  <li><a href="#parallel-pytorch-inference" id="toc-parallel-pytorch-inference" class="nav-link" data-scroll-target="#parallel-pytorch-inference">Parallel PyTorch Inference</a>
  <ul>
  <li><a href="#pure-python-multi-threaded-http-server" id="toc-pure-python-multi-threaded-http-server" class="nav-link" data-scroll-target="#pure-python-multi-threaded-http-server">Pure Python Multi-threaded HTTP Server</a></li>
  <li><a href="#gpt2-http-app" id="toc-gpt2-http-app" class="nav-link" data-scroll-target="#gpt2-http-app">GPT2 HTTP App</a>
  <ul>
  <li><a href="#synchronous-up-front-generation" id="toc-synchronous-up-front-generation" class="nav-link" data-scroll-target="#synchronous-up-front-generation">Synchronous Up-Front Generation</a></li>
  <li><a href="#our-goals" id="toc-our-goals" class="nav-link" data-scroll-target="#our-goals">Our Goals</a></li>
  <li><a href="#asynchronous-token-by-token-generation" id="toc-asynchronous-token-by-token-generation" class="nav-link" data-scroll-target="#asynchronous-token-by-token-generation">Asynchronous Token-by-Token Generation</a>
  <ul class="collapse">
  <li><a href="#step-1-have-generate-enqueue-an-async-generate_response." id="toc-step-1-have-generate-enqueue-an-async-generate_response." class="nav-link" data-scroll-target="#step-1-have-generate-enqueue-an-async-generate_response.">Step 1: Have generate() enqueue an async generate_response().</a></li>
  <li><a href="#step-2-implement-an-async-generate_response" id="toc-step-2-implement-an-async-generate_response" class="nav-link" data-scroll-target="#step-2-implement-an-async-generate_response">Step 2: Implement an async generate_response()</a></li>
  <li><a href="#step-3-implement-an-async-gpt.async_generate_for" id="toc-step-3-implement-an-async-gpt.async_generate_for" class="nav-link" data-scroll-target="#step-3-implement-an-async-gpt.async_generate_for">Step 3: Implement an async GPT.async_generate_for()</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#test-drive" id="toc-test-drive" class="nav-link" data-scroll-target="#test-drive">Test Drive!</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/tpn/website/edit/main/blog/posts/2025-xx-xx-pytorch-and-python-free-threading/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/tpn/website/issues/new/choose" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-notebooks"><h2>Notebooks</h2><ul><li><a href="gpt2_v1-preview.html"><i class="bi bi-journal-code"></i>gpt2_v1.ipynb</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">DRAFT: PyTorch and Python Free-Threading</h1>
<p class="subtitle lead"></p><p>Unlocking multi-threaded parallel inference on PyTorch models</p><p></p>
  <div class="quarto-categories">
    <div class="quarto-category">PyTorch</div>
    <div class="quarto-category">Python</div>
    <div class="quarto-category">Free-Threading</div>
    <div class="quarto-category">No-GIL</div>
    <div class="quarto-category">LLM</div>
    <div class="quarto-category">GPT2</div>
  </div>
  </div>

<div>
  <div class="description">
    <p>This post examines multi-threaded parallel inference on PyTorch models using the new <em>No-GIL</em>, free-threaded version of Python. Using a simple 124M parameter GPT2 model that we train from scratch, we explore the novel new territory unlocked by free-threaded Python: parallel PyTorch model inference, where multiple threads, unimpeded by the Python GIL, attempt to generate text from a transformer-based model in parallel.</p>
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Trent Nelson </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>

<nav id="TOC-body" role="doc-toc">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction">Introduction</a></li>
  <li><a href="#getting-started" id="toc-getting-started">Getting Started</a>
  <ul>
  <li><a href="#environments" id="toc-environments">Environments</a>
  <ul>
  <li><a href="#free-threaded-3.13-env-py313t" id="toc-free-threaded-3.13-env-py313t">Free-Threaded 3.13 Env (py313t)</a>
  <ul>
  <li><a href="#tiktoken" id="toc-tiktoken">TikToken</a></li>
  <li><a href="#torch" id="toc-torch">Torch</a></li>
  <li><a href="#ipython-kernel" id="toc-ipython-kernel">IPython Kernel</a></li>
  <li><a href="#datrie-and-cython" id="toc-datrie-and-cython">Datrie and Cython</a></li>
  </ul></li>
  <li><a href="#normal-3.13-env-py313" id="toc-normal-3.13-env-py313">Normal 3.13 Env (py313)</a></li>
  </ul></li>
  <li><a href="#parallelopedia" id="toc-parallelopedia">Parallelopedia</a></li>
  </ul></li>
  <li><a href="#pytorch-and-llm-crash-course" id="toc-pytorch-and-llm-crash-course">PyTorch and LLM Crash Course</a>
  <ul>
  <li><a href="#training-gpt-2-124m-locally" id="toc-training-gpt-2-124m-locally">Training GPT-2 (124M) Locally</a></li>
  </ul></li>
  <li><a href="#pytorch-gpt-2-implementation" id="toc-pytorch-gpt-2-implementation">PyTorch GPT-2 Implementation</a>
  <ul>
  <li><a href="#first-version" id="toc-first-version">First Version</a></li>
  <li><a href="#loading-the-model" id="toc-loading-the-model">Loading the Model</a></li>
  <li><a href="#generating-text" id="toc-generating-text">Generating Text</a></li>
  <li><a href="#tweaked-version" id="toc-tweaked-version">Tweaked Version</a></li>
  </ul></li>
  <li><a href="#parallel-pytorch-inference" id="toc-parallel-pytorch-inference">Parallel PyTorch Inference</a>
  <ul>
  <li><a href="#pure-python-multi-threaded-http-server" id="toc-pure-python-multi-threaded-http-server">Pure Python Multi-threaded HTTP Server</a></li>
  <li><a href="#gpt2-http-app" id="toc-gpt2-http-app">GPT2 HTTP App</a>
  <ul>
  <li><a href="#synchronous-up-front-generation" id="toc-synchronous-up-front-generation">Synchronous Up-Front Generation</a></li>
  <li><a href="#our-goals" id="toc-our-goals">Our Goals</a></li>
  <li><a href="#asynchronous-token-by-token-generation" id="toc-asynchronous-token-by-token-generation">Asynchronous Token-by-Token Generation</a>
  <ul>
  <li><a href="#step-1-have-generate-enqueue-an-async-generate_response." id="toc-step-1-have-generate-enqueue-an-async-generate_response.">Step 1: Have generate() enqueue an async generate_response().</a></li>
  <li><a href="#step-2-implement-an-async-generate_response" id="toc-step-2-implement-an-async-generate_response">Step 2: Implement an async generate_response()</a></li>
  <li><a href="#step-3-implement-an-async-gpt.async_generate_for" id="toc-step-3-implement-an-async-gpt.async_generate_for">Step 3: Implement an async GPT.async_generate_for()</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#test-drive" id="toc-test-drive">Test Drive!</a></li>
  </ul></li>
  </ul>
</nav>
<p>This blog post is sponsored in part by <a href="https://meta.com">Meta</a> in collaboration with <a href="https://quansight.com">Quansight</a> and <a href="https://openteams.com">OpenTeams</a>.</p>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Python 3.13, released in October 2024, is the first version of Python to introduce support for a “no-GIL” <em>free-threaded</em> mode, per <a href="https://peps.python.org/pep-0703/">PEP-703 Making the Global Interpreter Lock Optional in CPython</a>, unlocking the ability for multiple Python threads to run simultaneously.</p>
<p>This allows, for the first time since the language’s inception in December 1989, a single Python process to saturate all CPU cores in parallel with pure Python code (i.e.&nbsp;not farming out to extension modules written in C, C++, or, more recently, Rust).</p>
<p>A handful of the <a href="https://peps.python.org/pep-0703/#motivation">motivations</a> captured in that PEP opine on how the GIL impedes Python AI workflows, particularly as it relates to GPU programming.</p>
<p>This blog post explores what can be done with <a href="https://pytorch.org">PyTorch</a> now with the new free-threaded version of Python, specifically focusing on run-time inference on transformer-based generative models.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>I didn’t focus on how <em>training</em> PyTorch models might look in the new free-threaded Python world for a couple of reasons.</p>
<p>Primarily, training is a lot more complex if you’re involving multiple nodes—as gradients need to be carefully synchronized at critical points, for example—and is well outside the scope of a simple blog post.</p>
<p>Additionally, there’s already a huge body of existing work tackling multi-node training in PyTorch by way of the <a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html">Distributed Data Parallel</a>, <code>multiprocessing</code>-based facilities exposed by <a href="https://pytorch.org/tutorials/intermediate/dist_tuto.html"><code>torch.distributed</code></a>.</p>
<p>Whereas, on the flip side, no one has really explored what parallel inference might look like in a single-threaded Python because the GIL has prevented that from even being an option until now.</p>
</div>
</div>
</section>
<section id="getting-started" class="level1">
<h1>Getting Started</h1>
<p>All of this work was done on Linux (Ubuntu 22.04) with Python 3.13t, PyTorch 2.6, and CUDA 12.6.</p>
<p>Full source code is provided to everything captured in this post. It is worth noting that in a few cases, I am rolling my own solutions for things that have existing solutions in the broader Python ecosystem. For example, in the tail end of the post, I leverage a multi-threaded <code>asyncio</code>-based HTTP server I wrote instead of using existing solutions like <a href="https://fastapi.tiangolo.com/">FastAPI</a>.</p>
<p>The reason for this is that, as free-threaded Python is still in its infancy, a lot of packages do not work with it yet, especially those that rely on Cython, C or C++ code, or Rust.</p>
<p>In fact, Rust dependencies are particularly problematic due to the proliferation of Python projects leveraging <a href="https://github.com/PyO3/pyo3">PyO3</a> (Rust bindings for Python), especially prominent projects such as <a href="https://github.com/openai/tiktoken">TikToken</a> and <a href="https://docs.pydantic.dev/latest/">Pydantic</a>, upon which a lot of the Python AI ecosystem is built. PyO3 only recently grew support for free-threaded Python in their 0.23.3 release, which came out in December, 2025, and many dependent projects are yet to update to it.</p>
<p>Thus, this post and its supporting code should not be considered the state of the art for production deployments—its primary goal is exploratory in nature, and minimizing the number of moving pieces in the stack helps achieve this goal.</p>
<section id="environments" class="level2">
<h2 class="anchored" data-anchor-id="environments">Environments</h2>
<p>It is fiddly getting the environments set up in support of this post. Again, this is due to the infancy of free-threaded Python. So I apologize in advance for how long this environment setup section is.</p>
<p>I reference two <code>conda</code> environments in this post: a Python 3.13 free-threaded one named <code>py313t</code>, and a normal, not-free-threaded Python 3.13 one named <code>py313</code>.</p>
<p>The primary motivation behind the second <code>py313</code> environment is it allows us to install Jupyter Lab, which, at the time of writing, still isn’t compatible with a Python free-threaded installation. However, we can still register a free-threaded Python kernel with Jupyter, which is all we really care about when running the code in this post in a free-threaded environment.</p>
<p>Details on creating the <code>conda</code> environments follow.</p>
<section id="free-threaded-3.13-env-py313t" class="level3">
<h3 class="anchored" data-anchor-id="free-threaded-3.13-env-py313t">Free-Threaded 3.13 Env (py313t)</h3>
<p>I use <code>conda</code> to create the Python 3.13 free-threaded environment plus initial dependencies, activate it, then install the remaining dependencies via pip, as follows:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> create <span class="at">-n</span> py313t python=3.13 python-freethreading <span class="dt">\</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    nodejs pip tqdm flake8 rust requests <span class="dt">\</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">-c</span> conda-forge</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate py313t</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install numpy setuptools_rust regex safetensors</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><code>nodejs</code> is required for the UI component we’ll introduce later. <code>regex</code>, <code>rust</code>, and <code>setuptools_rust</code> are needed for <code>tiktoken</code>, described next. Finally, <code>numpy</code> is for <code>torch</code>, which we install later, too.</p>
<section id="tiktoken" class="level4">
<h4 class="anchored" data-anchor-id="tiktoken">TikToken</h4>
<p><a href="https://github.com/openai/tiktoken">TikToken</a> is a fast BPE tokenizer from OpenAI that is used extensively in the emerging Python LLM landscape. At the time of writing, the latest TikToken release was <a href="https://github.com/openai/tiktoken/releases/tag/0.8.0">0.8.0</a>, which was built against PyO3 0.22.2, which isn’t compatible with free-threaded Python.</p>
<p>Thankfully, it was trivial to get a local installation of <code>tiktoken</code> working by cloning the Github repo, bumping the PyO3 version in <code>Cargo.toml</code>, then rebuilding and installing.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is a perfect example of the type of fiddling around I wanted to avoid by not depending on any external packages other than the bare necessities, such as PyTorch. I made an exception for <code>tiktoken</code> because a) it’s arguably an equally-important part of the LLM stack as <code>torch</code>, and b) it thankfully wasn’t <em>too</em> difficult getting a compatible version of <code>tiktoken</code> installed locally.</p>
</div>
</div>
<p>Clone the tiktoken git repo and cd into it as follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/openai/tiktoken</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> tiktoken</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Edit the <code>Cargo.toml</code> file and change the <code>pyo3</code> dependency version to at least 0.23.3<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode diff code-with-copy"><code class="sourceCode diff"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">diff --git a/Cargo.toml b/Cargo.toml</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>index 2eed0c1..6be5f63 100644</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="dt">--- a/Cargo.toml</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="dt">+++ b/Cargo.toml</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -9,7 +9,7 @@ name = "_tiktoken"</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a> crate-type = ["cdylib"]</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a> [dependencies]</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="st">-pyo3 = { version = "0.22.2", default-features = false, features = ["extension-module", "macros"] }</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="va">+pyo3 = { version = "0.23.3", default-features = false, features = ["extension-module", "macros"] }</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a> # tiktoken dependencies</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a> fancy-regex = "0.13.0"</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>With this patch applied, and the <code>py313t</code> conda environment active (with <code>rust</code> and <code>setuptools_rust</code> installed):</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> setup.py build</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> setup.py install</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Show Build &amp; Install Output">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Show Build &amp; Install Output
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">(</span><span class="ex">py313t</span><span class="kw">)</span> <span class="ex">{pytorch}</span> <span class="pp">[</span><span class="ss">12.6</span><span class="pp">]</span> [trent@dgx/ttypts/3<span class="er">(</span><span class="ex">~s/tiktoken</span><span class="kw">)</span><span class="ex">%]</span> python setup.py build</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> build</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> build_py</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/_educational.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/__init__.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/registry.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/model.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/load.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/core.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken_ext/openai_public.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken_ext</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> egg_info</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="ex">writing</span> tiktoken.egg-info/PKG-INFO</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="ex">writing</span> dependency_links to tiktoken.egg-info/dependency_links.txt</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="ex">writing</span> requirements to tiktoken.egg-info/requires.txt</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="ex">writing</span> top-level names to tiktoken.egg-info/top_level.txt</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="ex">reading</span> manifest file <span class="st">'tiktoken.egg-info/SOURCES.txt'</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="ex">reading</span> manifest template <span class="st">'MANIFEST.in'</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> no files found matching <span class="st">'Makefile'</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="ex">adding</span> license file <span class="st">'LICENSE'</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="ex">writing</span> manifest file <span class="st">'tiktoken.egg-info/SOURCES.txt'</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/py.typed <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> build_ext</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> build_rust</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="ex">cargo</span> rustc <span class="at">--lib</span> <span class="at">--message-format</span><span class="op">=</span>json-render-diagnostics <span class="at">--manifest-path</span> Cargo.toml <span class="at">--release</span> <span class="at">-v</span> <span class="at">--features</span> pyo3/extension-module <span class="at">--crate-type</span> cdylib <span class="at">--</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> target-lexicon v0.12.16</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> once_cell v1.20.2</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> proc-macro2 v1.0.92</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> unicode-ident v1.0.14</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> memchr v2.7.4</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> regex-syntax v0.8.5</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> libc v0.2.169</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> autocfg v1.4.0</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> heck v0.5.0</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> bit-vec v0.6.3</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> unindent v0.2.3</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> indoc v2.0.5</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> cfg-if v1.0.0</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> rustc-hash v1.1.0</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> build_script_build <span class="at">--edition</span><span class="op">=</span>2018 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/target-lexicon-0.12.16/build.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> bin <span class="at">--emit</span><span class="op">=</span>dep-info,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("arch_zkasm", "default", "serde", "serde_support", "std"))'</span> <span class="at">-C</span> metadata=826df8be4fa9ef21 <span class="at">-C</span> extra-filename=-826df8be4fa9ef21 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/build/target-lexicon-826df8be4fa9ef21 <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> once_cell <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/once_cell-1.20.2/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--cfg</span> <span class="st">'feature="alloc"'</span> <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="race"'</span> <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("alloc", "atomic-polyfill", "critical-section", "default", "parking_lot", "portable-atomic", "race", "std", "unstable"))'</span> <span class="at">-C</span> metadata=6870d82906744d65 <span class="at">-C</span> extra-filename=-6870d82906744d65 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> build_script_build <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/proc-macro2-1.0.92/build.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> bin <span class="at">--emit</span><span class="op">=</span>dep-info,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--cfg</span> <span class="st">'feature="proc-macro"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("default", "nightly", "proc-macro", "span-locations"))'</span> <span class="at">-C</span> metadata=4463b02a2f05d75c <span class="at">-C</span> extra-filename=-4463b02a2f05d75c <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/build/proc-macro2-4463b02a2f05d75c <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> unicode_ident <span class="at">--edition</span><span class="op">=</span>2018 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/unicode-ident-1.0.14/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values())'</span> <span class="at">-C</span> metadata=17278dafa5f26de9 <span class="at">-C</span> extra-filename=-17278dafa5f26de9 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> memchr <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/memchr-2.7.4/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--cfg</span> <span class="st">'feature="alloc"'</span> <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("alloc", "compiler_builtins", "core", "default", "libc", "logging", "rustc-dep-of-std", "std", "use_std"))'</span> <span class="at">-C</span> metadata=25fa9792dd9399b0 <span class="at">-C</span> extra-filename=-25fa9792dd9399b0 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> regex_syntax <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/regex-syntax-0.8.5/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-age"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-bool"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-case"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-gencat"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-perl"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-script"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-segment"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("arbitrary", "default", "std", "unicode", "unicode-age", "unicode-bool", "unicode-case", "unicode-gencat", "unicode-perl", "unicode-script", "unicode-segment"))'</span> <span class="at">-C</span> metadata=66f570e05dbe3825 <span class="at">-C</span> extra-filename=-66f570e05dbe3825 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> build_script_build <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/libc-0.2.169/build.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> bin <span class="at">--emit</span><span class="op">=</span>dep-info,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("align", "const-extern-fn", "default", "extra_traits", "rustc-dep-of-std", "rustc-std-workspace-core", "std", "use_std"))'</span> <span class="at">-C</span> metadata=42fd5088387abf7a <span class="at">-C</span> extra-filename=-42fd5088387abf7a <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/build/libc-42fd5088387abf7a <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> autocfg <span class="at">--edition</span><span class="op">=</span>2015 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/autocfg-1.4.0/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values())'</span> <span class="at">-C</span> metadata=b8e4c5d316ce5bfb <span class="at">-C</span> extra-filename=-b8e4c5d316ce5bfb <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> bit_vec <span class="at">--edition</span><span class="op">=</span>2015 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/bit-vec-0.6.3/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("default", "serde", "serde_no_std", "serde_std", "std"))'</span> <span class="at">-C</span> metadata=de2a0d1e2ef2490a <span class="at">-C</span> extra-filename=-de2a0d1e2ef2490a <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> heck <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/heck-0.5.0/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values())'</span> <span class="at">-C</span> metadata=5e22b1dffa7f4255 <span class="at">-C</span> extra-filename=-5e22b1dffa7f4255 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> once_cell <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/once_cell-1.20.2/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--cfg</span> <span class="st">'feature="alloc"'</span> <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="race"'</span> <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("alloc", "atomic-polyfill", "critical-section", "default", "parking_lot", "portable-atomic", "race", "std", "unstable"))'</span> <span class="at">-C</span> metadata=05003007543cfa87 <span class="at">-C</span> extra-filename=-05003007543cfa87 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> unindent <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/unindent-0.2.3/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values())'</span> <span class="at">-C</span> metadata=d53e2a0385a47a80 <span class="at">-C</span> extra-filename=-d53e2a0385a47a80 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> indoc <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/indoc-2.0.5/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> proc-macro <span class="at">--emit</span><span class="op">=</span>dep-info,link <span class="at">-C</span> prefer-dynamic <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values())'</span> <span class="at">-C</span> metadata=b4e94d9ecbd21a39 <span class="at">-C</span> extra-filename=-b4e94d9ecbd21a39 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> proc_macro <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> cfg_if <span class="at">--edition</span><span class="op">=</span>2018 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/cfg-if-1.0.0/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("compiler_builtins", "core", "rustc-dep-of-std"))'</span> <span class="at">-C</span> metadata=e4ded2c19830fbdd <span class="at">-C</span> extra-filename=-e4ded2c19830fbdd <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> rustc_hash <span class="at">--edition</span><span class="op">=</span>2015 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/rustc-hash-1.1.0/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("default", "std"))'</span> <span class="at">-C</span> metadata=b006f4d81e95dfaf <span class="at">-C</span> extra-filename=-b006f4d81e95dfaf <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> bit-set v0.5.3</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> bit_set <span class="at">--edition</span><span class="op">=</span>2015 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/bit-set-0.5.3/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("default", "std"))'</span> <span class="at">-C</span> metadata=40d90f83eb5bab57 <span class="at">-C</span> extra-filename=-40d90f83eb5bab57 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> bit_vec=/home/trent/src/tiktoken/target/release/deps/libbit_vec-de2a0d1e2ef2490a.rmeta <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">/home/trent/src/tiktoken/target/release/build/libc-42fd5088387abf7a/build-script-build</span><span class="kw">`</span></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">/home/trent/src/tiktoken/target/release/build/proc-macro2-4463b02a2f05d75c/build-script-build</span><span class="kw">`</span></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> memoffset v0.9.1</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> build_script_build <span class="at">--edition</span><span class="op">=</span>2015 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/memoffset-0.9.1/build.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> bin <span class="at">--emit</span><span class="op">=</span>dep-info,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("default", "unstable_const", "unstable_offset_of"))'</span> <span class="at">-C</span> metadata=679ebbc3261d6845 <span class="at">-C</span> extra-filename=-679ebbc3261d6845 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/build/memoffset-679ebbc3261d6845 <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> autocfg=/home/trent/src/tiktoken/target/release/deps/libautocfg-b8e4c5d316ce5bfb.rlib <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> libc <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/libc-0.2.169/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("align", "const-extern-fn", "default", "extra_traits", "rustc-dep-of-std", "rustc-std-workspace-core", "std", "use_std"))'</span> <span class="at">-C</span> metadata=6b0fbe5bd5ba9d30 <span class="at">-C</span> extra-filename=-6b0fbe5bd5ba9d30 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow <span class="at">--cfg</span> freebsd11 <span class="at">--cfg</span> libc_const_extern_fn <span class="at">--check-cfg</span> <span class="st">'cfg(emscripten_new_stat_abi)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(espidf_time32)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(freebsd10)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(freebsd11)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(freebsd12)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(freebsd13)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(freebsd14)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(freebsd15)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(libc_const_extern_fn)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(libc_deny_warnings)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(libc_thread_local)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(libc_ctest)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(target_os,values("switch","aix","ohos","hurd","rtems","visionos","nuttx"))'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(target_env,values("illumos","wasi","aix","ohos"))'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(target_arch,values("loongarch64","mips32r6","mips64r6","csky"))'</span><span class="kw">`</span></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> proc_macro2 <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/proc-macro2-1.0.92/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--cfg</span> <span class="st">'feature="proc-macro"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("default", "nightly", "proc-macro", "span-locations"))'</span> <span class="at">-C</span> metadata=4c69c42d9df03375 <span class="at">-C</span> extra-filename=-4c69c42d9df03375 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> unicode_ident=/home/trent/src/tiktoken/target/release/deps/libunicode_ident-17278dafa5f26de9.rmeta <span class="at">--cap-lints</span> allow <span class="at">--cfg</span> wrap_proc_macro <span class="at">--check-cfg</span> <span class="st">'cfg(fuzzing)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(no_is_available)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(no_literal_byte_character)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(no_literal_c_string)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(no_source_text)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(proc_macro_span)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(procmacro2_backtrace)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(procmacro2_nightly_testing)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(procmacro2_semver_exempt)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(randomize_layout)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(span_locations)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(super_unstable)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(wrap_proc_macro)'</span><span class="kw">`</span></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">/home/trent/src/tiktoken/target/release/build/target-lexicon-826df8be4fa9ef21/build-script-build</span><span class="kw">`</span></span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> target_lexicon <span class="at">--edition</span><span class="op">=</span>2018 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/target-lexicon-0.12.16/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("arch_zkasm", "default", "serde", "serde_support", "std"))'</span> <span class="at">-C</span> metadata=a879275207ec599a <span class="at">-C</span> extra-filename=-a879275207ec599a <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow <span class="at">--cfg</span> <span class="st">'feature="rust_1_40"'</span><span class="kw">`</span></span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">/home/trent/src/tiktoken/target/release/build/memoffset-679ebbc3261d6845/build-script-build</span><span class="kw">`</span></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> memoffset <span class="at">--edition</span><span class="op">=</span>2015 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/memoffset-0.9.1/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("default", "unstable_const", "unstable_offset_of"))'</span> <span class="at">-C</span> metadata=65fe1a8a113b3005 <span class="at">-C</span> extra-filename=-65fe1a8a113b3005 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--cap-lints</span> allow <span class="at">--cfg</span> tuple_ty <span class="at">--cfg</span> allow_clippy <span class="at">--cfg</span> maybe_uninit <span class="at">--cfg</span> doctests <span class="at">--cfg</span> raw_ref_macros <span class="at">--cfg</span> stable_const <span class="at">--cfg</span> stable_offset_of<span class="kw">`</span></span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> aho-corasick v1.1.3</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> aho_corasick <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/aho-corasick-1.1.3/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--cfg</span> <span class="st">'feature="perf-literal"'</span> <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("default", "logging", "perf-literal", "std"))'</span> <span class="at">-C</span> metadata=6668c9f838fb89b3 <span class="at">-C</span> extra-filename=-6668c9f838fb89b3 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> memchr=/home/trent/src/tiktoken/target/release/deps/libmemchr-25fa9792dd9399b0.rmeta <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> pyo3-build-config v0.23.3</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> build_script_build <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/pyo3-build-config-0.23.3/build.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> bin <span class="at">--emit</span><span class="op">=</span>dep-info,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="extension-module"'</span> <span class="at">--cfg</span> <span class="st">'feature="resolve-config"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("abi3", "abi3-py310", "abi3-py311", "abi3-py312", "abi3-py37", "abi3-py38", "abi3-py39", "default", "extension-module", "python3-dll-a", "resolve-config"))'</span> <span class="at">-C</span> metadata=d8ab86bb094cf645 <span class="at">-C</span> extra-filename=-d8ab86bb094cf645 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/build/pyo3-build-config-d8ab86bb094cf645 <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> target_lexicon=/home/trent/src/tiktoken/target/release/deps/libtarget_lexicon-a879275207ec599a.rlib <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> quote v1.0.38</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> quote <span class="at">--edition</span><span class="op">=</span>2018 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/quote-1.0.38/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="proc-macro"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("default", "proc-macro"))'</span> <span class="at">-C</span> metadata=169332b6fe3d21d6 <span class="at">-C</span> extra-filename=-169332b6fe3d21d6 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> proc_macro2=/home/trent/src/tiktoken/target/release/deps/libproc_macro2-4c69c42d9df03375.rmeta <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> syn v2.0.95</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> syn <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/syn-2.0.95/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--cfg</span> <span class="st">'feature="clone-impls"'</span> <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="derive"'</span> <span class="at">--cfg</span> <span class="st">'feature="extra-traits"'</span> <span class="at">--cfg</span> <span class="st">'feature="full"'</span> <span class="at">--cfg</span> <span class="st">'feature="parsing"'</span> <span class="at">--cfg</span> <span class="st">'feature="printing"'</span> <span class="at">--cfg</span> <span class="st">'feature="proc-macro"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("clone-impls", "default", "derive", "extra-traits", "fold", "full", "parsing", "printing", "proc-macro", "test", "visit", "visit-mut"))'</span> <span class="at">-C</span> metadata=29d4a0ddbd98f61f <span class="at">-C</span> extra-filename=-29d4a0ddbd98f61f <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> proc_macro2=/home/trent/src/tiktoken/target/release/deps/libproc_macro2-4c69c42d9df03375.rmeta <span class="at">--extern</span> quote=/home/trent/src/tiktoken/target/release/deps/libquote-169332b6fe3d21d6.rmeta <span class="at">--extern</span> unicode_ident=/home/trent/src/tiktoken/target/release/deps/libunicode_ident-17278dafa5f26de9.rmeta <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">/home/trent/src/tiktoken/target/release/build/pyo3-build-config-d8ab86bb094cf645/build-script-build</span><span class="kw">`</span></span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> pyo3_build_config <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/pyo3-build-config-0.23.3/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> embed-bitcode=no <span class="at">-C</span> debug-assertions=off <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="extension-module"'</span> <span class="at">--cfg</span> <span class="st">'feature="resolve-config"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("abi3", "abi3-py310", "abi3-py311", "abi3-py312", "abi3-py37", "abi3-py38", "abi3-py39", "default", "extension-module", "python3-dll-a", "resolve-config"))'</span> <span class="at">-C</span> metadata=b884267014f5753b <span class="at">-C</span> extra-filename=-b884267014f5753b <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> once_cell=/home/trent/src/tiktoken/target/release/deps/libonce_cell-6870d82906744d65.rmeta <span class="at">--extern</span> target_lexicon=/home/trent/src/tiktoken/target/release/deps/libtarget_lexicon-a879275207ec599a.rmeta <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> pyo3-ffi v0.23.3</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> pyo3-macros-backend v0.23.3</span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> pyo3 v0.23.3</span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> build_script_build <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/pyo3-ffi-0.23.3/build.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> bin <span class="at">--emit</span><span class="op">=</span>dep-info,link <span class="at">-C</span> embed-bitcode=no <span class="at">--warn</span><span class="op">=</span>rust_2018_idioms <span class="st">'--warn=clippy::useless_transmute'</span> <span class="st">'--warn=clippy::used_underscore_binding'</span> <span class="at">--warn</span><span class="op">=</span>unused_lifetimes <span class="st">'--warn=clippy::unnecessary_wraps'</span> <span class="st">'--warn=clippy::todo'</span> <span class="at">--warn</span><span class="op">=</span>rust_2021_prelude_collisions <span class="st">'--warn=clippy::manual_ok_or'</span> <span class="st">'--warn=clippy::manual_assert'</span> <span class="st">'--warn=clippy::let_unit_value'</span> <span class="at">--warn</span><span class="op">=</span>invalid_doc_attributes <span class="st">'--warn=clippy::flat_map_option'</span> <span class="st">'--warn=clippy::filter_map_next'</span> <span class="st">'--warn=clippy::explicit_iter_loop'</span> <span class="st">'--warn=clippy::explicit_into_iter_loop'</span> <span class="at">--warn</span><span class="op">=</span>elided_lifetimes_in_paths <span class="st">'--warn=clippy::dbg_macro'</span> <span class="st">'--warn=clippy::checked_conversions'</span> <span class="st">'--warn=rustdoc::broken_intra_doc_links'</span> <span class="st">'--warn=rustdoc::bare_urls'</span> <span class="at">-C</span> debug-assertions=off <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="extension-module"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("abi3", "abi3-py310", "abi3-py311", "abi3-py312", "abi3-py37", "abi3-py38", "abi3-py39", "default", "extension-module", "generate-import-lib"))'</span> <span class="at">-C</span> metadata=5c5f8f108a22b6ae <span class="at">-C</span> extra-filename=-5c5f8f108a22b6ae <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/build/pyo3-ffi-5c5f8f108a22b6ae <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> pyo3_build_config=/home/trent/src/tiktoken/target/release/deps/libpyo3_build_config-b884267014f5753b.rlib <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> build_script_build <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/pyo3-macros-backend-0.23.3/build.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> bin <span class="at">--emit</span><span class="op">=</span>dep-info,link <span class="at">-C</span> embed-bitcode=no <span class="at">--warn</span><span class="op">=</span>rust_2018_idioms <span class="st">'--warn=clippy::useless_transmute'</span> <span class="st">'--warn=clippy::used_underscore_binding'</span> <span class="at">--warn</span><span class="op">=</span>unused_lifetimes <span class="st">'--warn=clippy::unnecessary_wraps'</span> <span class="st">'--warn=clippy::todo'</span> <span class="at">--warn</span><span class="op">=</span>rust_2021_prelude_collisions <span class="st">'--warn=clippy::manual_ok_or'</span> <span class="st">'--warn=clippy::manual_assert'</span> <span class="st">'--warn=clippy::let_unit_value'</span> <span class="at">--warn</span><span class="op">=</span>invalid_doc_attributes <span class="st">'--warn=clippy::flat_map_option'</span> <span class="st">'--warn=clippy::filter_map_next'</span> <span class="st">'--warn=clippy::explicit_iter_loop'</span> <span class="st">'--warn=clippy::explicit_into_iter_loop'</span> <span class="at">--warn</span><span class="op">=</span>elided_lifetimes_in_paths <span class="st">'--warn=clippy::dbg_macro'</span> <span class="st">'--warn=clippy::checked_conversions'</span> <span class="st">'--warn=rustdoc::broken_intra_doc_links'</span> <span class="st">'--warn=rustdoc::bare_urls'</span> <span class="at">-C</span> debug-assertions=off <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("experimental-async"))'</span> <span class="at">-C</span> metadata=bb4a4b3911c85e51 <span class="at">-C</span> extra-filename=-bb4a4b3911c85e51 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/build/pyo3-macros-backend-bb4a4b3911c85e51 <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> pyo3_build_config=/home/trent/src/tiktoken/target/release/deps/libpyo3_build_config-b884267014f5753b.rlib <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> build_script_build <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/pyo3-0.23.3/build.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> bin <span class="at">--emit</span><span class="op">=</span>dep-info,link <span class="at">-C</span> embed-bitcode=no <span class="at">--warn</span><span class="op">=</span>rust_2018_idioms <span class="st">'--warn=clippy::useless_transmute'</span> <span class="st">'--warn=clippy::used_underscore_binding'</span> <span class="at">--warn</span><span class="op">=</span>unused_lifetimes <span class="st">'--warn=clippy::unnecessary_wraps'</span> <span class="st">'--warn=clippy::todo'</span> <span class="at">--warn</span><span class="op">=</span>rust_2021_prelude_collisions <span class="st">'--warn=clippy::manual_ok_or'</span> <span class="st">'--warn=clippy::manual_assert'</span> <span class="st">'--warn=clippy::let_unit_value'</span> <span class="at">--warn</span><span class="op">=</span>invalid_doc_attributes <span class="st">'--warn=clippy::flat_map_option'</span> <span class="st">'--warn=clippy::filter_map_next'</span> <span class="st">'--warn=clippy::explicit_iter_loop'</span> <span class="st">'--warn=clippy::explicit_into_iter_loop'</span> <span class="at">--warn</span><span class="op">=</span>elided_lifetimes_in_paths <span class="st">'--warn=clippy::dbg_macro'</span> <span class="st">'--warn=clippy::checked_conversions'</span> <span class="st">'--warn=rustdoc::broken_intra_doc_links'</span> <span class="st">'--warn=rustdoc::bare_urls'</span> <span class="at">-C</span> debug-assertions=off <span class="at">--cfg</span> <span class="st">'feature="extension-module"'</span> <span class="at">--cfg</span> <span class="st">'feature="indoc"'</span> <span class="at">--cfg</span> <span class="st">'feature="macros"'</span> <span class="at">--cfg</span> <span class="st">'feature="pyo3-macros"'</span> <span class="at">--cfg</span> <span class="st">'feature="unindent"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("abi3", "abi3-py310", "abi3-py311", "abi3-py312", "abi3-py37", "abi3-py38", "abi3-py39", "anyhow", "auto-initialize", "chrono", "chrono-tz", "default", "either", "experimental-async", "experimental-inspect", "extension-module", "eyre", "full", "generate-import-lib", "hashbrown", "indexmap", "indoc", "inventory", "macros", "multiple-pymethods", "nightly", "num-bigint", "num-complex", "num-rational", "py-clone", "pyo3-macros", "rust_decimal", "serde", "smallvec", "unindent"))'</span> <span class="at">-C</span> metadata=65f0dbfaaf67ed5a <span class="at">-C</span> extra-filename=-65f0dbfaaf67ed5a <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/build/pyo3-65f0dbfaaf67ed5a <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> pyo3_build_config=/home/trent/src/tiktoken/target/release/deps/libpyo3_build_config-b884267014f5753b.rlib <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> regex-automata v0.4.9</span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> regex_automata <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/regex-automata-0.4.9/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--cfg</span> <span class="st">'feature="alloc"'</span> <span class="at">--cfg</span> <span class="st">'feature="dfa"'</span> <span class="at">--cfg</span> <span class="st">'feature="dfa-build"'</span> <span class="at">--cfg</span> <span class="st">'feature="dfa-onepass"'</span> <span class="at">--cfg</span> <span class="st">'feature="dfa-search"'</span> <span class="at">--cfg</span> <span class="st">'feature="hybrid"'</span> <span class="at">--cfg</span> <span class="st">'feature="meta"'</span> <span class="at">--cfg</span> <span class="st">'feature="nfa"'</span> <span class="at">--cfg</span> <span class="st">'feature="nfa-backtrack"'</span> <span class="at">--cfg</span> <span class="st">'feature="nfa-pikevm"'</span> <span class="at">--cfg</span> <span class="st">'feature="nfa-thompson"'</span> <span class="at">--cfg</span> <span class="st">'feature="perf"'</span> <span class="at">--cfg</span> <span class="st">'feature="perf-inline"'</span> <span class="at">--cfg</span> <span class="st">'feature="perf-literal"'</span> <span class="at">--cfg</span> <span class="st">'feature="perf-literal-multisubstring"'</span> <span class="at">--cfg</span> <span class="st">'feature="perf-literal-substring"'</span> <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--cfg</span> <span class="st">'feature="syntax"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-age"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-bool"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-case"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-gencat"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-perl"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-script"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-segment"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-word-boundary"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("alloc", "default", "dfa", "dfa-build", "dfa-onepass", "dfa-search", "hybrid", "internal-instrument", "internal-instrument-pikevm", "logging", "meta", "nfa", "nfa-backtrack", "nfa-pikevm", "nfa-thompson", "perf", "perf-inline", "perf-literal", "perf-literal-multisubstring", "perf-literal-substring", "std", "syntax", "unicode", "unicode-age", "unicode-bool", "unicode-case", "unicode-gencat", "unicode-perl", "unicode-script", "unicode-segment", "unicode-word-boundary"))'</span> <span class="at">-C</span> metadata=01135b6ed6d4413e <span class="at">-C</span> extra-filename=-01135b6ed6d4413e <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> aho_corasick=/home/trent/src/tiktoken/target/release/deps/libaho_corasick-6668c9f838fb89b3.rmeta <span class="at">--extern</span> memchr=/home/trent/src/tiktoken/target/release/deps/libmemchr-25fa9792dd9399b0.rmeta <span class="at">--extern</span> regex_syntax=/home/trent/src/tiktoken/target/release/deps/libregex_syntax-66f570e05dbe3825.rmeta <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">/home/trent/src/tiktoken/target/release/build/pyo3-macros-backend-bb4a4b3911c85e51/build-script-build</span><span class="kw">`</span></span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">/home/trent/src/tiktoken/target/release/build/pyo3-ffi-5c5f8f108a22b6ae/build-script-build</span><span class="kw">`</span></span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">/home/trent/src/tiktoken/target/release/build/pyo3-65f0dbfaaf67ed5a/build-script-build</span><span class="kw">`</span></span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> pyo3_ffi <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/pyo3-ffi-0.23.3/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--warn</span><span class="op">=</span>rust_2018_idioms <span class="st">'--warn=clippy::useless_transmute'</span> <span class="st">'--warn=clippy::used_underscore_binding'</span> <span class="at">--warn</span><span class="op">=</span>unused_lifetimes <span class="st">'--warn=clippy::unnecessary_wraps'</span> <span class="st">'--warn=clippy::todo'</span> <span class="at">--warn</span><span class="op">=</span>rust_2021_prelude_collisions <span class="st">'--warn=clippy::manual_ok_or'</span> <span class="st">'--warn=clippy::manual_assert'</span> <span class="st">'--warn=clippy::let_unit_value'</span> <span class="at">--warn</span><span class="op">=</span>invalid_doc_attributes <span class="st">'--warn=clippy::flat_map_option'</span> <span class="st">'--warn=clippy::filter_map_next'</span> <span class="st">'--warn=clippy::explicit_iter_loop'</span> <span class="st">'--warn=clippy::explicit_into_iter_loop'</span> <span class="at">--warn</span><span class="op">=</span>elided_lifetimes_in_paths <span class="st">'--warn=clippy::dbg_macro'</span> <span class="st">'--warn=clippy::checked_conversions'</span> <span class="st">'--warn=rustdoc::broken_intra_doc_links'</span> <span class="st">'--warn=rustdoc::bare_urls'</span> <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="extension-module"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("abi3", "abi3-py310", "abi3-py311", "abi3-py312", "abi3-py37", "abi3-py38", "abi3-py39", "default", "extension-module", "generate-import-lib"))'</span> <span class="at">-C</span> metadata=9ad2a4f2678f35bd <span class="at">-C</span> extra-filename=-9ad2a4f2678f35bd <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> libc=/home/trent/src/tiktoken/target/release/deps/liblibc-6b0fbe5bd5ba9d30.rmeta <span class="at">--cap-lints</span> allow <span class="at">--cfg</span> Py_3_7 <span class="at">--cfg</span> Py_3_8 <span class="at">--cfg</span> Py_3_9 <span class="at">--cfg</span> Py_3_10 <span class="at">--cfg</span> Py_3_11 <span class="at">--cfg</span> Py_3_12 <span class="at">--cfg</span> Py_3_13 <span class="at">--cfg</span> Py_GIL_DISABLED <span class="at">--cfg</span> rustc_has_once_lock <span class="at">--cfg</span> invalid_from_utf8_lint <span class="at">--cfg</span> c_str_lit <span class="at">--cfg</span> diagnostic_namespace <span class="at">--check-cfg</span> <span class="st">'cfg(Py_LIMITED_API)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_GIL_DISABLED)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(PyPy)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(GraalPy)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(py_sys_config, values("Py_DEBUG", "Py_REF_DEBUG", "Py_TRACE_REFS", "COUNT_ALLOCS"))'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(invalid_from_utf8_lint)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(pyo3_disable_reference_pool)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(pyo3_leak_on_drop_without_reference_pool)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(diagnostic_namespace)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(c_str_lit)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(rustc_has_once_lock)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_7)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_8)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_9)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_10)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_11)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_12)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_13)'</span><span class="kw">`</span></span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> pyo3_macros_backend <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/pyo3-macros-backend-0.23.3/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> embed-bitcode=no <span class="at">--warn</span><span class="op">=</span>rust_2018_idioms <span class="st">'--warn=clippy::useless_transmute'</span> <span class="st">'--warn=clippy::used_underscore_binding'</span> <span class="at">--warn</span><span class="op">=</span>unused_lifetimes <span class="st">'--warn=clippy::unnecessary_wraps'</span> <span class="st">'--warn=clippy::todo'</span> <span class="at">--warn</span><span class="op">=</span>rust_2021_prelude_collisions <span class="st">'--warn=clippy::manual_ok_or'</span> <span class="st">'--warn=clippy::manual_assert'</span> <span class="st">'--warn=clippy::let_unit_value'</span> <span class="at">--warn</span><span class="op">=</span>invalid_doc_attributes <span class="st">'--warn=clippy::flat_map_option'</span> <span class="st">'--warn=clippy::filter_map_next'</span> <span class="st">'--warn=clippy::explicit_iter_loop'</span> <span class="st">'--warn=clippy::explicit_into_iter_loop'</span> <span class="at">--warn</span><span class="op">=</span>elided_lifetimes_in_paths <span class="st">'--warn=clippy::dbg_macro'</span> <span class="st">'--warn=clippy::checked_conversions'</span> <span class="st">'--warn=rustdoc::broken_intra_doc_links'</span> <span class="st">'--warn=rustdoc::bare_urls'</span> <span class="at">-C</span> debug-assertions=off <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("experimental-async"))'</span> <span class="at">-C</span> metadata=c7424188824c71f8 <span class="at">-C</span> extra-filename=-c7424188824c71f8 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> heck=/home/trent/src/tiktoken/target/release/deps/libheck-5e22b1dffa7f4255.rmeta <span class="at">--extern</span> proc_macro2=/home/trent/src/tiktoken/target/release/deps/libproc_macro2-4c69c42d9df03375.rmeta <span class="at">--extern</span> pyo3_build_config=/home/trent/src/tiktoken/target/release/deps/libpyo3_build_config-b884267014f5753b.rmeta <span class="at">--extern</span> quote=/home/trent/src/tiktoken/target/release/deps/libquote-169332b6fe3d21d6.rmeta <span class="at">--extern</span> syn=/home/trent/src/tiktoken/target/release/deps/libsyn-29d4a0ddbd98f61f.rmeta <span class="at">--cap-lints</span> allow <span class="at">--cfg</span> rustc_has_once_lock <span class="at">--cfg</span> invalid_from_utf8_lint <span class="at">--cfg</span> c_str_lit <span class="at">--cfg</span> diagnostic_namespace <span class="at">--check-cfg</span> <span class="st">'cfg(Py_LIMITED_API)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_GIL_DISABLED)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(PyPy)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(GraalPy)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(py_sys_config, values("Py_DEBUG", "Py_REF_DEBUG", "Py_TRACE_REFS", "COUNT_ALLOCS"))'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(invalid_from_utf8_lint)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(pyo3_disable_reference_pool)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(pyo3_leak_on_drop_without_reference_pool)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(diagnostic_namespace)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(c_str_lit)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(rustc_has_once_lock)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_7)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_8)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_9)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_10)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_11)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_12)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_13)'</span><span class="kw">`</span></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> fancy-regex v0.13.0</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> regex v1.11.1</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> bstr v1.11.3</span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> regex <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/regex-1.11.1/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="perf"'</span> <span class="at">--cfg</span> <span class="st">'feature="perf-backtrack"'</span> <span class="at">--cfg</span> <span class="st">'feature="perf-cache"'</span> <span class="at">--cfg</span> <span class="st">'feature="perf-dfa"'</span> <span class="at">--cfg</span> <span class="st">'feature="perf-inline"'</span> <span class="at">--cfg</span> <span class="st">'feature="perf-literal"'</span> <span class="at">--cfg</span> <span class="st">'feature="perf-onepass"'</span> <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-age"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-bool"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-case"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-gencat"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-perl"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-script"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode-segment"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("default", "logging", "pattern", "perf", "perf-backtrack", "perf-cache", "perf-dfa", "perf-dfa-full", "perf-inline", "perf-literal", "perf-onepass", "std", "unicode", "unicode-age", "unicode-bool", "unicode-case", "unicode-gencat", "unicode-perl", "unicode-script", "unicode-segment", "unstable", "use_std"))'</span> <span class="at">-C</span> metadata=9ab83d1dbb2872e1 <span class="at">-C</span> extra-filename=-9ab83d1dbb2872e1 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> aho_corasick=/home/trent/src/tiktoken/target/release/deps/libaho_corasick-6668c9f838fb89b3.rmeta <span class="at">--extern</span> memchr=/home/trent/src/tiktoken/target/release/deps/libmemchr-25fa9792dd9399b0.rmeta <span class="at">--extern</span> regex_automata=/home/trent/src/tiktoken/target/release/deps/libregex_automata-01135b6ed6d4413e.rmeta <span class="at">--extern</span> regex_syntax=/home/trent/src/tiktoken/target/release/deps/libregex_syntax-66f570e05dbe3825.rmeta <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> fancy_regex <span class="at">--edition</span><span class="op">=</span>2018 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fancy-regex-0.13.0/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="perf"'</span> <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("default", "perf", "std", "track_caller", "unicode"))'</span> <span class="at">-C</span> metadata=2bd42caf041ad10c <span class="at">-C</span> extra-filename=-2bd42caf041ad10c <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> bit_set=/home/trent/src/tiktoken/target/release/deps/libbit_set-40d90f83eb5bab57.rmeta <span class="at">--extern</span> regex_automata=/home/trent/src/tiktoken/target/release/deps/libregex_automata-01135b6ed6d4413e.rmeta <span class="at">--extern</span> regex_syntax=/home/trent/src/tiktoken/target/release/deps/libregex_syntax-66f570e05dbe3825.rmeta <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> bstr <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/bstr-1.11.3/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--cfg</span> <span class="st">'feature="alloc"'</span> <span class="at">--cfg</span> <span class="st">'feature="default"'</span> <span class="at">--cfg</span> <span class="st">'feature="std"'</span> <span class="at">--cfg</span> <span class="st">'feature="unicode"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("alloc", "default", "serde", "std", "unicode"))'</span> <span class="at">-C</span> metadata=cc96e78f4e9fd97f <span class="at">-C</span> extra-filename=-cc96e78f4e9fd97f <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> memchr=/home/trent/src/tiktoken/target/release/deps/libmemchr-25fa9792dd9399b0.rmeta <span class="at">--extern</span> regex_automata=/home/trent/src/tiktoken/target/release/deps/libregex_automata-01135b6ed6d4413e.rmeta <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> pyo3-macros v0.23.3</span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> pyo3_macros <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/pyo3-macros-0.23.3/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> proc-macro <span class="at">--emit</span><span class="op">=</span>dep-info,link <span class="at">-C</span> prefer-dynamic <span class="at">-C</span> embed-bitcode=no <span class="at">--warn</span><span class="op">=</span>rust_2018_idioms <span class="st">'--warn=clippy::useless_transmute'</span> <span class="st">'--warn=clippy::used_underscore_binding'</span> <span class="at">--warn</span><span class="op">=</span>unused_lifetimes <span class="st">'--warn=clippy::unnecessary_wraps'</span> <span class="st">'--warn=clippy::todo'</span> <span class="at">--warn</span><span class="op">=</span>rust_2021_prelude_collisions <span class="st">'--warn=clippy::manual_ok_or'</span> <span class="st">'--warn=clippy::manual_assert'</span> <span class="st">'--warn=clippy::let_unit_value'</span> <span class="at">--warn</span><span class="op">=</span>invalid_doc_attributes <span class="st">'--warn=clippy::flat_map_option'</span> <span class="st">'--warn=clippy::filter_map_next'</span> <span class="st">'--warn=clippy::explicit_iter_loop'</span> <span class="st">'--warn=clippy::explicit_into_iter_loop'</span> <span class="at">--warn</span><span class="op">=</span>elided_lifetimes_in_paths <span class="st">'--warn=clippy::dbg_macro'</span> <span class="st">'--warn=clippy::checked_conversions'</span> <span class="st">'--warn=rustdoc::broken_intra_doc_links'</span> <span class="st">'--warn=rustdoc::bare_urls'</span> <span class="at">-C</span> debug-assertions=off <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("experimental-async", "multiple-pymethods"))'</span> <span class="at">-C</span> metadata=97a13ca0f34dda72 <span class="at">-C</span> extra-filename=-97a13ca0f34dda72 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> proc_macro2=/home/trent/src/tiktoken/target/release/deps/libproc_macro2-4c69c42d9df03375.rlib <span class="at">--extern</span> pyo3_macros_backend=/home/trent/src/tiktoken/target/release/deps/libpyo3_macros_backend-c7424188824c71f8.rlib <span class="at">--extern</span> quote=/home/trent/src/tiktoken/target/release/deps/libquote-169332b6fe3d21d6.rlib <span class="at">--extern</span> syn=/home/trent/src/tiktoken/target/release/deps/libsyn-29d4a0ddbd98f61f.rlib <span class="at">--extern</span> proc_macro <span class="at">--cap-lints</span> allow<span class="kw">`</span></span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> pyo3 <span class="at">--edition</span><span class="op">=</span>2021 /home/trent/.cargo/registry/src/index.crates.io-6f17d22bba15001f/pyo3-0.23.3/src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> lib <span class="at">--emit</span><span class="op">=</span>dep-info,metadata,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--warn</span><span class="op">=</span>rust_2018_idioms <span class="st">'--warn=clippy::useless_transmute'</span> <span class="st">'--warn=clippy::used_underscore_binding'</span> <span class="at">--warn</span><span class="op">=</span>unused_lifetimes <span class="st">'--warn=clippy::unnecessary_wraps'</span> <span class="st">'--warn=clippy::todo'</span> <span class="at">--warn</span><span class="op">=</span>rust_2021_prelude_collisions <span class="st">'--warn=clippy::manual_ok_or'</span> <span class="st">'--warn=clippy::manual_assert'</span> <span class="st">'--warn=clippy::let_unit_value'</span> <span class="at">--warn</span><span class="op">=</span>invalid_doc_attributes <span class="st">'--warn=clippy::flat_map_option'</span> <span class="st">'--warn=clippy::filter_map_next'</span> <span class="st">'--warn=clippy::explicit_iter_loop'</span> <span class="st">'--warn=clippy::explicit_into_iter_loop'</span> <span class="at">--warn</span><span class="op">=</span>elided_lifetimes_in_paths <span class="st">'--warn=clippy::dbg_macro'</span> <span class="st">'--warn=clippy::checked_conversions'</span> <span class="st">'--warn=rustdoc::broken_intra_doc_links'</span> <span class="st">'--warn=rustdoc::bare_urls'</span> <span class="at">--cfg</span> <span class="st">'feature="extension-module"'</span> <span class="at">--cfg</span> <span class="st">'feature="indoc"'</span> <span class="at">--cfg</span> <span class="st">'feature="macros"'</span> <span class="at">--cfg</span> <span class="st">'feature="pyo3-macros"'</span> <span class="at">--cfg</span> <span class="st">'feature="unindent"'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values("abi3", "abi3-py310", "abi3-py311", "abi3-py312", "abi3-py37", "abi3-py38", "abi3-py39", "anyhow", "auto-initialize", "chrono", "chrono-tz", "default", "either", "experimental-async", "experimental-inspect", "extension-module", "eyre", "full", "generate-import-lib", "hashbrown", "indexmap", "indoc", "inventory", "macros", "multiple-pymethods", "nightly", "num-bigint", "num-complex", "num-rational", "py-clone", "pyo3-macros", "rust_decimal", "serde", "smallvec", "unindent"))'</span> <span class="at">-C</span> metadata=99d0b007138eadf4 <span class="at">-C</span> extra-filename=-99d0b007138eadf4 <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> cfg_if=/home/trent/src/tiktoken/target/release/deps/libcfg_if-e4ded2c19830fbdd.rmeta <span class="at">--extern</span> indoc=/home/trent/src/tiktoken/target/release/deps/libindoc-b4e94d9ecbd21a39.so <span class="at">--extern</span> libc=/home/trent/src/tiktoken/target/release/deps/liblibc-6b0fbe5bd5ba9d30.rmeta <span class="at">--extern</span> memoffset=/home/trent/src/tiktoken/target/release/deps/libmemoffset-65fe1a8a113b3005.rmeta <span class="at">--extern</span> once_cell=/home/trent/src/tiktoken/target/release/deps/libonce_cell-05003007543cfa87.rmeta <span class="at">--extern</span> pyo3_ffi=/home/trent/src/tiktoken/target/release/deps/libpyo3_ffi-9ad2a4f2678f35bd.rmeta <span class="at">--extern</span> pyo3_macros=/home/trent/src/tiktoken/target/release/deps/libpyo3_macros-97a13ca0f34dda72.so <span class="at">--extern</span> unindent=/home/trent/src/tiktoken/target/release/deps/libunindent-d53e2a0385a47a80.rmeta <span class="at">--cap-lints</span> allow <span class="at">--cfg</span> Py_3_7 <span class="at">--cfg</span> Py_3_8 <span class="at">--cfg</span> Py_3_9 <span class="at">--cfg</span> Py_3_10 <span class="at">--cfg</span> Py_3_11 <span class="at">--cfg</span> Py_3_12 <span class="at">--cfg</span> Py_3_13 <span class="at">--cfg</span> Py_GIL_DISABLED <span class="at">--cfg</span> rustc_has_once_lock <span class="at">--cfg</span> invalid_from_utf8_lint <span class="at">--cfg</span> c_str_lit <span class="at">--cfg</span> diagnostic_namespace <span class="at">--check-cfg</span> <span class="st">'cfg(Py_LIMITED_API)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_GIL_DISABLED)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(PyPy)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(GraalPy)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(py_sys_config, values("Py_DEBUG", "Py_REF_DEBUG", "Py_TRACE_REFS", "COUNT_ALLOCS"))'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(invalid_from_utf8_lint)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(pyo3_disable_reference_pool)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(pyo3_leak_on_drop_without_reference_pool)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(diagnostic_namespace)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(c_str_lit)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(rustc_has_once_lock)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_7)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_8)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_9)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_10)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_11)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_12)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(Py_3_13)'</span><span class="kw">`</span></span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Dirty</span> tiktoken v0.8.0 <span class="er">(</span><span class="ex">/home/trent/src/tiktoken</span><span class="kw">)</span><span class="bu">:</span> the toolchain changed</span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a>   <span class="ex">Compiling</span> tiktoken v0.8.0 <span class="er">(</span><span class="ex">/home/trent/src/tiktoken</span><span class="kw">)</span></span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a>     <span class="ex">Running</span> <span class="kw">`</span><span class="ex">rustc</span> <span class="at">--crate-name</span> _tiktoken <span class="at">--edition</span><span class="op">=</span>2021 src/lib.rs <span class="at">--error-format</span><span class="op">=</span>json <span class="at">--json</span><span class="op">=</span>diagnostic-rendered-ansi,artifacts,future-incompat <span class="at">--diagnostic-width</span><span class="op">=</span>254 <span class="at">--crate-type</span> cdylib <span class="at">--emit</span><span class="op">=</span>dep-info,link <span class="at">-C</span> opt-level=3 <span class="at">-C</span> embed-bitcode=no <span class="at">--check-cfg</span> <span class="st">'cfg(docsrs)'</span> <span class="at">--check-cfg</span> <span class="st">'cfg(feature, values())'</span> <span class="at">-C</span> metadata=2d15c1d1b98ec97b <span class="at">--out-dir</span> /home/trent/src/tiktoken/target/release/deps <span class="at">-C</span> linker=/home/trent/mambaforge/envs/py313t/bin/x86_64-conda-linux-gnu-cc <span class="at">-C</span> strip=debuginfo <span class="at">-L</span> dependency=/home/trent/src/tiktoken/target/release/deps <span class="at">--extern</span> bstr=/home/trent/src/tiktoken/target/release/deps/libbstr-cc96e78f4e9fd97f.rlib <span class="at">--extern</span> fancy_regex=/home/trent/src/tiktoken/target/release/deps/libfancy_regex-2bd42caf041ad10c.rlib <span class="at">--extern</span> pyo3=/home/trent/src/tiktoken/target/release/deps/libpyo3-99d0b007138eadf4.rlib <span class="at">--extern</span> regex=/home/trent/src/tiktoken/target/release/deps/libregex-9ab83d1dbb2872e1.rlib <span class="at">--extern</span> rustc_hash=/home/trent/src/tiktoken/target/release/deps/librustc_hash-b006f4d81e95dfaf.rlib<span class="kw">`</span></span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated method <span class="kw">`</span><span class="ex">pyo3::IntoPy::into_py</span><span class="kw">`</span>: <span class="kw">`</span><span class="ex">IntoPy</span><span class="kw">`</span> is going to be replaced by <span class="kw">`</span><span class="ex">IntoPyObject</span><span class="kw">`</span>. See the migration guide <span class="er">(</span><span class="ex">https://pyo3.rs/v0.23.0/migration</span><span class="kw">)</span> <span class="cf">for</span> more <span class="ex">information.</span></span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:508:16</span>
<span id="cb5-103"><a href="#cb5-103" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-104"><a href="#cb5-104" aria-hidden="true" tabindex="-1"></a><span class="ex">508</span> <span class="kw">|</span>         <span class="ex">buffer.into_py</span><span class="er">(</span><span class="ex">py</span><span class="kw">)</span></span>
<span id="cb5-105"><a href="#cb5-105" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                <span class="ex">^^^^^^^</span></span>
<span id="cb5-106"><a href="#cb5-106" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-107"><a href="#cb5-107" aria-hidden="true" tabindex="-1"></a>    <span class="ex">=</span> note: <span class="kw">`</span><span class="co">#[warn(deprecated)]</span><span class="kw">`</span> on by default</span>
<span id="cb5-108"><a href="#cb5-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-109"><a href="#cb5-109" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated associated function <span class="kw">`</span><span class="ex">pyo3::types::PyList::new_bound</span><span class="kw">`</span>: renamed to <span class="kw">`</span><span class="ex">PyList::new</span><span class="kw">`</span></span>
<span id="cb5-110"><a href="#cb5-110" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:555:38</span>
<span id="cb5-111"><a href="#cb5-111" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-112"><a href="#cb5-112" aria-hidden="true" tabindex="-1"></a><span class="ex">555</span> <span class="kw">|</span>         <span class="bu">let</span> <span class="va">py_completions</span> <span class="op">=</span> <span class="va">PyList</span><span class="op">::</span><span class="va">new_bound</span><span class="er">(</span></span>
<span id="cb5-113"><a href="#cb5-113" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                                      <span class="ex">^^^^^^^^^</span></span>
<span id="cb5-114"><a href="#cb5-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-115"><a href="#cb5-115" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated associated function <span class="kw">`</span><span class="ex">pyo3::types::PyList::new_bound</span><span class="kw">`</span>: renamed to <span class="kw">`</span><span class="ex">PyList::new</span><span class="kw">`</span></span>
<span id="cb5-116"><a href="#cb5-116" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:559:36</span>
<span id="cb5-117"><a href="#cb5-117" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-118"><a href="#cb5-118" aria-hidden="true" tabindex="-1"></a><span class="ex">559</span> <span class="kw">|</span>                 <span class="ex">.map</span><span class="er">(</span><span class="kw">|</span><span class="fu">seq</span><span class="kw">|</span> <span class="ex">PyList::new_bound</span><span class="er">(</span><span class="ex">py,</span> <span class="kw">&amp;</span><span class="va">seq</span><span class="op">[</span>..<span class="op">]</span><span class="kw">))</span><span class="ex">,</span></span>
<span id="cb5-119"><a href="#cb5-119" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                                    <span class="ex">^^^^^^^^^</span></span>
<span id="cb5-120"><a href="#cb5-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-121"><a href="#cb5-121" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated method <span class="kw">`</span><span class="ex">pyo3::IntoPy::into_py</span><span class="kw">`</span>: <span class="kw">`</span><span class="ex">IntoPy</span><span class="kw">`</span> is going to be replaced by <span class="kw">`</span><span class="ex">IntoPyObject</span><span class="kw">`</span>. See the migration guide <span class="er">(</span><span class="ex">https://pyo3.rs/v0.23.0/migration</span><span class="kw">)</span> <span class="cf">for</span> more <span class="ex">information.</span></span>
<span id="cb5-122"><a href="#cb5-122" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:561:34</span>
<span id="cb5-123"><a href="#cb5-123" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-124"><a href="#cb5-124" aria-hidden="true" tabindex="-1"></a><span class="ex">561</span> <span class="kw">|</span>         <span class="kw">(</span><span class="ex">tokens,</span> py_completions<span class="kw">)</span><span class="ex">.into_py</span><span class="er">(</span><span class="ex">py</span><span class="kw">)</span></span>
<span id="cb5-125"><a href="#cb5-125" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                                  <span class="ex">^^^^^^^</span></span>
<span id="cb5-126"><a href="#cb5-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-127"><a href="#cb5-127" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated associated function <span class="kw">`</span><span class="ex">pyo3::types::PyBytes::new_bound</span><span class="kw">`</span>: renamed to <span class="kw">`</span><span class="ex">PyBytes::new</span><span class="kw">`</span></span>
<span id="cb5-128"><a href="#cb5-128" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:589:38</span>
<span id="cb5-129"><a href="#cb5-129" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-130"><a href="#cb5-130" aria-hidden="true" tabindex="-1"></a><span class="ex">589</span> <span class="kw">|</span>             <span class="ex">Ok</span><span class="er">(</span><span class="ex">bytes</span><span class="kw">)</span> <span class="ex">=</span><span class="op">&gt;</span> Ok<span class="er">(</span><span class="ex">PyBytes::new_bound</span><span class="er">(</span><span class="ex">py,</span> <span class="kw">&amp;</span><span class="ex">bytes</span><span class="kw">)</span><span class="fu">.into()</span><span class="kw">)</span><span class="ex">,</span></span>
<span id="cb5-131"><a href="#cb5-131" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                                      <span class="ex">^^^^^^^^^</span></span>
<span id="cb5-132"><a href="#cb5-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-133"><a href="#cb5-133" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated associated function <span class="kw">`</span><span class="ex">pyo3::types::PyBytes::new_bound</span><span class="kw">`</span>: renamed to <span class="kw">`</span><span class="ex">PyBytes::new</span><span class="kw">`</span></span>
<span id="cb5-134"><a href="#cb5-134" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:596:32</span>
<span id="cb5-135"><a href="#cb5-135" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-136"><a href="#cb5-136" aria-hidden="true" tabindex="-1"></a><span class="ex">596</span> <span class="kw">|</span>             <span class="cf">return</span> <span class="ex">Ok</span><span class="er">(</span><span class="ex">PyBytes::new_bound</span><span class="er">(</span><span class="ex">py,</span> bytes<span class="kw">)</span><span class="fu">.into()</span><span class="kw">);</span></span>
<span id="cb5-137"><a href="#cb5-137" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                                <span class="ex">^^^^^^^^^</span></span>
<span id="cb5-138"><a href="#cb5-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-139"><a href="#cb5-139" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated associated function <span class="kw">`</span><span class="ex">pyo3::types::PyBytes::new_bound</span><span class="kw">`</span>: renamed to <span class="kw">`</span><span class="ex">PyBytes::new</span><span class="kw">`</span></span>
<span id="cb5-140"><a href="#cb5-140" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:599:32</span>
<span id="cb5-141"><a href="#cb5-141" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-142"><a href="#cb5-142" aria-hidden="true" tabindex="-1"></a><span class="ex">599</span> <span class="kw">|</span>             <span class="cf">return</span> <span class="ex">Ok</span><span class="er">(</span><span class="ex">PyBytes::new_bound</span><span class="er">(</span><span class="ex">py,</span> bytes<span class="kw">)</span><span class="fu">.into()</span><span class="kw">);</span></span>
<span id="cb5-143"><a href="#cb5-143" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                                <span class="ex">^^^^^^^^^</span></span>
<span id="cb5-144"><a href="#cb5-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-145"><a href="#cb5-145" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated associated function <span class="kw">`</span><span class="ex">pyo3::types::PyBytes::new_bound</span><span class="kw">`</span>: renamed to <span class="kw">`</span><span class="ex">PyBytes::new</span><span class="kw">`</span></span>
<span id="cb5-146"><a href="#cb5-146" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:611:31</span>
<span id="cb5-147"><a href="#cb5-147" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-148"><a href="#cb5-148" aria-hidden="true" tabindex="-1"></a><span class="ex">611</span> <span class="kw">|</span>             <span class="ex">.map</span><span class="er">(</span><span class="kw">|</span><span class="ex">x</span><span class="kw">|</span> <span class="ex">PyBytes::new_bound</span><span class="er">(</span><span class="ex">py,</span> x<span class="kw">)</span><span class="fu">.into()</span><span class="kw">)</span></span>
<span id="cb5-149"><a href="#cb5-149" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                               <span class="ex">^^^^^^^^^</span></span>
<span id="cb5-150"><a href="#cb5-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-151"><a href="#cb5-151" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> <span class="kw">`</span><span class="ex">tiktoken</span><span class="kw">`</span> <span class="er">(</span><span class="ex">lib</span><span class="kw">)</span> <span class="ex">generated</span> 8 warnings</span>
<span id="cb5-152"><a href="#cb5-152" aria-hidden="true" tabindex="-1"></a>    <span class="ex">Finished</span> <span class="kw">`</span><span class="ex">release</span><span class="kw">`</span> profile <span class="pp">[</span><span class="ss">optimized</span><span class="pp">]</span> target<span class="er">(</span><span class="ex">s</span><span class="kw">)</span> <span class="er">in</span> <span class="ex">13.17s</span></span>
<span id="cb5-153"><a href="#cb5-153" aria-hidden="true" tabindex="-1"></a><span class="ex">Copying</span> rust artifact from target/release/lib_tiktoken.so to build/lib.linux-x86_64-cpython-313t/tiktoken/_tiktoken.cpython-313t-x86_64-linux-gnu.so</span>
<span id="cb5-154"><a href="#cb5-154" aria-hidden="true" tabindex="-1"></a><span class="kw">(</span><span class="ex">py313t</span><span class="kw">)</span> <span class="ex">{pytorch}</span> <span class="pp">[</span><span class="ss">12.6</span><span class="pp">]</span> [trent@dgx/ttypts/3<span class="er">(</span><span class="ex">~s/tiktoken</span><span class="kw">)</span><span class="ex">%]</span> python setup.py install</span>
<span id="cb5-155"><a href="#cb5-155" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> install</span>
<span id="cb5-156"><a href="#cb5-156" aria-hidden="true" tabindex="-1"></a><span class="ex">/home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/setuptools/_distutils/cmd.py:79:</span> SetuptoolsDeprecationWarning: setup.py install is deprecated.</span>
<span id="cb5-157"><a href="#cb5-157" aria-hidden="true" tabindex="-1"></a><span class="ex">!!</span></span>
<span id="cb5-158"><a href="#cb5-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-159"><a href="#cb5-159" aria-hidden="true" tabindex="-1"></a>        <span class="ex">********************************************************************************</span></span>
<span id="cb5-160"><a href="#cb5-160" aria-hidden="true" tabindex="-1"></a>        <span class="ex">Please</span> avoid running <span class="kw">``</span>setup.py<span class="kw">``</span> directly.</span>
<span id="cb5-161"><a href="#cb5-161" aria-hidden="true" tabindex="-1"></a>        <span class="ex">Instead,</span> use pypa/build, pypa/installer or other</span>
<span id="cb5-162"><a href="#cb5-162" aria-hidden="true" tabindex="-1"></a>        <span class="ex">standards-based</span> tools.</span>
<span id="cb5-163"><a href="#cb5-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-164"><a href="#cb5-164" aria-hidden="true" tabindex="-1"></a>        <span class="ex">See</span> https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.</span>
<span id="cb5-165"><a href="#cb5-165" aria-hidden="true" tabindex="-1"></a>        <span class="ex">********************************************************************************</span></span>
<span id="cb5-166"><a href="#cb5-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-167"><a href="#cb5-167" aria-hidden="true" tabindex="-1"></a><span class="ex">!!</span></span>
<span id="cb5-168"><a href="#cb5-168" aria-hidden="true" tabindex="-1"></a>  <span class="fu">self.initialize_options()</span></span>
<span id="cb5-169"><a href="#cb5-169" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> build</span>
<span id="cb5-170"><a href="#cb5-170" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> build_py</span>
<span id="cb5-171"><a href="#cb5-171" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/_educational.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-172"><a href="#cb5-172" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/__init__.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-173"><a href="#cb5-173" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/registry.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-174"><a href="#cb5-174" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/model.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-175"><a href="#cb5-175" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/load.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-176"><a href="#cb5-176" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/core.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-177"><a href="#cb5-177" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken_ext/openai_public.py <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken_ext</span>
<span id="cb5-178"><a href="#cb5-178" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> egg_info</span>
<span id="cb5-179"><a href="#cb5-179" aria-hidden="true" tabindex="-1"></a><span class="ex">writing</span> tiktoken.egg-info/PKG-INFO</span>
<span id="cb5-180"><a href="#cb5-180" aria-hidden="true" tabindex="-1"></a><span class="ex">writing</span> dependency_links to tiktoken.egg-info/dependency_links.txt</span>
<span id="cb5-181"><a href="#cb5-181" aria-hidden="true" tabindex="-1"></a><span class="ex">writing</span> requirements to tiktoken.egg-info/requires.txt</span>
<span id="cb5-182"><a href="#cb5-182" aria-hidden="true" tabindex="-1"></a><span class="ex">writing</span> top-level names to tiktoken.egg-info/top_level.txt</span>
<span id="cb5-183"><a href="#cb5-183" aria-hidden="true" tabindex="-1"></a><span class="ex">reading</span> manifest file <span class="st">'tiktoken.egg-info/SOURCES.txt'</span></span>
<span id="cb5-184"><a href="#cb5-184" aria-hidden="true" tabindex="-1"></a><span class="ex">reading</span> manifest template <span class="st">'MANIFEST.in'</span></span>
<span id="cb5-185"><a href="#cb5-185" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> no files found matching <span class="st">'Makefile'</span></span>
<span id="cb5-186"><a href="#cb5-186" aria-hidden="true" tabindex="-1"></a><span class="ex">adding</span> license file <span class="st">'LICENSE'</span></span>
<span id="cb5-187"><a href="#cb5-187" aria-hidden="true" tabindex="-1"></a><span class="ex">writing</span> manifest file <span class="st">'tiktoken.egg-info/SOURCES.txt'</span></span>
<span id="cb5-188"><a href="#cb5-188" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> tiktoken/py.typed <span class="at">-</span><span class="op">&gt;</span> build/lib.linux-x86_64-cpython-313t/tiktoken</span>
<span id="cb5-189"><a href="#cb5-189" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> build_ext</span>
<span id="cb5-190"><a href="#cb5-190" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> build_rust</span>
<span id="cb5-191"><a href="#cb5-191" aria-hidden="true" tabindex="-1"></a><span class="ex">cargo</span> rustc <span class="at">--lib</span> <span class="at">--message-format</span><span class="op">=</span>json-render-diagnostics <span class="at">--manifest-path</span> Cargo.toml <span class="at">--release</span> <span class="at">-v</span> <span class="at">--features</span> pyo3/extension-module <span class="at">--crate-type</span> cdylib <span class="at">--</span></span>
<span id="cb5-192"><a href="#cb5-192" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> target-lexicon v0.12.16</span>
<span id="cb5-193"><a href="#cb5-193" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> unicode-ident v1.0.14</span>
<span id="cb5-194"><a href="#cb5-194" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> memchr v2.7.4</span>
<span id="cb5-195"><a href="#cb5-195" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> regex-syntax v0.8.5</span>
<span id="cb5-196"><a href="#cb5-196" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> autocfg v1.4.0</span>
<span id="cb5-197"><a href="#cb5-197" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> aho-corasick v1.1.3</span>
<span id="cb5-198"><a href="#cb5-198" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> heck v0.5.0</span>
<span id="cb5-199"><a href="#cb5-199" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> bit-vec v0.6.3</span>
<span id="cb5-200"><a href="#cb5-200" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> indoc v2.0.5</span>
<span id="cb5-201"><a href="#cb5-201" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> cfg-if v1.0.0</span>
<span id="cb5-202"><a href="#cb5-202" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> once_cell v1.20.2</span>
<span id="cb5-203"><a href="#cb5-203" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> unindent v0.2.3</span>
<span id="cb5-204"><a href="#cb5-204" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> rustc-hash v1.1.0</span>
<span id="cb5-205"><a href="#cb5-205" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> proc-macro2 v1.0.92</span>
<span id="cb5-206"><a href="#cb5-206" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> regex-automata v0.4.9</span>
<span id="cb5-207"><a href="#cb5-207" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> libc v0.2.169</span>
<span id="cb5-208"><a href="#cb5-208" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> bit-set v0.5.3</span>
<span id="cb5-209"><a href="#cb5-209" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> pyo3-build-config v0.23.3</span>
<span id="cb5-210"><a href="#cb5-210" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> quote v1.0.38</span>
<span id="cb5-211"><a href="#cb5-211" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> memoffset v0.9.1</span>
<span id="cb5-212"><a href="#cb5-212" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> bstr v1.11.3</span>
<span id="cb5-213"><a href="#cb5-213" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> fancy-regex v0.13.0</span>
<span id="cb5-214"><a href="#cb5-214" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> regex v1.11.1</span>
<span id="cb5-215"><a href="#cb5-215" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> syn v2.0.95</span>
<span id="cb5-216"><a href="#cb5-216" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> pyo3-macros-backend v0.23.3</span>
<span id="cb5-217"><a href="#cb5-217" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> pyo3-ffi v0.23.3</span>
<span id="cb5-218"><a href="#cb5-218" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> pyo3-macros v0.23.3</span>
<span id="cb5-219"><a href="#cb5-219" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> pyo3 v0.23.3</span>
<span id="cb5-220"><a href="#cb5-220" aria-hidden="true" tabindex="-1"></a>       <span class="ex">Fresh</span> tiktoken v0.8.0 <span class="er">(</span><span class="ex">/home/trent/src/tiktoken</span><span class="kw">)</span></span>
<span id="cb5-221"><a href="#cb5-221" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated method <span class="kw">`</span><span class="ex">pyo3::IntoPy::into_py</span><span class="kw">`</span>: <span class="kw">`</span><span class="ex">IntoPy</span><span class="kw">`</span> is going to be replaced by <span class="kw">`</span><span class="ex">IntoPyObject</span><span class="kw">`</span>. See the migration guide <span class="er">(</span><span class="ex">https://pyo3.rs/v0.23.0/migration</span><span class="kw">)</span> <span class="cf">for</span> more <span class="ex">information.</span></span>
<span id="cb5-222"><a href="#cb5-222" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:508:16</span>
<span id="cb5-223"><a href="#cb5-223" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-224"><a href="#cb5-224" aria-hidden="true" tabindex="-1"></a><span class="ex">508</span> <span class="kw">|</span>         <span class="ex">buffer.into_py</span><span class="er">(</span><span class="ex">py</span><span class="kw">)</span></span>
<span id="cb5-225"><a href="#cb5-225" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                <span class="ex">^^^^^^^</span></span>
<span id="cb5-226"><a href="#cb5-226" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-227"><a href="#cb5-227" aria-hidden="true" tabindex="-1"></a>    <span class="ex">=</span> note: <span class="kw">`</span><span class="co">#[warn(deprecated)]</span><span class="kw">`</span> on by default</span>
<span id="cb5-228"><a href="#cb5-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-229"><a href="#cb5-229" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated associated function <span class="kw">`</span><span class="ex">pyo3::types::PyList::new_bound</span><span class="kw">`</span>: renamed to <span class="kw">`</span><span class="ex">PyList::new</span><span class="kw">`</span></span>
<span id="cb5-230"><a href="#cb5-230" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:555:38</span>
<span id="cb5-231"><a href="#cb5-231" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-232"><a href="#cb5-232" aria-hidden="true" tabindex="-1"></a><span class="ex">555</span> <span class="kw">|</span>         <span class="bu">let</span> <span class="va">py_completions</span> <span class="op">=</span> <span class="va">PyList</span><span class="op">::</span><span class="va">new_bound</span><span class="er">(</span></span>
<span id="cb5-233"><a href="#cb5-233" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                                      <span class="ex">^^^^^^^^^</span></span>
<span id="cb5-234"><a href="#cb5-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-235"><a href="#cb5-235" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated associated function <span class="kw">`</span><span class="ex">pyo3::types::PyList::new_bound</span><span class="kw">`</span>: renamed to <span class="kw">`</span><span class="ex">PyList::new</span><span class="kw">`</span></span>
<span id="cb5-236"><a href="#cb5-236" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:559:36</span>
<span id="cb5-237"><a href="#cb5-237" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-238"><a href="#cb5-238" aria-hidden="true" tabindex="-1"></a><span class="ex">559</span> <span class="kw">|</span>                 <span class="ex">.map</span><span class="er">(</span><span class="kw">|</span><span class="fu">seq</span><span class="kw">|</span> <span class="ex">PyList::new_bound</span><span class="er">(</span><span class="ex">py,</span> <span class="kw">&amp;</span><span class="va">seq</span><span class="op">[</span>..<span class="op">]</span><span class="kw">))</span><span class="ex">,</span></span>
<span id="cb5-239"><a href="#cb5-239" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                                    <span class="ex">^^^^^^^^^</span></span>
<span id="cb5-240"><a href="#cb5-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-241"><a href="#cb5-241" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated method <span class="kw">`</span><span class="ex">pyo3::IntoPy::into_py</span><span class="kw">`</span>: <span class="kw">`</span><span class="ex">IntoPy</span><span class="kw">`</span> is going to be replaced by <span class="kw">`</span><span class="ex">IntoPyObject</span><span class="kw">`</span>. See the migration guide <span class="er">(</span><span class="ex">https://pyo3.rs/v0.23.0/migration</span><span class="kw">)</span> <span class="cf">for</span> more <span class="ex">information.</span></span>
<span id="cb5-242"><a href="#cb5-242" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:561:34</span>
<span id="cb5-243"><a href="#cb5-243" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-244"><a href="#cb5-244" aria-hidden="true" tabindex="-1"></a><span class="ex">561</span> <span class="kw">|</span>         <span class="kw">(</span><span class="ex">tokens,</span> py_completions<span class="kw">)</span><span class="ex">.into_py</span><span class="er">(</span><span class="ex">py</span><span class="kw">)</span></span>
<span id="cb5-245"><a href="#cb5-245" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                                  <span class="ex">^^^^^^^</span></span>
<span id="cb5-246"><a href="#cb5-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-247"><a href="#cb5-247" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated associated function <span class="kw">`</span><span class="ex">pyo3::types::PyBytes::new_bound</span><span class="kw">`</span>: renamed to <span class="kw">`</span><span class="ex">PyBytes::new</span><span class="kw">`</span></span>
<span id="cb5-248"><a href="#cb5-248" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:589:38</span>
<span id="cb5-249"><a href="#cb5-249" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-250"><a href="#cb5-250" aria-hidden="true" tabindex="-1"></a><span class="ex">589</span> <span class="kw">|</span>             <span class="ex">Ok</span><span class="er">(</span><span class="ex">bytes</span><span class="kw">)</span> <span class="ex">=</span><span class="op">&gt;</span> Ok<span class="er">(</span><span class="ex">PyBytes::new_bound</span><span class="er">(</span><span class="ex">py,</span> <span class="kw">&amp;</span><span class="ex">bytes</span><span class="kw">)</span><span class="fu">.into()</span><span class="kw">)</span><span class="ex">,</span></span>
<span id="cb5-251"><a href="#cb5-251" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                                      <span class="ex">^^^^^^^^^</span></span>
<span id="cb5-252"><a href="#cb5-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-253"><a href="#cb5-253" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated associated function <span class="kw">`</span><span class="ex">pyo3::types::PyBytes::new_bound</span><span class="kw">`</span>: renamed to <span class="kw">`</span><span class="ex">PyBytes::new</span><span class="kw">`</span></span>
<span id="cb5-254"><a href="#cb5-254" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:596:32</span>
<span id="cb5-255"><a href="#cb5-255" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-256"><a href="#cb5-256" aria-hidden="true" tabindex="-1"></a><span class="ex">596</span> <span class="kw">|</span>             <span class="cf">return</span> <span class="ex">Ok</span><span class="er">(</span><span class="ex">PyBytes::new_bound</span><span class="er">(</span><span class="ex">py,</span> bytes<span class="kw">)</span><span class="fu">.into()</span><span class="kw">);</span></span>
<span id="cb5-257"><a href="#cb5-257" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                                <span class="ex">^^^^^^^^^</span></span>
<span id="cb5-258"><a href="#cb5-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-259"><a href="#cb5-259" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated associated function <span class="kw">`</span><span class="ex">pyo3::types::PyBytes::new_bound</span><span class="kw">`</span>: renamed to <span class="kw">`</span><span class="ex">PyBytes::new</span><span class="kw">`</span></span>
<span id="cb5-260"><a href="#cb5-260" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:599:32</span>
<span id="cb5-261"><a href="#cb5-261" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-262"><a href="#cb5-262" aria-hidden="true" tabindex="-1"></a><span class="ex">599</span> <span class="kw">|</span>             <span class="cf">return</span> <span class="ex">Ok</span><span class="er">(</span><span class="ex">PyBytes::new_bound</span><span class="er">(</span><span class="ex">py,</span> bytes<span class="kw">)</span><span class="fu">.into()</span><span class="kw">);</span></span>
<span id="cb5-263"><a href="#cb5-263" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                                <span class="ex">^^^^^^^^^</span></span>
<span id="cb5-264"><a href="#cb5-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-265"><a href="#cb5-265" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> use of deprecated associated function <span class="kw">`</span><span class="ex">pyo3::types::PyBytes::new_bound</span><span class="kw">`</span>: renamed to <span class="kw">`</span><span class="ex">PyBytes::new</span><span class="kw">`</span></span>
<span id="cb5-266"><a href="#cb5-266" aria-hidden="true" tabindex="-1"></a>   <span class="ex">--</span><span class="op">&gt;</span> src/lib.rs:611:31</span>
<span id="cb5-267"><a href="#cb5-267" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span></span>
<span id="cb5-268"><a href="#cb5-268" aria-hidden="true" tabindex="-1"></a><span class="ex">611</span> <span class="kw">|</span>             <span class="ex">.map</span><span class="er">(</span><span class="kw">|</span><span class="ex">x</span><span class="kw">|</span> <span class="ex">PyBytes::new_bound</span><span class="er">(</span><span class="ex">py,</span> x<span class="kw">)</span><span class="fu">.into()</span><span class="kw">)</span></span>
<span id="cb5-269"><a href="#cb5-269" aria-hidden="true" tabindex="-1"></a>    <span class="kw">|</span>                               <span class="ex">^^^^^^^^^</span></span>
<span id="cb5-270"><a href="#cb5-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-271"><a href="#cb5-271" aria-hidden="true" tabindex="-1"></a><span class="ex">warning:</span> <span class="kw">`</span><span class="ex">tiktoken</span><span class="kw">`</span> <span class="er">(</span><span class="ex">lib</span><span class="kw">)</span> <span class="ex">generated</span> 8 warnings</span>
<span id="cb5-272"><a href="#cb5-272" aria-hidden="true" tabindex="-1"></a>    <span class="ex">Finished</span> <span class="kw">`</span><span class="ex">release</span><span class="kw">`</span> profile <span class="pp">[</span><span class="ss">optimized</span><span class="pp">]</span> target<span class="er">(</span><span class="ex">s</span><span class="kw">)</span> <span class="er">in</span> <span class="ex">0.03s</span></span>
<span id="cb5-273"><a href="#cb5-273" aria-hidden="true" tabindex="-1"></a><span class="ex">Copying</span> rust artifact from target/release/lib_tiktoken.so to build/lib.linux-x86_64-cpython-313t/tiktoken/_tiktoken.cpython-313t-x86_64-linux-gnu.so</span>
<span id="cb5-274"><a href="#cb5-274" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> install_lib</span>
<span id="cb5-275"><a href="#cb5-275" aria-hidden="true" tabindex="-1"></a><span class="ex">creating</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken_ext</span>
<span id="cb5-276"><a href="#cb5-276" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> build/lib.linux-x86_64-cpython-313t/tiktoken_ext/openai_public.py <span class="at">-</span><span class="op">&gt;</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken_ext</span>
<span id="cb5-277"><a href="#cb5-277" aria-hidden="true" tabindex="-1"></a><span class="ex">creating</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken</span>
<span id="cb5-278"><a href="#cb5-278" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> build/lib.linux-x86_64-cpython-313t/tiktoken/_educational.py <span class="at">-</span><span class="op">&gt;</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken</span>
<span id="cb5-279"><a href="#cb5-279" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> build/lib.linux-x86_64-cpython-313t/tiktoken/__init__.py <span class="at">-</span><span class="op">&gt;</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken</span>
<span id="cb5-280"><a href="#cb5-280" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> build/lib.linux-x86_64-cpython-313t/tiktoken/py.typed <span class="at">-</span><span class="op">&gt;</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken</span>
<span id="cb5-281"><a href="#cb5-281" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> build/lib.linux-x86_64-cpython-313t/tiktoken/registry.py <span class="at">-</span><span class="op">&gt;</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken</span>
<span id="cb5-282"><a href="#cb5-282" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> build/lib.linux-x86_64-cpython-313t/tiktoken/model.py <span class="at">-</span><span class="op">&gt;</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken</span>
<span id="cb5-283"><a href="#cb5-283" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> build/lib.linux-x86_64-cpython-313t/tiktoken/load.py <span class="at">-</span><span class="op">&gt;</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken</span>
<span id="cb5-284"><a href="#cb5-284" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> build/lib.linux-x86_64-cpython-313t/tiktoken/_tiktoken.cpython-313t-x86_64-linux-gnu.so <span class="at">-</span><span class="op">&gt;</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken</span>
<span id="cb5-285"><a href="#cb5-285" aria-hidden="true" tabindex="-1"></a><span class="ex">copying</span> build/lib.linux-x86_64-cpython-313t/tiktoken/core.py <span class="at">-</span><span class="op">&gt;</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken</span>
<span id="cb5-286"><a href="#cb5-286" aria-hidden="true" tabindex="-1"></a><span class="ex">byte-compiling</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken_ext/openai_public.py to openai_public.cpython-313.pyc</span>
<span id="cb5-287"><a href="#cb5-287" aria-hidden="true" tabindex="-1"></a><span class="ex">byte-compiling</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken/_educational.py to _educational.cpython-313.pyc</span>
<span id="cb5-288"><a href="#cb5-288" aria-hidden="true" tabindex="-1"></a><span class="ex">byte-compiling</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken/__init__.py to __init__.cpython-313.pyc</span>
<span id="cb5-289"><a href="#cb5-289" aria-hidden="true" tabindex="-1"></a><span class="ex">byte-compiling</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken/registry.py to registry.cpython-313.pyc</span>
<span id="cb5-290"><a href="#cb5-290" aria-hidden="true" tabindex="-1"></a><span class="ex">byte-compiling</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken/model.py to model.cpython-313.pyc</span>
<span id="cb5-291"><a href="#cb5-291" aria-hidden="true" tabindex="-1"></a><span class="ex">byte-compiling</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken/load.py to load.cpython-313.pyc</span>
<span id="cb5-292"><a href="#cb5-292" aria-hidden="true" tabindex="-1"></a><span class="ex">byte-compiling</span> /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken/core.py to core.cpython-313.pyc</span>
<span id="cb5-293"><a href="#cb5-293" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> install_egg_info</span>
<span id="cb5-294"><a href="#cb5-294" aria-hidden="true" tabindex="-1"></a><span class="ex">Copying</span> tiktoken.egg-info to /home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/tiktoken-0.8.0-py3.13.egg-info</span>
<span id="cb5-295"><a href="#cb5-295" aria-hidden="true" tabindex="-1"></a><span class="ex">running</span> install_scripts</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<p>After this, you should be able to import the <code>tiktoken</code> module in Python:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> cd ..</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> python <span class="at">-Xgil</span><span class="op">=</span>0</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="ex">Python</span> 3.13.1 experimental free-threading build <span class="kw">|</span> <span class="ex">packaged</span> by conda-forge <span class="kw">|</span> <span class="kw">(</span><span class="ex">main,</span> Jan 13 2025, 09:59:40<span class="kw">)</span> <span class="ex">[GCC</span> 13.3.0] on linux</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="ex">Type</span> <span class="st">"help"</span>, <span class="st">"copyright"</span>, <span class="st">"credits"</span> or <span class="st">"license"</span> for more information.</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> import <span class="ex">tiktoken</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="torch" class="level4">
<h4 class="anchored" data-anchor-id="torch">Torch</h4>
<p>Install PyTorch 2.6 via <code>pip</code> with the conda <code>py313t</code> environment active:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> conda activate py313t</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> pip install torch==2.6 <span class="at">--index-url</span> https://download.pytorch.org/whl/cu126</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If you have trouble installing PyTorch, consult their <a href="https://pytorch.org/get-started/locally/">Getting Started</a> guide.</p>
<p>You can verify torch installed correctly as follows:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> python <span class="at">-Xgil</span><span class="op">=</span>0</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="ex">Python</span> 3.13.1 experimental free-threading build <span class="kw">|</span> <span class="ex">packaged</span> by conda-forge <span class="kw">|</span> <span class="kw">(</span><span class="ex">main,</span> Jan 13 2025, 09:59:40<span class="kw">)</span> <span class="ex">[GCC</span> 13.3.0] on linux</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="ex">Type</span> <span class="st">"help"</span>, <span class="st">"copyright"</span>, <span class="st">"credits"</span> or <span class="st">"license"</span> for more information.</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> import <span class="ex">torch</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> torch.cuda.is_available<span class="kw">()</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="ex">True</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="ipython-kernel" class="level4">
<h4 class="anchored" data-anchor-id="ipython-kernel">IPython Kernel</h4>
<p>Installing IPython Kernel allows us to use our free-threaded Python installation via the Jupyter Lab instance we install in the <code>py313</code> environment.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate py313t</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install ipykernel</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Once <code>ipykernel</code> is installed, run the following:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> python3.13t <span class="at">-m</span> ipykernel <span class="at">--install</span> <span class="at">--name</span> py313t <span class="at">--user</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="ex">Installed</span> kernelspec py313t in /home/trent/.local/share/jupyter/kernels/py313t</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This will install a kernel configuration file, <code>kernel.json</code>, which we need to tweak by adding the <code>-Xgil=0</code> startup flag to the Python interpreter:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> cd ~/.local/jupyter/share/kernels/py313t</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> cp kernel.json kernel.json.orig</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> vi kernel.json</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Edit kernel.json to make it look like the diff below.</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> diff <span class="at">-u</span> kernel.json.orig kernel.json</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode diff code-with-copy"><code class="sourceCode diff"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">--- kernel.json.orig    2025-02-04 15:02:21.814112004 -0800</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="dt">+++ kernel.json 2025-02-04 15:02:36.553806199 -0800</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -1,6 +1,7 @@</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a> {</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  "argv": [</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>   "/home/trent/mambaforge/envs/py313t/bin/python3.13t",</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="va">+  "-Xgil=0",</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>   "-Xfrozen_modules=off",</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>   "-m",</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>   "ipykernel_launcher",</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -12,4 +13,4 @@</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>  "metadata": {</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>   "debugger": true</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>  }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="datrie-and-cython" class="level4">
<h4 class="anchored" data-anchor-id="datrie-and-cython">Datrie and Cython</h4>
<p><a href="https://github.com/pytries/datrie">datrie</a> is a Python library that provides a <em>trie</em> (or <em>digital search tree</em>) data structure by way of the <a href="https://linux.thai.net/~thep/datrie/datrie.html">libdatrie</a> C library. The Python <code>datrie</code> library isn’t strictly necessary to run <code>parallelopedia.gpt2</code>, but other components rely on it, so it’s handy to get installed now, if possible.</p>
<p>It relies upon Cython, and thus, for now, you need to install a free-threaded compatible version of Cython first, as follows:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate py313t</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install git+https://github.com/cython/cython</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Then, clone the <code>datrie</code> repo and install as follows:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate py313t</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/pytries/datrie <span class="at">--recursive</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> datrie</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> setup.py build</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> setup.py install</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If everything goes well, you should see something like this when you launch Python and import <code>datrie</code>:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> python</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="ex">Python</span> 3.13.1 experimental free-threading build <span class="kw">|</span> <span class="ex">packaged</span> by conda-forge <span class="kw">|</span> <span class="kw">(</span><span class="ex">main,</span> Jan 13 2025, 09:59:40<span class="kw">)</span> <span class="ex">[GCC</span> 13.3.0] on linux</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="ex">Type</span> <span class="st">"help"</span>, <span class="st">"copyright"</span>, <span class="st">"credits"</span> or <span class="st">"license"</span> for more information.</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> import <span class="ex">datrie</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="normal-3.13-env-py313" class="level3">
<h3 class="anchored" data-anchor-id="normal-3.13-env-py313">Normal 3.13 Env (py313)</h3>
<p>The second <code>py313</code> environment is almost identical to <code>py313t</code>, except it is not a <code>python-freethreading</code> installation, and, additionally, we install Jupyter Lab. We can install <code>tiktoken</code> directly via <code>pip</code>, so we don’t need the supporting Rust cruft. Likewise for <code>datrie</code>, we don’t need to first install Cython and then build <code>datrie</code> from git.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> create <span class="at">-n</span> py313 python=3.13 <span class="dt">\</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    nodejs pip tqdm flake8 jupyterlab requests <span class="dt">\</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">-c</span> conda-forge</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate py313</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install numpy datrie tiktoken safetensors</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install torch==2.6 <span class="at">--index-url</span> https://download.pytorch.org/whl/cu126</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="parallelopedia" class="level2">
<h2 class="anchored" data-anchor-id="parallelopedia">Parallelopedia</h2>
<p>All of the code in this article is available in the <a href="https://github.com/tpn/parallelopedia">Parallelopedia</a> repository on Github. The code we’ll be focusing on in this post lives in the <a href="https://github.com/tpn/parallelopedia/blob/main/src/parallelopedia/gpt2.py">parallelopedia.gpt2</a> module.</p>
<p>There is also a web user interface component named <a href="https://github.com/tpn/parallelopedia-ui">Parallelopedia-UI</a>, which we will use later in the post.</p>
<p>Clone the repositories as follows:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> git clone https://github.com/tpn/parallelopedia</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> git clone https://github.com/tpn/parallelopedia-ui</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="env-vars callout callout-style-default callout-important callout-titled" title="Important Environment Variables">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important Environment Variables
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The code and command examples in this post will assume you’ve added the <code>src</code> directory to your <code>PYTHONPATH</code>, the <code>bin</code> directory to your <code>PATH</code>, and set the <code>PARALLELOPEDIA_ROOT</code> environment variable to the root of the repository. You can do this as follows:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> parallelopedia</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">PYTHONPATH</span><span class="op">=</span><span class="va">$(</span><span class="bu">pwd</span><span class="va">)</span>/src:<span class="va">$PYTHONPATH</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">PATH</span><span class="op">=</span><span class="va">$(</span><span class="bu">pwd</span><span class="va">)</span>/bin:<span class="va">$PATH</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">PARALLELOPEDIA_ROOT</span><span class="op">=</span><span class="va">$(</span><span class="bu">pwd</span><span class="va">)</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ..</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> parallelopedia-ui</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">PARALLELOPEDIA_UI</span><span class="op">=</span><span class="va">$(</span><span class="bu">pwd</span><span class="va">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>It is recommended that you add these to your shell. For me, using zsh, I use the following:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">PARALLELOPEDIA_ROOT</span><span class="op">=</span><span class="pp">~</span>s1/parallelopedia</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">PARALLELOPEDIA_UI</span><span class="op">=</span><span class="pp">~</span>s1/parallelopedia-ui</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">PYTHONPATH</span><span class="op">=</span><span class="va">$PARALLELOPEDIA_ROOT</span>/src:<span class="va">$PYTHONPATH</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">PATH</span><span class="op">=</span><span class="va">$PARALLELOPEDIA_ROOT</span>/bin:<span class="va">$PATH</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<p>You can perform a quick sanity check that things are working as follows:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> python <span class="at">-Xgil</span><span class="op">=</span>0 <span class="at">-m</span> parallelopedia.http.server <span class="at">--help</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="ex">usage:</span> server.py <span class="pp">[-</span><span class="ss">h</span><span class="pp">]</span> [--ip IP] [--port PORT] <span class="pp">[--</span><span class="ss">debug</span><span class="pp">]</span> [--log-level <span class="dt">{DEBUG</span><span class="op">,</span><span class="dt">INFO</span><span class="op">,</span><span class="dt">WARNING</span><span class="op">,</span><span class="dt">ERROR</span><span class="op">,</span><span class="dt">CRITICAL}</span>] [--threads THREADS] [--protocol-class PROTOCOL_CLASS] [--app-classes APP_CLASSES [APP_CLASSES ...]] [--listen-backlog LISTEN_BACKLOG]</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="ex">Run</span> the HTTP server.</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="ex">options:</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  <span class="ex">-h,</span> <span class="at">--help</span>            show this help message and exit</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  <span class="ex">--ip</span> IP               IP address to bind the server to.</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>  <span class="ex">--port</span> PORT           Port number to bind the server to.</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>  <span class="ex">--debug</span>               Enable debug mode for asyncio.</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>  <span class="ex">--log-level</span> <span class="dt">{DEBUG</span><span class="op">,</span><span class="dt">INFO</span><span class="op">,</span><span class="dt">WARNING</span><span class="op">,</span><span class="dt">ERROR</span><span class="op">,</span><span class="dt">CRITICAL}</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>                        <span class="ex">Set</span> the logging level.</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>  <span class="ex">--threads</span> THREADS     Number of threads to use.</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>  <span class="ex">--protocol-class</span> PROTOCOL_CLASS</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>                        <span class="ex">The</span> protocol class to use for the server.</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>  <span class="ex">--app-classes</span> APP_CLASSES [APP_CLASSES ...]</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>                        <span class="ex">Space-separated</span> list of HTTP application classes.</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>  <span class="ex">--listen-backlog</span> LISTEN_BACKLOG</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>                        <span class="ex">The</span> listen backlog for the server.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="pytorch-and-llm-crash-course" class="level1">
<h1>PyTorch and LLM Crash Course</h1>
<p>My involvement with PyTorch and Large Language Models (LLMs) started around late November last year, 2024. Going in, I knew nothing about PyTorch, nor deep neural networks, nor LLMs—other than having enjoyed using LLMs thoroughly the past couple of years. I had never trained an AI model of any kind. I did have a bit of NumPy and data science exposure up my sleeve, plus general familiarity with Python.</p>
<p>Thanks to <a href="https://karpathy.ai/">Andrej Karpathy</a>’s phenomenal YouTube series on deep neural networks and LLMs titled <a href="https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ">Neural Networks: From Zero to Hero</a>, over the course of about 3 weeks or so I went from zero to… well I wouldn’t necessarily say <em>hero</em>—perhaps zero to <em>not-completley-clueless</em> is more apropos.</p>
<p>Andrej’s content is a fantastic resource to learn everything you need to know to understand how modern LLMs work from the ground-up. It’s not a short series—there are 19 hours, 21 minutes and two seconds of content across ten videos—and you’ll probably spend double that if you <em>really</em> want to properly absorb the content.</p>
<p>None of the work presented in this post would have been possible had I not invested the time in Andrej’s series. If you’re reading this Andrej, thanks, and keep up the brilliant work!</p>
<section id="training-gpt-2-124m-locally" class="level2">
<h2 class="anchored" data-anchor-id="training-gpt-2-124m-locally">Training GPT-2 (124M) Locally</h2>
<p>Equipped with my new knowledge about LLMs, PyTorch, and, thanks to Andrej’s final video in the series titled <a href="https://www.youtube.com/watch?v=l8pRSuU81PU&amp;list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&amp;index=10&amp;t=1286s&amp;pp=iAQB">Let’s reproduce GPT-2 (124M)</a> and the accompanying <a href="https://github.com/karpathy/build-nanogpt">build-nanogpt</a> Github repo, I was able to train a local GPT-2 model via PyTorch, from scratch, using the <a href="https://huggingface.co/rhysjones/gpt2-124M-edu-fineweb-10B">edu_fineweb10B</a> dataset.</p>
<p>I only had to make one change in order to run locally: <a href="https://github.com/tpn/build-nanogpt/commit/0069c4a35d1a362c1fd50f9f5bce00a170e15904">Use 8 for micro batch size instead of 64</a>. With that change in place, I was able to train GPT-2 from scratch as follows:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> conda activate py313</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> git clone gh:tpn/build-nanogpt</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> cd build-nanogpt</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the fineweb dataset.</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> python fineweb.py</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Train!</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> torchrun <span class="at">--standalone</span> <span class="at">--nproc_per_node</span><span class="op">=</span>4 train_gpt2.py</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This was run on an NVIDIA DGX workstation from 2017, which has an Intel Xeon(R) CPU E5-2698 v4 @ 2.20GHz (20 cores, 40 threads), and four Tesla V100-DGXS-32GB GPUs.</p>
<p>Training in parallel across all four GPUs yielded around 36,000 tokens/sec, with an average time of about 14.5 seconds per loop iteration. Training took about 3 days and 5 hours for 19,072 steps. All four GPUs were pegged close to their 300W power limit for those three days.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Amusingly, well after the fact, I decided to see what kind of training performance I’d get on my Windows 11 gaming box (via WSL2 and Ubuntu 22.04), which has an AMD Ryzen 9 7950X3D (16 cores, 32 threads) and NVIDIA RTX 4090. Training via <code>python train_gpt2.py</code> (<code>torchrun</code> wasn’t needed as I wasn’t using multiple GPUs) yielded about 45,000 tokens/sec, which is a nice bump, but what was most impressive was the reduction to the loop iteration duration, which averaged out to about 180ms!</p>
<p>So, I could have completed the same training process in about an hour or so, at a vastly reduced impact on my electricity bill that month :-)</p>
</div>
</div>
<p>Once training completes, a <code>log/model_19072.pt</code> file is produced, which is the checkpoint of the model at that final step, obtained via a call to <code>torch.save()</code>. The model has 124M parameters—which is tiny by modern standards—and is just under 500MB on disk.</p>
<p>You can download that very model I trained via the HuggingFace dataset I set up here: <a href="https://huggingface.co/datasets/trentnelson/parallelopedia-data-gpt2/blob/main/model_19072.pt">model_19072.pt</a>. Once downloaded, place the file in <code>$PARALLELOPEDIA_ROOT/data</code>; alternatively, if you run the Jupyter Notebook below, it’ll automatically download the model from HuggingFace on first run.</p>
</section>
</section>
<section id="pytorch-gpt-2-implementation" class="level1">
<h1>PyTorch GPT-2 Implementation</h1>
<p>Let’s introduce the first version of the Python code we’re going to use. Again, all of this has been made possible thanks to Andrej Karpathy’s work with his <a href="https://www.youtube.com/watch?v=l8pRSuU81PU&amp;list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&amp;index=10&amp;t=1286s&amp;pp=iAQB">YouTube series</a> and <a href="https://github.com/karpathy/build-nanogpt">build-nanogpt</a> repo, so any and all code you see in this post can typically be traced back to something equivalent that appears in <a href="https://github.com/karpathy/build-nanogpt/blob/master/train_gpt2.py">train_gpt2.py</a>. None of this code would have made any sense to me a month or two ago—but I can promise you that if you devote sufficient time to watching and understanding the entire series, you’ll have a comprehensive understanding of all of the pieces present in this post.</p>
<p>You can follow along in a Jupyter Lab notebook if you activate the <code>py313</code> environment and launch <code>jupyter lab</code>. If you correctly registered your <code>py313t</code> kernel per the instructions earlier, you should see an option when creating a new notebook to use the <code>py313t</code> Python kernel, which will be the free-threaded version. On the right of this page you should see all of the notebooks referenced.</p>
<section id="first-version" class="level2">
<h2 class="anchored" data-anchor-id="first-version">First Version</h2>
<p>The code below roughly corresponds to my first version of the code in the commit <a href="https://github.com/tpn/parallelopedia/blob/3ed4fe60a767a12b31fca183fed00fef43c65827/src/parallelopedia/gpt2.py">3ed4fe6: Add gpt2.py</a>, with some formatting and style tweaks to ensure the code is viewable on mobile devices without requiring horizontal scrolling.</p>
<p>There are a number of deficiencies in this code, which we’ll address in subsequent versions. For now, it’s a good starting point to get a feel for how we can use PyTorch to load a GPT-2 model checkpoint, tokenize some input text, and generate some output text.</p>
<div class="quarto-embed-nb-cell">
<div id="gpt2-v1-setup" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># gpt2_v1.ipynb</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> dataclasses</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dataclasses <span class="im">import</span> dataclass</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> os.path <span class="im">import</span> join, exists</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> subprocess</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> textwrap <span class="im">import</span> wrap</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tiktoken</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> functional <span class="im">as</span> F</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper Timer Class</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ElapsedTimer:</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a><span class="co">    Context manager and reusable timer to measure elapsed time.</span></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a><span class="co">    Example:</span></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a><span class="co">        timer = elapsed_timer()</span></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a><span class="co">        with timer:</span></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a><span class="co">            do_something()</span></span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a><span class="co">        print(f'Elapsed: {timer.elapsed:.3f}')</span></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a><span class="co">        # Re-enterable:</span></span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a><span class="co">        with timer:</span></span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a><span class="co">            do_something_else()</span></span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a><span class="co">        print(f'Elapsed: {timer.elapsed:.3f}')</span></span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.start <span class="op">=</span> <span class="va">None</span></span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._elapsed <span class="op">=</span> <span class="va">None</span></span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__enter__</span>(<span class="va">self</span>):</span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.start <span class="op">=</span> time.perf_counter()</span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__exit__</span>(<span class="va">self</span>, exc_type, exc_value, traceback):</span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._elapsed <span class="op">=</span> time.perf_counter() <span class="op">-</span> <span class="va">self</span>.start</span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> elapsed(<span class="va">self</span>):</span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a><span class="co">        Return the elapsed time for the most recent context.</span></span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>._elapsed <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Timer has not been used in a context yet."</span>)</span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>._elapsed</span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-60"><a href="#cb22-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-61"><a href="#cb22-61" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-62"><a href="#cb22-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Globals</span></span>
<span id="cb22-63"><a href="#cb22-63" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-64"><a href="#cb22-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-65"><a href="#cb22-65" aria-hidden="true" tabindex="-1"></a>LOG_LEVEL <span class="op">=</span> <span class="st">'DEBUG'</span></span>
<span id="cb22-66"><a href="#cb22-66" aria-hidden="true" tabindex="-1"></a>PARALLELOPEDIA_ROOT <span class="op">=</span> os.environ[<span class="st">'PARALLELOPEDIA_ROOT'</span>]</span>
<span id="cb22-67"><a href="#cb22-67" aria-hidden="true" tabindex="-1"></a>PARALLELOPEDIA_DATA_DIR <span class="op">=</span> join(PARALLELOPEDIA_ROOT, <span class="st">'data'</span>)</span>
<span id="cb22-68"><a href="#cb22-68" aria-hidden="true" tabindex="-1"></a>MODEL_CHECKPOINT <span class="op">=</span> join(</span>
<span id="cb22-69"><a href="#cb22-69" aria-hidden="true" tabindex="-1"></a>    PARALLELOPEDIA_DATA_DIR,</span>
<span id="cb22-70"><a href="#cb22-70" aria-hidden="true" tabindex="-1"></a>    <span class="st">'model_19072.pt'</span>,</span>
<span id="cb22-71"><a href="#cb22-71" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb22-72"><a href="#cb22-72" aria-hidden="true" tabindex="-1"></a>MODEL_DOWNLOAD_URL <span class="op">=</span> (</span>
<span id="cb22-73"><a href="#cb22-73" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://huggingface.co/datasets/trentnelson/"</span></span>
<span id="cb22-74"><a href="#cb22-74" aria-hidden="true" tabindex="-1"></a>    <span class="st">"parallelopedia-data-gpt2/resolve/main/model_19072.pt"</span></span>
<span id="cb22-75"><a href="#cb22-75" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb22-76"><a href="#cb22-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-77"><a href="#cb22-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the model from huggingface if necessary.</span></span>
<span id="cb22-78"><a href="#cb22-78" aria-hidden="true" tabindex="-1"></a>os.makedirs(PARALLELOPEDIA_DATA_DIR, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-79"><a href="#cb22-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-80"><a href="#cb22-80" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> exists(MODEL_CHECKPOINT):</span>
<span id="cb22-81"><a href="#cb22-81" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Downloading </span><span class="sc">{</span>MODEL_DOWNLOAD_URL<span class="sc">}</span><span class="ss"> via wget '</span></span>
<span id="cb22-82"><a href="#cb22-82" aria-hidden="true" tabindex="-1"></a>          <span class="st">'this might take a while...'</span>)</span>
<span id="cb22-83"><a href="#cb22-83" aria-hidden="true" tabindex="-1"></a>    args <span class="op">=</span> [</span>
<span id="cb22-84"><a href="#cb22-84" aria-hidden="true" tabindex="-1"></a>        <span class="st">"wget"</span>,</span>
<span id="cb22-85"><a href="#cb22-85" aria-hidden="true" tabindex="-1"></a>        <span class="st">"--quiet"</span>,</span>
<span id="cb22-86"><a href="#cb22-86" aria-hidden="true" tabindex="-1"></a>        MODEL_DOWNLOAD_URL,</span>
<span id="cb22-87"><a href="#cb22-87" aria-hidden="true" tabindex="-1"></a>        <span class="st">"-P"</span>,</span>
<span id="cb22-88"><a href="#cb22-88" aria-hidden="true" tabindex="-1"></a>        PARALLELOPEDIA_DATA_DIR,</span>
<span id="cb22-89"><a href="#cb22-89" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb22-90"><a href="#cb22-90" aria-hidden="true" tabindex="-1"></a>    timer <span class="op">=</span> ElapsedTimer()</span>
<span id="cb22-91"><a href="#cb22-91" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> timer:</span>
<span id="cb22-92"><a href="#cb22-92" aria-hidden="true" tabindex="-1"></a>        subprocess.run(args, check<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-93"><a href="#cb22-93" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Downloaded model in </span><span class="sc">{</span>timer<span class="sc">.</span>elapsed<span class="sc">:.3f}</span><span class="ss"> seconds.'</span>)</span>
<span id="cb22-94"><a href="#cb22-94" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-95"><a href="#cb22-95" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> exists(MODEL_CHECKPOINT), <span class="st">"Missing checkpoint."</span></span>
<span id="cb22-96"><a href="#cb22-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-97"><a href="#cb22-97" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-98"><a href="#cb22-98" aria-hidden="true" tabindex="-1"></a><span class="co"># Logging</span></span>
<span id="cb22-99"><a href="#cb22-99" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-100"><a href="#cb22-100" aria-hidden="true" tabindex="-1"></a><span class="co"># N.B. We redirect logs to sys.stdout in order for Quarto to pick</span></span>
<span id="cb22-101"><a href="#cb22-101" aria-hidden="true" tabindex="-1"></a><span class="co">#      them up and include them in rendering the output.</span></span>
<span id="cb22-102"><a href="#cb22-102" aria-hidden="true" tabindex="-1"></a>logging.basicConfig(</span>
<span id="cb22-103"><a href="#cb22-103" aria-hidden="true" tabindex="-1"></a>    level<span class="op">=</span><span class="bu">getattr</span>(logging, LOG_LEVEL),</span>
<span id="cb22-104"><a href="#cb22-104" aria-hidden="true" tabindex="-1"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">'</span><span class="sc">%(asctime)s</span><span class="st"> - </span><span class="sc">%(levelname)s</span><span class="st"> - </span><span class="sc">%(message)s</span><span class="st">'</span>,</span>
<span id="cb22-105"><a href="#cb22-105" aria-hidden="true" tabindex="-1"></a>    stream<span class="op">=</span>sys.stdout</span>
<span id="cb22-106"><a href="#cb22-106" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb22-107"><a href="#cb22-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-108"><a href="#cb22-108" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-109"><a href="#cb22-109" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup</span></span>
<span id="cb22-110"><a href="#cb22-110" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-111"><a href="#cb22-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-112"><a href="#cb22-112" aria-hidden="true" tabindex="-1"></a><span class="co"># Use bfloat16 for matmul precision where possible.</span></span>
<span id="cb22-113"><a href="#cb22-113" aria-hidden="true" tabindex="-1"></a>torch.set_float32_matmul_precision(<span class="st">'high'</span>)</span>
<span id="cb22-114"><a href="#cb22-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-115"><a href="#cb22-115" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-116"><a href="#cb22-116" aria-hidden="true" tabindex="-1"></a><span class="co"># GPT2 PyTorch Model Components</span></span>
<span id="cb22-117"><a href="#cb22-117" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-118"><a href="#cb22-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-119"><a href="#cb22-119" aria-hidden="true" tabindex="-1"></a><span class="co"># Now define the classes making up our GPT2 implementation.</span></span>
<span id="cb22-120"><a href="#cb22-120" aria-hidden="true" tabindex="-1"></a><span class="co"># These map directly to the components introduced by the</span></span>
<span id="cb22-121"><a href="#cb22-121" aria-hidden="true" tabindex="-1"></a><span class="co"># now-seminal 2017 "Attention Is All You Need" paper.</span></span>
<span id="cb22-122"><a href="#cb22-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-123"><a href="#cb22-123" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CausalSelfAttention(nn.Module):</span>
<span id="cb22-124"><a href="#cb22-124" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb22-125"><a href="#cb22-125" aria-hidden="true" tabindex="-1"></a><span class="co">    Causal self-attention for the GPT2 model.</span></span>
<span id="cb22-126"><a href="#cb22-126" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb22-127"><a href="#cb22-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-128"><a href="#cb22-128" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, config):</span>
<span id="cb22-129"><a href="#cb22-129" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb22-130"><a href="#cb22-130" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> config.n_embd <span class="op">%</span> config.n_head <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb22-131"><a href="#cb22-131" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Key, query, value projections for all heads, but in a batch.</span></span>
<span id="cb22-132"><a href="#cb22-132" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c_attn <span class="op">=</span> nn.Linear(config.n_embd, <span class="dv">3</span> <span class="op">*</span> config.n_embd)</span>
<span id="cb22-133"><a href="#cb22-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-134"><a href="#cb22-134" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Output projection.</span></span>
<span id="cb22-135"><a href="#cb22-135" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c_proj <span class="op">=</span> nn.Linear(config.n_embd, config.n_embd)</span>
<span id="cb22-136"><a href="#cb22-136" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c_proj.NANOGPT_SCALE_INIT <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb22-137"><a href="#cb22-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-138"><a href="#cb22-138" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Regularization.</span></span>
<span id="cb22-139"><a href="#cb22-139" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_head <span class="op">=</span> config.n_head</span>
<span id="cb22-140"><a href="#cb22-140" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_embd <span class="op">=</span> config.n_embd</span>
<span id="cb22-141"><a href="#cb22-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-142"><a href="#cb22-142" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb22-143"><a href="#cb22-143" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Batch size, sequence length, embedding dimensionality.</span></span>
<span id="cb22-144"><a href="#cb22-144" aria-hidden="true" tabindex="-1"></a>        B, T, C <span class="op">=</span> (x.size())</span>
<span id="cb22-145"><a href="#cb22-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-146"><a href="#cb22-146" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate query, key, values for all heads in</span></span>
<span id="cb22-147"><a href="#cb22-147" aria-hidden="true" tabindex="-1"></a>        <span class="co"># batch and move head forward to be the batch dim.</span></span>
<span id="cb22-148"><a href="#cb22-148" aria-hidden="true" tabindex="-1"></a>        <span class="co">#</span></span>
<span id="cb22-149"><a href="#cb22-149" aria-hidden="true" tabindex="-1"></a>        <span class="co"># N.B. nh is "number of heads", hs is "head size",</span></span>
<span id="cb22-150"><a href="#cb22-150" aria-hidden="true" tabindex="-1"></a>        <span class="co">#      and C (number of channels) is nh * hs.</span></span>
<span id="cb22-151"><a href="#cb22-151" aria-hidden="true" tabindex="-1"></a>        <span class="co">#      E.g. in GPT-2 (124M), n_head=12, hs=64, so</span></span>
<span id="cb22-152"><a href="#cb22-152" aria-hidden="true" tabindex="-1"></a>        <span class="co">#      nh*hs=C=768 channels in the Transformer.</span></span>
<span id="cb22-153"><a href="#cb22-153" aria-hidden="true" tabindex="-1"></a>        qkv <span class="op">=</span> <span class="va">self</span>.c_attn(x)</span>
<span id="cb22-154"><a href="#cb22-154" aria-hidden="true" tabindex="-1"></a>        q, k, v <span class="op">=</span> qkv.split(<span class="va">self</span>.n_embd, dim<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb22-155"><a href="#cb22-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-156"><a href="#cb22-156" aria-hidden="true" tabindex="-1"></a>        head_dim <span class="op">=</span> C <span class="op">//</span> <span class="va">self</span>.n_head</span>
<span id="cb22-157"><a href="#cb22-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-158"><a href="#cb22-158" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (B, nh, T, hs)</span></span>
<span id="cb22-159"><a href="#cb22-159" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> k.view(B, T, <span class="va">self</span>.n_head, head_dim).transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb22-160"><a href="#cb22-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-161"><a href="#cb22-161" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (B, nh, T, hs)</span></span>
<span id="cb22-162"><a href="#cb22-162" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> q.view(B, T, <span class="va">self</span>.n_head, head_dim).transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb22-163"><a href="#cb22-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-164"><a href="#cb22-164" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (B, nh, T, hs)</span></span>
<span id="cb22-165"><a href="#cb22-165" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> v.view(B, T, <span class="va">self</span>.n_head, head_dim).transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb22-166"><a href="#cb22-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-167"><a href="#cb22-167" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Flash attention.</span></span>
<span id="cb22-168"><a href="#cb22-168" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> F.scaled_dot_product_attention(q, k, v, is_causal<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-169"><a href="#cb22-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-170"><a href="#cb22-170" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Re-assemble all head outputs side by side.</span></span>
<span id="cb22-171"><a href="#cb22-171" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> (y.transpose(<span class="dv">1</span>, <span class="dv">2</span>).contiguous().view(B, T, C))</span>
<span id="cb22-172"><a href="#cb22-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-173"><a href="#cb22-173" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Output projection.</span></span>
<span id="cb22-174"><a href="#cb22-174" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> <span class="va">self</span>.c_proj(y)</span>
<span id="cb22-175"><a href="#cb22-175" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> y</span>
<span id="cb22-176"><a href="#cb22-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-177"><a href="#cb22-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-178"><a href="#cb22-178" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP(nn.Module):</span>
<span id="cb22-179"><a href="#cb22-179" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb22-180"><a href="#cb22-180" aria-hidden="true" tabindex="-1"></a><span class="co">    Multi-layer perceptron for the GPT2 model.</span></span>
<span id="cb22-181"><a href="#cb22-181" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb22-182"><a href="#cb22-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-183"><a href="#cb22-183" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, config):</span>
<span id="cb22-184"><a href="#cb22-184" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb22-185"><a href="#cb22-185" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c_fc <span class="op">=</span> nn.Linear(config.n_embd, <span class="dv">4</span> <span class="op">*</span> config.n_embd)</span>
<span id="cb22-186"><a href="#cb22-186" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gelu <span class="op">=</span> nn.GELU(approximate<span class="op">=</span><span class="st">'tanh'</span>)</span>
<span id="cb22-187"><a href="#cb22-187" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c_proj <span class="op">=</span> nn.Linear(<span class="dv">4</span> <span class="op">*</span> config.n_embd, config.n_embd)</span>
<span id="cb22-188"><a href="#cb22-188" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c_proj.NANOGPT_SCALE_INIT <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb22-189"><a href="#cb22-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-190"><a href="#cb22-190" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb22-191"><a href="#cb22-191" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.c_fc(x)</span>
<span id="cb22-192"><a href="#cb22-192" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.gelu(x)</span>
<span id="cb22-193"><a href="#cb22-193" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.c_proj(x)</span>
<span id="cb22-194"><a href="#cb22-194" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb22-195"><a href="#cb22-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-196"><a href="#cb22-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-197"><a href="#cb22-197" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Block(nn.Module):</span>
<span id="cb22-198"><a href="#cb22-198" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb22-199"><a href="#cb22-199" aria-hidden="true" tabindex="-1"></a><span class="co">    Transformer block for the GPT2 model.</span></span>
<span id="cb22-200"><a href="#cb22-200" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb22-201"><a href="#cb22-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-202"><a href="#cb22-202" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, config):</span>
<span id="cb22-203"><a href="#cb22-203" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb22-204"><a href="#cb22-204" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ln_1 <span class="op">=</span> nn.LayerNorm(config.n_embd)</span>
<span id="cb22-205"><a href="#cb22-205" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attn <span class="op">=</span> CausalSelfAttention(config)</span>
<span id="cb22-206"><a href="#cb22-206" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ln_2 <span class="op">=</span> nn.LayerNorm(config.n_embd)</span>
<span id="cb22-207"><a href="#cb22-207" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlp <span class="op">=</span> MLP(config)</span>
<span id="cb22-208"><a href="#cb22-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-209"><a href="#cb22-209" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb22-210"><a href="#cb22-210" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.attn(<span class="va">self</span>.ln_1(x))</span>
<span id="cb22-211"><a href="#cb22-211" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.mlp(<span class="va">self</span>.ln_2(x))</span>
<span id="cb22-212"><a href="#cb22-212" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb22-213"><a href="#cb22-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-214"><a href="#cb22-214" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-215"><a href="#cb22-215" aria-hidden="true" tabindex="-1"></a><span class="co"># GPT2 Supporting Classes</span></span>
<span id="cb22-216"><a href="#cb22-216" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-217"><a href="#cb22-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-218"><a href="#cb22-218" aria-hidden="true" tabindex="-1"></a><span class="co"># N.B. These differ slightly from Andrej's classes in</span></span>
<span id="cb22-219"><a href="#cb22-219" aria-hidden="true" tabindex="-1"></a><span class="co">#      `train_gpt2.py`.  `GPTCheckpoint` is a helper</span></span>
<span id="cb22-220"><a href="#cb22-220" aria-hidden="true" tabindex="-1"></a><span class="co">#      class I wrote that has no analog in the former.</span></span>
<span id="cb22-221"><a href="#cb22-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-222"><a href="#cb22-222" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb22-223"><a href="#cb22-223" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GPTConfig:</span>
<span id="cb22-224"><a href="#cb22-224" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb22-225"><a href="#cb22-225" aria-hidden="true" tabindex="-1"></a><span class="co">    Configuration class for GPT model.</span></span>
<span id="cb22-226"><a href="#cb22-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-227"><a href="#cb22-227" aria-hidden="true" tabindex="-1"></a><span class="co">    Attributes:</span></span>
<span id="cb22-228"><a href="#cb22-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-229"><a href="#cb22-229" aria-hidden="true" tabindex="-1"></a><span class="co">        block_size (int): Maximum sequence length.</span></span>
<span id="cb22-230"><a href="#cb22-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-231"><a href="#cb22-231" aria-hidden="true" tabindex="-1"></a><span class="co">        vocab_size (int): Number of tokens.  GPT2 from</span></span>
<span id="cb22-232"><a href="#cb22-232" aria-hidden="true" tabindex="-1"></a><span class="co">            huggingface has a vocab size of 50257, which</span></span>
<span id="cb22-233"><a href="#cb22-233" aria-hidden="true" tabindex="-1"></a><span class="co">            includes 50,000 BPE merges, 256 byte tokens,</span></span>
<span id="cb22-234"><a href="#cb22-234" aria-hidden="true" tabindex="-1"></a><span class="co">            and 1 &lt;|endoftext|&gt; token.  However, Andrej</span></span>
<span id="cb22-235"><a href="#cb22-235" aria-hidden="true" tabindex="-1"></a><span class="co">            Karpathy's `build-nanogpt/train_gpt2.py`</span></span>
<span id="cb22-236"><a href="#cb22-236" aria-hidden="true" tabindex="-1"></a><span class="co">            uses a vocab size of 50304.  I vaguely recall</span></span>
<span id="cb22-237"><a href="#cb22-237" aria-hidden="true" tabindex="-1"></a><span class="co">            the explanation for this discrepancy as a local</span></span>
<span id="cb22-238"><a href="#cb22-238" aria-hidden="true" tabindex="-1"></a><span class="co">            optimization to yield better alignment sizes,</span></span>
<span id="cb22-239"><a href="#cb22-239" aria-hidden="true" tabindex="-1"></a><span class="co">            but I'm not 100% certain.</span></span>
<span id="cb22-240"><a href="#cb22-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-241"><a href="#cb22-241" aria-hidden="true" tabindex="-1"></a><span class="co">            The local GPT2 training that we did on</span></span>
<span id="cb22-242"><a href="#cb22-242" aria-hidden="true" tabindex="-1"></a><span class="co">            edu_fineweb10b used 50304, so we will use</span></span>
<span id="cb22-243"><a href="#cb22-243" aria-hidden="true" tabindex="-1"></a><span class="co">            that here.</span></span>
<span id="cb22-244"><a href="#cb22-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-245"><a href="#cb22-245" aria-hidden="true" tabindex="-1"></a><span class="co">        n_layer (int): Number of layers.</span></span>
<span id="cb22-246"><a href="#cb22-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-247"><a href="#cb22-247" aria-hidden="true" tabindex="-1"></a><span class="co">        n_head (int): Number of attention heads.</span></span>
<span id="cb22-248"><a href="#cb22-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-249"><a href="#cb22-249" aria-hidden="true" tabindex="-1"></a><span class="co">        n_embd (int): Embedding dimension.</span></span>
<span id="cb22-250"><a href="#cb22-250" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb22-251"><a href="#cb22-251" aria-hidden="true" tabindex="-1"></a>    block_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1024</span></span>
<span id="cb22-252"><a href="#cb22-252" aria-hidden="true" tabindex="-1"></a>    vocab_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">50304</span></span>
<span id="cb22-253"><a href="#cb22-253" aria-hidden="true" tabindex="-1"></a>    n_layer: <span class="bu">int</span> <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb22-254"><a href="#cb22-254" aria-hidden="true" tabindex="-1"></a>    n_head: <span class="bu">int</span> <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb22-255"><a href="#cb22-255" aria-hidden="true" tabindex="-1"></a>    n_embd: <span class="bu">int</span> <span class="op">=</span> <span class="dv">768</span></span>
<span id="cb22-256"><a href="#cb22-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-257"><a href="#cb22-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-258"><a href="#cb22-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-259"><a href="#cb22-259" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-260"><a href="#cb22-260" aria-hidden="true" tabindex="-1"></a><span class="co"># GPT2 Model Implementation</span></span>
<span id="cb22-261"><a href="#cb22-261" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb22-262"><a href="#cb22-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-263"><a href="#cb22-263" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GPT(nn.Module):</span>
<span id="cb22-264"><a href="#cb22-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-265"><a href="#cb22-265" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, config, device):</span>
<span id="cb22-266"><a href="#cb22-266" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb22-267"><a href="#cb22-267" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.config <span class="op">=</span> config</span>
<span id="cb22-268"><a href="#cb22-268" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> device</span>
<span id="cb22-269"><a href="#cb22-269" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.manual_seed <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb22-270"><a href="#cb22-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-271"><a href="#cb22-271" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transformer <span class="op">=</span> nn.ModuleDict(</span>
<span id="cb22-272"><a href="#cb22-272" aria-hidden="true" tabindex="-1"></a>            <span class="bu">dict</span>(</span>
<span id="cb22-273"><a href="#cb22-273" aria-hidden="true" tabindex="-1"></a>                wte<span class="op">=</span>nn.Embedding(config.vocab_size, config.n_embd),</span>
<span id="cb22-274"><a href="#cb22-274" aria-hidden="true" tabindex="-1"></a>                wpe<span class="op">=</span>nn.Embedding(config.block_size, config.n_embd),</span>
<span id="cb22-275"><a href="#cb22-275" aria-hidden="true" tabindex="-1"></a>                h<span class="op">=</span>nn.ModuleList(</span>
<span id="cb22-276"><a href="#cb22-276" aria-hidden="true" tabindex="-1"></a>                    [Block(config) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(config.n_layer)]</span>
<span id="cb22-277"><a href="#cb22-277" aria-hidden="true" tabindex="-1"></a>                ),</span>
<span id="cb22-278"><a href="#cb22-278" aria-hidden="true" tabindex="-1"></a>                ln_f<span class="op">=</span>nn.LayerNorm(config.n_embd),</span>
<span id="cb22-279"><a href="#cb22-279" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb22-280"><a href="#cb22-280" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-281"><a href="#cb22-281" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lm_head <span class="op">=</span> nn.Linear(</span>
<span id="cb22-282"><a href="#cb22-282" aria-hidden="true" tabindex="-1"></a>            config.n_embd, config.vocab_size, bias<span class="op">=</span><span class="va">False</span></span>
<span id="cb22-283"><a href="#cb22-283" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-284"><a href="#cb22-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-285"><a href="#cb22-285" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transformer.wte.weight <span class="op">=</span> <span class="va">self</span>.lm_head.weight</span>
<span id="cb22-286"><a href="#cb22-286" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.<span class="bu">apply</span>(<span class="va">self</span>._init_weights)</span>
<span id="cb22-287"><a href="#cb22-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-288"><a href="#cb22-288" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _init_weights(<span class="va">self</span>, module):</span>
<span id="cb22-289"><a href="#cb22-289" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(module, nn.Linear):</span>
<span id="cb22-290"><a href="#cb22-290" aria-hidden="true" tabindex="-1"></a>            std <span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb22-291"><a href="#cb22-291" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">hasattr</span>(module, <span class="st">"NANOGPT_SCALE_INIT"</span>):</span>
<span id="cb22-292"><a href="#cb22-292" aria-hidden="true" tabindex="-1"></a>                std <span class="op">*=</span> (<span class="dv">2</span> <span class="op">*</span> <span class="va">self</span>.config.n_layer) <span class="op">**</span> <span class="op">-</span><span class="fl">0.5</span></span>
<span id="cb22-293"><a href="#cb22-293" aria-hidden="true" tabindex="-1"></a>            torch.nn.init.normal_(module.weight, mean<span class="op">=</span><span class="fl">0.0</span>, std<span class="op">=</span>std)</span>
<span id="cb22-294"><a href="#cb22-294" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> module.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb22-295"><a href="#cb22-295" aria-hidden="true" tabindex="-1"></a>                torch.nn.init.zeros_(module.bias)</span>
<span id="cb22-296"><a href="#cb22-296" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(module, nn.Embedding):</span>
<span id="cb22-297"><a href="#cb22-297" aria-hidden="true" tabindex="-1"></a>            torch.nn.init.normal_(module.weight, mean<span class="op">=</span><span class="fl">0.0</span>, std<span class="op">=</span><span class="fl">0.02</span>)</span>
<span id="cb22-298"><a href="#cb22-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-299"><a href="#cb22-299" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, idx, targets<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb22-300"><a href="#cb22-300" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb22-301"><a href="#cb22-301" aria-hidden="true" tabindex="-1"></a><span class="co">        Forward pass of the GPT model.</span></span>
<span id="cb22-302"><a href="#cb22-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-303"><a href="#cb22-303" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb22-304"><a href="#cb22-304" aria-hidden="true" tabindex="-1"></a><span class="co">            idx (torch.Tensor): Supplies the input tensor of shape</span></span>
<span id="cb22-305"><a href="#cb22-305" aria-hidden="true" tabindex="-1"></a><span class="co">                (B, T).</span></span>
<span id="cb22-306"><a href="#cb22-306" aria-hidden="true" tabindex="-1"></a><span class="co">            targets (torch.Tensor): Optionally supplies the target</span></span>
<span id="cb22-307"><a href="#cb22-307" aria-hidden="true" tabindex="-1"></a><span class="co">                tensor of shape (B, T) for computing the loss.</span></span>
<span id="cb22-308"><a href="#cb22-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-309"><a href="#cb22-309" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb22-310"><a href="#cb22-310" aria-hidden="true" tabindex="-1"></a>        (B, T) <span class="op">=</span> idx.size()</span>
<span id="cb22-311"><a href="#cb22-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-312"><a href="#cb22-312" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward the token and position embeddings.</span></span>
<span id="cb22-313"><a href="#cb22-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-314"><a href="#cb22-314" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Shape (T)</span></span>
<span id="cb22-315"><a href="#cb22-315" aria-hidden="true" tabindex="-1"></a>        pos <span class="op">=</span> torch.arange(<span class="dv">0</span>, T, dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span>idx.device)</span>
<span id="cb22-316"><a href="#cb22-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-317"><a href="#cb22-317" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Position embeddings of shape (T, n_embd).</span></span>
<span id="cb22-318"><a href="#cb22-318" aria-hidden="true" tabindex="-1"></a>        pos_emb <span class="op">=</span> <span class="va">self</span>.transformer.wpe(pos)</span>
<span id="cb22-319"><a href="#cb22-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-320"><a href="#cb22-320" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Token embeddings of shape (B, T, n_embd).</span></span>
<span id="cb22-321"><a href="#cb22-321" aria-hidden="true" tabindex="-1"></a>        tok_emb <span class="op">=</span> <span class="va">self</span>.transformer.wte(idx)</span>
<span id="cb22-322"><a href="#cb22-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-323"><a href="#cb22-323" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> tok_emb <span class="op">+</span> pos_emb</span>
<span id="cb22-324"><a href="#cb22-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-325"><a href="#cb22-325" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward the blocks of the transformer.</span></span>
<span id="cb22-326"><a href="#cb22-326" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> block <span class="kw">in</span> <span class="va">self</span>.transformer.h:</span>
<span id="cb22-327"><a href="#cb22-327" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> block(x)</span>
<span id="cb22-328"><a href="#cb22-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-329"><a href="#cb22-329" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward the final layernorm and the classifier.</span></span>
<span id="cb22-330"><a href="#cb22-330" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.transformer.ln_f(x)</span>
<span id="cb22-331"><a href="#cb22-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-332"><a href="#cb22-332" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (B, T, vocab_size)</span></span>
<span id="cb22-333"><a href="#cb22-333" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.lm_head(x)</span>
<span id="cb22-334"><a href="#cb22-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-335"><a href="#cb22-335" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> <span class="va">None</span></span>
<span id="cb22-336"><a href="#cb22-336" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> targets <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb22-337"><a href="#cb22-337" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> F.cross_entropy(</span>
<span id="cb22-338"><a href="#cb22-338" aria-hidden="true" tabindex="-1"></a>                logits.view(<span class="op">-</span><span class="dv">1</span>, logits.size(<span class="op">-</span><span class="dv">1</span>)), targets.view(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb22-339"><a href="#cb22-339" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb22-340"><a href="#cb22-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-341"><a href="#cb22-341" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (logits, loss)</span>
<span id="cb22-342"><a href="#cb22-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-343"><a href="#cb22-343" aria-hidden="true" tabindex="-1"></a>    <span class="at">@classmethod</span></span>
<span id="cb22-344"><a href="#cb22-344" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> from_local_pretrained(</span>
<span id="cb22-345"><a href="#cb22-345" aria-hidden="true" tabindex="-1"></a>        cls, model_path: <span class="bu">str</span>, map_location: <span class="bu">str</span> <span class="op">=</span> <span class="st">"cuda"</span></span>
<span id="cb22-346"><a href="#cb22-346" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb22-347"><a href="#cb22-347" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb22-348"><a href="#cb22-348" aria-hidden="true" tabindex="-1"></a><span class="co">        Load a model from a local checkpoint.</span></span>
<span id="cb22-349"><a href="#cb22-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-350"><a href="#cb22-350" aria-hidden="true" tabindex="-1"></a><span class="co">        N.B. This is a new method based off GPT.from_pretrained</span></span>
<span id="cb22-351"><a href="#cb22-351" aria-hidden="true" tabindex="-1"></a><span class="co">             in Andrej Karpathy's train_gpt2.py.</span></span>
<span id="cb22-352"><a href="#cb22-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-353"><a href="#cb22-353" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb22-354"><a href="#cb22-354" aria-hidden="true" tabindex="-1"></a><span class="co">            cls (type): Supplies the class type.</span></span>
<span id="cb22-355"><a href="#cb22-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-356"><a href="#cb22-356" aria-hidden="true" tabindex="-1"></a><span class="co">            model_path (str): Supplies the path to the model</span></span>
<span id="cb22-357"><a href="#cb22-357" aria-hidden="true" tabindex="-1"></a><span class="co">                checkpoint.</span></span>
<span id="cb22-358"><a href="#cb22-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-359"><a href="#cb22-359" aria-hidden="true" tabindex="-1"></a><span class="co">            map_location (str): Supplies the device to which</span></span>
<span id="cb22-360"><a href="#cb22-360" aria-hidden="true" tabindex="-1"></a><span class="co">                the model will be mapped.</span></span>
<span id="cb22-361"><a href="#cb22-361" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb22-362"><a href="#cb22-362" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.serialization.safe_globals([GPTConfig]):</span>
<span id="cb22-363"><a href="#cb22-363" aria-hidden="true" tabindex="-1"></a>            checkpoint <span class="op">=</span> torch.load(</span>
<span id="cb22-364"><a href="#cb22-364" aria-hidden="true" tabindex="-1"></a>                model_path,</span>
<span id="cb22-365"><a href="#cb22-365" aria-hidden="true" tabindex="-1"></a>                map_location<span class="op">=</span>map_location,</span>
<span id="cb22-366"><a href="#cb22-366" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb22-367"><a href="#cb22-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-368"><a href="#cb22-368" aria-hidden="true" tabindex="-1"></a>        config <span class="op">=</span> checkpoint[<span class="st">"config"</span>]</span>
<span id="cb22-369"><a href="#cb22-369" aria-hidden="true" tabindex="-1"></a>        config <span class="op">=</span> GPTConfig(<span class="op">**</span>checkpoint[<span class="st">"config"</span>])</span>
<span id="cb22-370"><a href="#cb22-370" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> cls(config, device<span class="op">=</span>map_location)</span>
<span id="cb22-371"><a href="#cb22-371" aria-hidden="true" tabindex="-1"></a>        model.load_state_dict(checkpoint[<span class="st">"model"</span>])</span>
<span id="cb22-372"><a href="#cb22-372" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb22-373"><a href="#cb22-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-374"><a href="#cb22-374" aria-hidden="true" tabindex="-1"></a>        msg <span class="op">=</span> (</span>
<span id="cb22-375"><a href="#cb22-375" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Loaded model from step </span><span class="sc">{</span>checkpoint[<span class="st">'step'</span>]<span class="sc">}</span><span class="ss">, "</span></span>
<span id="cb22-376"><a href="#cb22-376" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"val_loss </span><span class="sc">{</span>checkpoint[<span class="st">'val_loss'</span>]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb22-377"><a href="#cb22-377" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-378"><a href="#cb22-378" aria-hidden="true" tabindex="-1"></a>        logging.info(msg)</span>
<span id="cb22-379"><a href="#cb22-379" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> model</span>
<span id="cb22-380"><a href="#cb22-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-381"><a href="#cb22-381" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate(</span>
<span id="cb22-382"><a href="#cb22-382" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, text: <span class="bu">str</span>, max_length: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1024</span>, top_k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">50</span>,</span>
<span id="cb22-383"><a href="#cb22-383" aria-hidden="true" tabindex="-1"></a>        seed: <span class="bu">int</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb22-384"><a href="#cb22-384" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb22-385"><a href="#cb22-385" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb22-386"><a href="#cb22-386" aria-hidden="true" tabindex="-1"></a><span class="co">        Generate text from the model.</span></span>
<span id="cb22-387"><a href="#cb22-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-388"><a href="#cb22-388" aria-hidden="true" tabindex="-1"></a><span class="co">        N.B. This is a new method based off the generation code</span></span>
<span id="cb22-389"><a href="#cb22-389" aria-hidden="true" tabindex="-1"></a><span class="co">             present in Andrej Karpathy's train_gpt2.py.</span></span>
<span id="cb22-390"><a href="#cb22-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-391"><a href="#cb22-391" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb22-392"><a href="#cb22-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-393"><a href="#cb22-393" aria-hidden="true" tabindex="-1"></a><span class="co">            text (str): Supplies the prompt.</span></span>
<span id="cb22-394"><a href="#cb22-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-395"><a href="#cb22-395" aria-hidden="true" tabindex="-1"></a><span class="co">            max_length (int): Supplies the maximum total length,</span></span>
<span id="cb22-396"><a href="#cb22-396" aria-hidden="true" tabindex="-1"></a><span class="co">                including prompt.</span></span>
<span id="cb22-397"><a href="#cb22-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-398"><a href="#cb22-398" aria-hidden="true" tabindex="-1"></a><span class="co">            top_k (int): Supplies the number of tokens to consider</span></span>
<span id="cb22-399"><a href="#cb22-399" aria-hidden="true" tabindex="-1"></a><span class="co">                at each generation step.</span></span>
<span id="cb22-400"><a href="#cb22-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-401"><a href="#cb22-401" aria-hidden="true" tabindex="-1"></a><span class="co">            seed (int): Optionally supplies the manual seed to use</span></span>
<span id="cb22-402"><a href="#cb22-402" aria-hidden="true" tabindex="-1"></a><span class="co">                for the generator.  If None, the model's manual</span></span>
<span id="cb22-403"><a href="#cb22-403" aria-hidden="true" tabindex="-1"></a><span class="co">                seed will be used.</span></span>
<span id="cb22-404"><a href="#cb22-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-405"><a href="#cb22-405" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb22-406"><a href="#cb22-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-407"><a href="#cb22-407" aria-hidden="true" tabindex="-1"></a><span class="co">            str: The generated text (including the initial prompt).</span></span>
<span id="cb22-408"><a href="#cb22-408" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb22-409"><a href="#cb22-409" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.<span class="bu">eval</span>()</span>
<span id="cb22-410"><a href="#cb22-410" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> <span class="va">self</span>.device</span>
<span id="cb22-411"><a href="#cb22-411" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Obtain our GPT2 tokenizer, and resolve the stop token.</span></span>
<span id="cb22-412"><a href="#cb22-412" aria-hidden="true" tabindex="-1"></a>        enc <span class="op">=</span> tiktoken.get_encoding(<span class="st">"gpt2"</span>)</span>
<span id="cb22-413"><a href="#cb22-413" aria-hidden="true" tabindex="-1"></a>        stop_string <span class="op">=</span> <span class="st">'&lt;|endoftext|&gt;'</span></span>
<span id="cb22-414"><a href="#cb22-414" aria-hidden="true" tabindex="-1"></a>        stop_token <span class="op">=</span> enc.n_vocab <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb22-415"><a href="#cb22-415" aria-hidden="true" tabindex="-1"></a>        actual <span class="op">=</span> enc.decode([stop_token])</span>
<span id="cb22-416"><a href="#cb22-416" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> actual <span class="op">==</span> stop_string, (</span>
<span id="cb22-417"><a href="#cb22-417" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"expected </span><span class="sc">{</span>stop_string<span class="sc">}</span><span class="ss">, got </span><span class="sc">{</span>actual<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb22-418"><a href="#cb22-418" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-419"><a href="#cb22-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-420"><a href="#cb22-420" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode the prompt.</span></span>
<span id="cb22-421"><a href="#cb22-421" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> enc.encode(text)</span>
<span id="cb22-422"><a href="#cb22-422" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.tensor(</span>
<span id="cb22-423"><a href="#cb22-423" aria-hidden="true" tabindex="-1"></a>            tokens, dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span>device</span>
<span id="cb22-424"><a href="#cb22-424" aria-hidden="true" tabindex="-1"></a>        ).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb22-425"><a href="#cb22-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-426"><a href="#cb22-426" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create a random generator for reproducibility.</span></span>
<span id="cb22-427"><a href="#cb22-427" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> seed <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb22-428"><a href="#cb22-428" aria-hidden="true" tabindex="-1"></a>            seed <span class="op">=</span> <span class="va">self</span>.manual_seed</span>
<span id="cb22-429"><a href="#cb22-429" aria-hidden="true" tabindex="-1"></a>        sample_rng <span class="op">=</span> torch.Generator(device<span class="op">=</span>device)</span>
<span id="cb22-430"><a href="#cb22-430" aria-hidden="true" tabindex="-1"></a>        sample_rng.manual_seed(seed)</span>
<span id="cb22-431"><a href="#cb22-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-432"><a href="#cb22-432" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate tokens up to our max length, or until we hit the</span></span>
<span id="cb22-433"><a href="#cb22-433" aria-hidden="true" tabindex="-1"></a>        <span class="co"># stop token.</span></span>
<span id="cb22-434"><a href="#cb22-434" aria-hidden="true" tabindex="-1"></a>        start <span class="op">=</span> time.perf_counter()</span>
<span id="cb22-435"><a href="#cb22-435" aria-hidden="true" tabindex="-1"></a>        count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-436"><a href="#cb22-436" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> x.size(<span class="dv">1</span>) <span class="op">&lt;</span> max_length:</span>
<span id="cb22-437"><a href="#cb22-437" aria-hidden="true" tabindex="-1"></a>            count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb22-438"><a href="#cb22-438" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb22-439"><a href="#cb22-439" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Forward pass, ignoring the returned loss.</span></span>
<span id="cb22-440"><a href="#cb22-440" aria-hidden="true" tabindex="-1"></a>                (logits, _) <span class="op">=</span> <span class="va">self</span>(x)</span>
<span id="cb22-441"><a href="#cb22-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-442"><a href="#cb22-442" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Take the logits at the last time-step (shape:</span></span>
<span id="cb22-443"><a href="#cb22-443" aria-hidden="true" tabindex="-1"></a>            <span class="co"># (1, vocab_size)).</span></span>
<span id="cb22-444"><a href="#cb22-444" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> logits[:, <span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb22-445"><a href="#cb22-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-446"><a href="#cb22-446" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Convert to probabilities.</span></span>
<span id="cb22-447"><a href="#cb22-447" aria-hidden="true" tabindex="-1"></a>            probs <span class="op">=</span> F.softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb22-448"><a href="#cb22-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-449"><a href="#cb22-449" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Top-k sampling.</span></span>
<span id="cb22-450"><a href="#cb22-450" aria-hidden="true" tabindex="-1"></a>            topk_probs, topk_indices <span class="op">=</span> torch.topk(</span>
<span id="cb22-451"><a href="#cb22-451" aria-hidden="true" tabindex="-1"></a>                probs, k<span class="op">=</span>top_k, dim<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb22-452"><a href="#cb22-452" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb22-453"><a href="#cb22-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-454"><a href="#cb22-454" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Sample the next token.</span></span>
<span id="cb22-455"><a href="#cb22-455" aria-hidden="true" tabindex="-1"></a>            next_idx <span class="op">=</span> torch.multinomial(</span>
<span id="cb22-456"><a href="#cb22-456" aria-hidden="true" tabindex="-1"></a>                topk_probs, num_samples<span class="op">=</span><span class="dv">1</span>, generator<span class="op">=</span>sample_rng</span>
<span id="cb22-457"><a href="#cb22-457" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb22-458"><a href="#cb22-458" aria-hidden="true" tabindex="-1"></a>            next_token <span class="op">=</span> torch.gather(topk_indices, <span class="op">-</span><span class="dv">1</span>, next_idx)</span>
<span id="cb22-459"><a href="#cb22-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-460"><a href="#cb22-460" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the next token is the stop token, we're done.</span></span>
<span id="cb22-461"><a href="#cb22-461" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> next_token.item() <span class="op">==</span> stop_token:</span>
<span id="cb22-462"><a href="#cb22-462" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb22-463"><a href="#cb22-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-464"><a href="#cb22-464" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Otherwise, append the token to the current sequence</span></span>
<span id="cb22-465"><a href="#cb22-465" aria-hidden="true" tabindex="-1"></a>            <span class="co"># and continue generation.</span></span>
<span id="cb22-466"><a href="#cb22-466" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> torch.cat((x, next_token), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb22-467"><a href="#cb22-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-468"><a href="#cb22-468" aria-hidden="true" tabindex="-1"></a>        end <span class="op">=</span> time.perf_counter()</span>
<span id="cb22-469"><a href="#cb22-469" aria-hidden="true" tabindex="-1"></a>        elapsed <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb22-470"><a href="#cb22-470" aria-hidden="true" tabindex="-1"></a>        tokens_per_sec <span class="op">=</span> <span class="bu">float</span>(count) <span class="op">/</span> elapsed</span>
<span id="cb22-471"><a href="#cb22-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-472"><a href="#cb22-472" aria-hidden="true" tabindex="-1"></a>        msg <span class="op">=</span> (</span>
<span id="cb22-473"><a href="#cb22-473" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'Generated </span><span class="sc">{</span>count<span class="sc">}</span><span class="ss"> tokens in </span><span class="sc">{</span>elapsed<span class="sc">:.2f}</span><span class="ss"> seconds '</span></span>
<span id="cb22-474"><a href="#cb22-474" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'(</span><span class="sc">{</span>tokens_per_sec<span class="sc">:.2f}</span><span class="ss"> tokens/sec)'</span></span>
<span id="cb22-475"><a href="#cb22-475" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-476"><a href="#cb22-476" aria-hidden="true" tabindex="-1"></a>        logging.debug(msg)</span>
<span id="cb22-477"><a href="#cb22-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-478"><a href="#cb22-478" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Decode the output tokens and return the generated text,</span></span>
<span id="cb22-479"><a href="#cb22-479" aria-hidden="true" tabindex="-1"></a>        <span class="co"># including the initial prompt.</span></span>
<span id="cb22-480"><a href="#cb22-480" aria-hidden="true" tabindex="-1"></a>        output_tokens <span class="op">=</span> x[<span class="dv">0</span>].tolist()</span>
<span id="cb22-481"><a href="#cb22-481" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> enc.decode(output_tokens)</span>
<span id="cb22-482"><a href="#cb22-482" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<a class="quarto-notebook-link" id="nblink-1" href="gpt2_v1-preview.html#cell-gpt2-v1-setup">Source: gpt2_v1.ipynb</a></div>
</section>
<section id="loading-the-model" class="level2">
<h2 class="anchored" data-anchor-id="loading-the-model">Loading the Model</h2>
<p>With the code above executed in a preceding Jupyter Notebook cell, we can load the model as follows:</p>
<div class="quarto-embed-nb-cell">
<div id="cell-gpt2-v1-load-model" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GPT.from_local_pretrained(</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    MODEL_CHECKPOINT,</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    map_location<span class="op">=</span><span class="st">'cuda'</span>,</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>model.to(<span class="st">'cuda'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2025-02-06 15:12:03,802 - INFO - Loaded model from step 19072, val_loss 3.0519702434539795</code></pre>
</div>
<div id="gpt2-v1-load-model" class="cell-output cell-output-display" data-execution_count="2">
<pre><code>GPT(
  (transformer): ModuleDict(
    (wte): Embedding(50304, 768)
    (wpe): Embedding(1024, 768)
    (h): ModuleList(
      (0-11): 12 x Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): CausalSelfAttention(
          (c_attn): Linear(in_features=768, out_features=2304, bias=True)
          (c_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): GELU(approximate='tanh')
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (lm_head): Linear(in_features=768, out_features=50304, bias=False)
)</code></pre>
</div>
</div>
</div>
</section>
<section id="generating-text" class="level2">
<h2 class="anchored" data-anchor-id="generating-text">Generating Text</h2>
<p>Once we’ve got a model instance, text can be generated by simply calling the model’s <code>generate()</code> function with a prompt, and, optionally, some additional parameters like seed and max length. This is also referred to as inference—the two terms are interchangeable, and mean the same thing: the act of providing some input tokens—your encoded prompt—to your trained model, and having it generate tokens in response.</p>
<p>Note that this isn’t a <em>chat</em> or <em>instruction</em> model, nor has it been fine-tuned to remotely resemble something actually usable. So you can’t ask it questions or have it write code for you.</p>
<p>What you can do, though, is provide it with a half written sentence, and then laugh at the ridiculous content it generates in response. Although note that its syntax is pretty good—the model has clearly learned enough during training about how the English language is structured, which words make sense when placed together, that sort of thing. It just has no clue about underlying semantics.</p>
<div class="desktop-only">
<div class="quarto-embed-nb-cell">
<div id="gpt2-v1-generate-1-desktop" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"Albert Einstein's Theory of Relativity stated that"</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> model.generate(prompt, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>.join(wrap(result, width<span class="op">=</span><span class="dv">105</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2025-02-06 15:12:05,068 - DEBUG - Generated 79 tokens in 0.77 seconds (102.55 tokens/sec)
Albert Einstein's Theory of Relativity stated that the speed of light was approximately 10 000 of
parsecs, whereas quantum physicists have suggested that, as we move further into the universe, the
universe might grow older. The new experiment, conducted by researchers at the University of New Jersey,
New York, and the University of California, Berkeley shows that photons travelling at the speed of light
will be around 30 to 65 kilometres per second.</code></pre>
</div>
</div>
</div>
</div>
<div class="tablet-only">
<div class="quarto-embed-nb-cell">
<div id="gpt2-v1-generate-1-tablet" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"Albert Einstein's Theory of Relativity stated that"</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> model.generate(prompt, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>.join(wrap(result, width<span class="op">=</span><span class="dv">58</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2025-02-06 15:12:05,620 - DEBUG - Generated 79 tokens in 0.55 seconds (144.83 tokens/sec)
Albert Einstein's Theory of Relativity stated that the
speed of light was approximately 10 000 of parsecs,
whereas quantum physicists have suggested that, as we move
further into the universe, the universe might grow older.
The new experiment, conducted by researchers at the
University of New Jersey, New York, and the University of
California, Berkeley shows that photons travelling at the
speed of light will be around 30 to 65 kilometres per
second.</code></pre>
</div>
</div>
</div>
</div>
<div class="phone-only">
<div class="quarto-embed-nb-cell">
<div id="gpt2-v1-generate-1-phone" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"Albert Einstein's Theory of Relativity stated that"</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> model.generate(prompt, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>.join(wrap(result, width<span class="op">=</span><span class="dv">45</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2025-02-06 15:12:06,179 - DEBUG - Generated 79 tokens in 0.55 seconds (143.23 tokens/sec)
Albert Einstein's Theory of Relativity stated
that the speed of light was approximately 10
000 of parsecs, whereas quantum physicists
have suggested that, as we move further into
the universe, the universe might grow older.
The new experiment, conducted by researchers
at the University of New Jersey, New York,
and the University of California, Berkeley
shows that photons travelling at the speed of
light will be around 30 to 65 kilometres per
second.</code></pre>
</div>
</div>
</div>
</div>
<p>Now, it’s worth noting at this point that a 124 million parameter GPT2 model, trained from scratch for 19,072 iterations on the <code>edu_fineweb10b</code> data set, with a final loss score of 3.052, is, quite frankly, hot garbage :-)</p>
<p>Do not be expecting output from this model to rival anything close to what you’d expect from a contemporary LLM. In fact, we can’t even rely on it to even remotely generate content that is factual in nature. It spews hot probabilisitic garbage that mostly conforms to the structure of the English language.</p>
<p>But at least it’s <em>our</em> hot garbage that we trained from nothing, and it’s all we need to start playing around with generating text in parallel.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Hot Garbage Example">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hot Garbage Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Provide a slightly different seed to the prompt above and you’ll precisely see some hot garbage generation in action. In the following example, with an identical prompt as the one prior, it just streams nonsense until hitting its max token limit, nary a stop token in sight.</p>
<div class="desktop-only">
<div class="quarto-embed-nb-cell">
<div id="gpt2-v1-generate-2-desktop" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> model.generate(prompt, seed<span class="op">=</span><span class="dv">20190903</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>.join(wrap(result, width<span class="op">=</span><span class="dv">100</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2025-02-06 15:12:22,030 - DEBUG - Generated 1015 tokens in 15.84 seconds (64.07 tokens/sec)
Albert Einstein's Theory of Relativity stated that the speed of light is the same as it is in two
places, which means that a given speed can either be described by two different speed equations
directly or they may be both equations. It is then assumed that the speed of light is the speed of
the universe or the universe's existence relative to Earth. In relativity, a measure of the speed of
light is the absolute speed of the light. As long as the speed of light is less than its speed in
two different places, the absolute speed can be calculated. For example, the absolute speed is
1/2990000000 (2,299,792,458) km/hr with an absolute speed about 10 times as fast as it is in two
different places. Now we can use the following equation to describe the speed of light: E = C/C2 The
speed of light, as a function of C, is a constant. By Einstein's definition of relativity, the speed
of light is a constant. This is because light travels at its maximum speed along the direction (if
it's travelling above the speed of light, the point where light must be observed is called
"aperture" of the speed of light). The speed of light is about half as fast as the speed of light
because the speed of light has a smaller varying velocity for each direction of radiation. The speed
of light, as a function of C, is a constant. The speed of a wave is the constant measured along the
direction of the wave relative to its location in space. E = C/C2 where E is the speed of light
along the direction of the wave. Because the speed of the wave is the speed of the particle in the
wave, and c the speed of the particle, E's is also given by the speed of light. For example, a light
particle is moving from its place of greatest velocity to its location of greatest velocity. E.g. C
= F/d, C = d/d For most materials and most other objects, the speed of light is the same for all
wavelengths. The speed of light is, on the other hand, the speed of the energy form of a photon.
E.g. c = C/d, C = e/d For most particles, light travels over one degree of separation and this is
how photons interact with other particles. We can compare a particle's velocity to an object's
velocity. The speed of light is measured by the distance between the particle's nose and the surface
of the object. For example, a photon of light emits the energy of a single photon. If a photon of
another type is fired at the same speed as the first, it will get out of the light, but a photon of
the other type will not get back to the ground. The fractional energy will be reduced. The distance
between two photons of the same type will be reduced to the square of their energies. E.g. C = C/C2,
C = -D/d., D = 9/6 A photon of color does not have sufficient energy to be emitted by that color and
is therefore subject to The speed of light is the change in velocity over time. This is a constant,
but sometimes it is possible to express it like this: E = c2/e In relativity, the length of the
distance is the length of time the length of wave is divided by the speed of light. E.g. a beam of
light travelling at about 9.2 miles per second must travel at around 7.3 miles per second to get
E.g. a beam moving at 3.2 miles per second must travel at around 8 miles per second to get E.g. a
beam moving at 1.8 miles per second must travel at 9.0 miles per second to get E.g. an object going
at 2.3 miles per second must travel at 1.8 miles per second to get E.g. a beam moving at 2.3 miles
per second must travel at 3.4 miles per second to get E.g.. a beam traveling at 3.4 miles per second
to get E.g.. a beam moving at 2.3 miles per second must travel at 3.8 miles per second to get E.g..
a beam traveling at 3.8 miles per second to get E.g.. a beam moving at about 4.4 miles per second
must travel at about 3.9 miles per second to get E.g.. a beam moving at 5.5 miles per second to get
a beam moving at 5.9 miles per S.G.D.. is the same thing as a mass. The distance is a unit in terms
of the speed of light. Determining the speed of light is an additional measure of the energy. For
most things</code></pre>
</div>
</div>
</div>
</div>
<div class="tablet-only">
<div class="quarto-embed-nb-cell">
<div id="gpt2-v1-generate-2-tablet" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> model.generate(prompt, seed<span class="op">=</span><span class="dv">20190903</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>.join(wrap(result, width<span class="op">=</span><span class="dv">54</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2025-02-06 15:12:37,853 - DEBUG - Generated 1015 tokens in 15.82 seconds (64.18 tokens/sec)
Albert Einstein's Theory of Relativity stated that the
speed of light is the same as it is in two places,
which means that a given speed can either be described
by two different speed equations directly or they may
be both equations. It is then assumed that the speed
of light is the speed of the universe or the
universe's existence relative to Earth. In relativity,
a measure of the speed of light is the absolute speed
of the light. As long as the speed of light is less
than its speed in two different places, the absolute
speed can be calculated. For example, the absolute
speed is 1/2990000000 (2,299,792,458) km/hr with an
absolute speed about 10 times as fast as it is in two
different places. Now we can use the following
equation to describe the speed of light: E = C/C2 The
speed of light, as a function of C, is a constant. By
Einstein's definition of relativity, the speed of
light is a constant. This is because light travels at
its maximum speed along the direction (if it's
travelling above the speed of light, the point where
light must be observed is called "aperture" of the
speed of light). The speed of light is about half as
fast as the speed of light because the speed of light
has a smaller varying velocity for each direction of
radiation. The speed of light, as a function of C, is
a constant. The speed of a wave is the constant
measured along the direction of the wave relative to
its location in space. E = C/C2 where E is the speed
of light along the direction of the wave. Because the
speed of the wave is the speed of the particle in the
wave, and c the speed of the particle, E's is also
given by the speed of light. For example, a light
particle is moving from its place of greatest velocity
to its location of greatest velocity. E.g. C = F/d, C
= d/d For most materials and most other objects, the
speed of light is the same for all wavelengths. The
speed of light is, on the other hand, the speed of the
energy form of a photon. E.g. c = C/d, C = e/d For
most particles, light travels over one degree of
separation and this is how photons interact with other
particles. We can compare a particle's velocity to an
object's velocity. The speed of light is measured by
the distance between the particle's nose and the
surface of the object. For example, a photon of light
emits the energy of a single photon. If a photon of
another type is fired at the same speed as the first,
it will get out of the light, but a photon of the
other type will not get back to the ground. The
fractional energy will be reduced. The distance
between two photons of the same type will be reduced
to the square of their energies. E.g. C = C/C2, C =
-D/d., D = 9/6 A photon of color does not have
sufficient energy to be emitted by that color and is
therefore subject to The speed of light is the change
in velocity over time. This is a constant, but
sometimes it is possible to express it like this: E =
c2/e In relativity, the length of the distance is the
length of time the length of wave is divided by the
speed of light. E.g. a beam of light travelling at
about 9.2 miles per second must travel at around 7.3
miles per second to get E.g. a beam moving at 3.2
miles per second must travel at around 8 miles per
second to get E.g. a beam moving at 1.8 miles per
second must travel at 9.0 miles per second to get E.g.
an object going at 2.3 miles per second must travel at
1.8 miles per second to get E.g. a beam moving at 2.3
miles per second must travel at 3.4 miles per second
to get E.g.. a beam traveling at 3.4 miles per second
to get E.g.. a beam moving at 2.3 miles per second
must travel at 3.8 miles per second to get E.g.. a
beam traveling at 3.8 miles per second to get E.g.. a
beam moving at about 4.4 miles per second must travel
at about 3.9 miles per second to get E.g.. a beam
moving at 5.5 miles per second to get a beam moving at
5.9 miles per S.G.D.. is the same thing as a mass. The
distance is a unit in terms of the speed of light.
Determining the speed of light is an additional
measure of the energy. For most things</code></pre>
</div>
</div>
</div>
</div>
<div class="phone-only">
<div class="quarto-embed-nb-cell">
<div id="gpt2-v1-generate-2-phone" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> model.generate(prompt, seed<span class="op">=</span><span class="dv">20190903</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>.join(wrap(result, width<span class="op">=</span><span class="dv">40</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2025-02-06 15:12:53,952 - DEBUG - Generated 1015 tokens in 16.09 seconds (63.08 tokens/sec)
Albert Einstein's Theory of Relativity
stated that the speed of light is the
same as it is in two places, which means
that a given speed can either be
described by two different speed
equations directly or they may be both
equations. It is then assumed that the
speed of light is the speed of the
universe or the universe's existence
relative to Earth. In relativity, a
measure of the speed of light is the
absolute speed of the light. As long as
the speed of light is less than its
speed in two different places, the
absolute speed can be calculated. For
example, the absolute speed is
1/2990000000 (2,299,792,458) km/hr with
an absolute speed about 10 times as fast
as it is in two different places. Now we
can use the following equation to
describe the speed of light: E = C/C2
The speed of light, as a function of C,
is a constant. By Einstein's definition
of relativity, the speed of light is a
constant. This is because light travels
at its maximum speed along the direction
(if it's travelling above the speed of
light, the point where light must be
observed is called "aperture" of the
speed of light). The speed of light is
about half as fast as the speed of light
because the speed of light has a smaller
varying velocity for each direction of
radiation. The speed of light, as a
function of C, is a constant. The speed
of a wave is the constant measured along
the direction of the wave relative to
its location in space. E = C/C2 where E
is the speed of light along the
direction of the wave. Because the speed
of the wave is the speed of the particle
in the wave, and c the speed of the
particle, E's is also given by the speed
of light. For example, a light particle
is moving from its place of greatest
velocity to its location of greatest
velocity. E.g. C = F/d, C = d/d For most
materials and most other objects, the
speed of light is the same for all
wavelengths. The speed of light is, on
the other hand, the speed of the energy
form of a photon. E.g. c = C/d, C = e/d
For most particles, light travels over
one degree of separation and this is how
photons interact with other particles.
We can compare a particle's velocity to
an object's velocity. The speed of light
is measured by the distance between the
particle's nose and the surface of the
object. For example, a photon of light
emits the energy of a single photon. If
a photon of another type is fired at the
same speed as the first, it will get out
of the light, but a photon of the other
type will not get back to the ground.
The fractional energy will be reduced.
The distance between two photons of the
same type will be reduced to the square
of their energies. E.g. C = C/C2, C =
-D/d., D = 9/6 A photon of color does
not have sufficient energy to be emitted
by that color and is therefore subject
to The speed of light is the change in
velocity over time. This is a constant,
but sometimes it is possible to express
it like this: E = c2/e In relativity,
the length of the distance is the length
of time the length of wave is divided by
the speed of light. E.g. a beam of light
travelling at about 9.2 miles per second
must travel at around 7.3 miles per
second to get E.g. a beam moving at 3.2
miles per second must travel at around 8
miles per second to get E.g. a beam
moving at 1.8 miles per second must
travel at 9.0 miles per second to get
E.g. an object going at 2.3 miles per
second must travel at 1.8 miles per
second to get E.g. a beam moving at 2.3
miles per second must travel at 3.4
miles per second to get E.g.. a beam
traveling at 3.4 miles per second to get
E.g.. a beam moving at 2.3 miles per
second must travel at 3.8 miles per
second to get E.g.. a beam traveling at
3.8 miles per second to get E.g.. a beam
moving at about 4.4 miles per second
must travel at about 3.9 miles per
second to get E.g.. a beam moving at 5.5
miles per second to get a beam moving at
5.9 miles per S.G.D.. is the same thing
as a mass. The distance is a unit in
terms of the speed of light. Determining
the speed of light is an additional
measure of the energy. For most things</code></pre>
</div>
</div>
</div>
</div>
<p>lolwat.</p>
</div>
</div>
</div>
</section>
<section id="tweaked-version" class="level2">
<h2 class="anchored" data-anchor-id="tweaked-version">Tweaked Version</h2>
<p>TODO.</p>
</section>
</section>
<section id="parallel-pytorch-inference" class="level1">
<h1>Parallel PyTorch Inference</h1>
<p>Now we finally get to the fun part: let’s investigate whether or not PyTorch model inference can be done simultaneously, in parallel, by multiple threads, running on multiple cores at the same time, in a single free-threaded Python process. And ideally, we should only need one GPU, with all of these threads <em>sharing</em> it as fairly as possible. Although if we have multiple GPUs, we should be able to distribute the incoming work evenly across those too, if we want.</p>
<p>This is novel, uncharted territory we’re able to now explore thanks to the free-threaded version of Python.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Simultaneous vs Parallel vs Concurrent">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Simultaneous vs Parallel vs Concurrent
</div>
</div>
<div class="callout-body-container callout-body">
<p>The phrasing I’ve used above—<em>“simultaneously, in parallel”</em>—is a bit redundant. They both imply the same thing. When I use either word in this post, I’m explicitly referring to the new ability unlocked by free-threaded Python, where multiple threads can be running Python code on different CPU cores at the same time—i.e.&nbsp;<em>simultaneously</em>. And thus, you’re performing work in <em>parallel</em>.</p>
<p>When I use the term <em>concurrent</em> or <em>concurrency</em>, I’m using it in the traditional sense within the context of Python: making progress on multiple things at a time. This term is well suited to describe things like web servers, where a single Python process, with a single thread, running on a single CPU core, can service multiple clients at any given time (by way of <a href="https://speakerdeck.com/trent/pyparallel-how-we-removed-the-gil-and-exploited-all-cores?slide=27">non-blocking socket I/O and event multiplexing</a>), but it’s not servicing any of those clients <em>simultaneously</em> on different cores, because that would require multiple threads running in <em>parallel</em>.</p>
<p>Some more details regarding <em>parallelism</em> vs <em>concurrency</em> can be found on <a href="https://speakerdeck.com/trent/parallelism-and-concurrency-with-python?slide=8">slide 8</a> of a deck I put together many years ago titled <a href="https://speakerdeck.com/trent/parallelism-and-concurrency-with-python">Parallelism and Concurrency in Python</a>.</p>
</div>
</div>
<p>So how do we try this out? I guess we could spin up some threads and have them all call <code>model.generate()</code>, but that’s a little boring.</p>
<p>Why not try implement a pure Python, multi-threaded <code>asyncio</code>-based HTTP server, expose a <code>/generate</code>-esque style <code>GET</code> endpoint, and wire that up to the model generation code we saw above, allowing us to serve web requests for generation in parallel, ideally in an <code>asyncio</code>-friendly manner, where we can stream individual tokens back one-by-one via HTTP’s chunked-encoding transfer protocol, giving each thread’s event loop the ability to service multiple clients <em>concurrently</em> in a reasonably fair manner, whilst also servicing many clients in <em>parallel</em> across all threads, and for kicks, get AI to whip up a janky little React Bootstrap UI that we can slap in front of it all to test it?</p>
<section id="pure-python-multi-threaded-http-server" class="level2">
<h2 class="anchored" data-anchor-id="pure-python-multi-threaded-http-server">Pure Python Multi-threaded HTTP Server</h2>
<p>First thing we need is a nice and simple <code>asyncio</code>-based HTTP server, that also happens to work with multi-threading now that we have a free-threaded Python at our disposal.</p>
<p>Luckily, I have one of those laying around already! In support of another article I’m actively working on (which was meant to get published before this post), I ported the <a href="https://github.com/pyparallel/pyparallel/blob/branches/3.3-px/Lib/async/http/server.py">HTTP Server</a> I wrote many years ago for <a href="https://pyparallel.org">PyParallel</a><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> to use the new <code>asyncio</code> facilities available with Python, and then slapped multiple threads on it, where each thread gets its own <code>asyncio</code> event loop.</p>
<p>Turns out, thankfully, that this Just Works, at least on Linux<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>—we can now have a pure Python HTTP server, running in a single Python process, that’ll happily saturate every CPU core under load.</p>
<p>The server code lives in <a href="https://github.com/tpn/parallelopedia/blob/main/src/parallelopedia/http/server.py"><code>parallelopedia.http.server</code></a>, and it includes a super janky little notion of <em>“HTTP Apps”</em>, the purpose of which can be best demonstrated with a simple example:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PlaintextApp(HttpApp):</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    routes <span class="op">=</span> make_routes()</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    route <span class="op">=</span> router(routes)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">@route</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> plaintext(<span class="va">self</span>, request):</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> text_response(request, <span class="st">'Hello, World!'</span>)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.server.send_response(response)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SleeperApp(HttpApp):</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    routes <span class="op">=</span> make_routes()</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>    route <span class="op">=</span> router(routes)</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">@route</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> sleep(<span class="va">self</span>, request, seconds):</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="bu">int</span>(seconds))</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>        msg <span class="op">=</span> <span class="ss">f'Slept for </span><span class="sc">{</span>seconds<span class="sc">}</span><span class="ss"> seconds.'</span>)</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> text_response(request, msg)</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.server.send_response(response)</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a server with the two apps.</span></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>app_classes<span class="op">=</span>[PlaintextApp, SleeperApp]</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>server <span class="op">=</span> HttpServer(app_classes<span class="op">=</span>app_classes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In the above example, the HTTP server will route requests for the <code>/plaintext</code> endpoint to an instance of the <code>PlaintextApp</code>’s <code>plaintext()</code> routine, and <code>/sleep</code> requests get routed to the <code>SleeperApp</code>’s <code>sleep()</code> routine.</p>
<p>The <em>“slapped multiple threads on it”</em> activity I refered to earlier is handled by some new <a href="https://github.com/tpn/parallelopedia/blob/main/src/parallelopedia/http/server.py#L1344">async and threading scaffolding</a> added to the bottom of that module, with the pertinent pieces reproduced below:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="cf">async</span> <span class="kw">def</span> main_async(</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    args: argparse.Namespace,</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    protocol_class: <span class="bu">type</span>,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">*</span>protocol_args: Tuple</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co">    This is the main function for the server when it is running in</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="co">    asynchronous mode.  It will create a server instance and then</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co">    call serve_forever() on it.</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Arguments:</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="co">        args (argparse.Namespace): Supplies the command-line arguments.</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="co">        protocol_class (type): Supplies the protocol class to use.</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="co">        protocol_args (tuple): Supplies the arguments to pass to the</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a><span class="co">            protocol class constructor.</span></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>    loop <span class="op">=</span> asyncio.get_running_loop()</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> os.name <span class="kw">in</span> (<span class="st">'nt'</span>, <span class="st">'cygwin'</span>):</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>        reuse_port <span class="op">=</span> <span class="va">False</span></span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>        reuse_port <span class="op">=</span> <span class="va">True</span></span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>    reuse_address <span class="op">=</span> <span class="va">True</span></span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>    server <span class="op">=</span> <span class="cf">await</span> loop.create_server(</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>        <span class="kw">lambda</span>: protocol_class(<span class="op">*</span>protocol_args),</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a>        args.ip,</span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a>        args.port,</span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a>        backlog<span class="op">=</span>args.listen_backlog,</span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>        reuse_address<span class="op">=</span>reuse_address,</span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a>        reuse_port<span class="op">=</span>reuse_port,</span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">async</span> <span class="cf">with</span> server:</span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">await</span> server.serve_forever()</span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> start_event_loop(</span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a>    args: argparse.Namespace,</span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a>    protocol_class: <span class="bu">type</span>,</span>
<span id="cb39-47"><a href="#cb39-47" aria-hidden="true" tabindex="-1"></a>    <span class="op">*</span>protocol_args: Tuple</span>
<span id="cb39-48"><a href="#cb39-48" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb39-49"><a href="#cb39-49" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb39-50"><a href="#cb39-50" aria-hidden="true" tabindex="-1"></a><span class="co">    This function will start the asyncio event loop and run</span></span>
<span id="cb39-51"><a href="#cb39-51" aria-hidden="true" tabindex="-1"></a><span class="co">    the main_async() function.  It is intended to be the</span></span>
<span id="cb39-52"><a href="#cb39-52" aria-hidden="true" tabindex="-1"></a><span class="co">    target of a threading.Thread.</span></span>
<span id="cb39-53"><a href="#cb39-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-54"><a href="#cb39-54" aria-hidden="true" tabindex="-1"></a><span class="co">    Arguments:</span></span>
<span id="cb39-55"><a href="#cb39-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-56"><a href="#cb39-56" aria-hidden="true" tabindex="-1"></a><span class="co">        args (argparse.Namespace): Supplies the command-line arguments.</span></span>
<span id="cb39-57"><a href="#cb39-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-58"><a href="#cb39-58" aria-hidden="true" tabindex="-1"></a><span class="co">        protocol_class (type): Supplies the protocol class to use.</span></span>
<span id="cb39-59"><a href="#cb39-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-60"><a href="#cb39-60" aria-hidden="true" tabindex="-1"></a><span class="co">        protocol_args (tuple): Supplies the arguments to pass to the</span></span>
<span id="cb39-61"><a href="#cb39-61" aria-hidden="true" tabindex="-1"></a><span class="co">            protocol class constructor.</span></span>
<span id="cb39-62"><a href="#cb39-62" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb39-63"><a href="#cb39-63" aria-hidden="true" tabindex="-1"></a>    asyncio.run(</span>
<span id="cb39-64"><a href="#cb39-64" aria-hidden="true" tabindex="-1"></a>        main_async(</span>
<span id="cb39-65"><a href="#cb39-65" aria-hidden="true" tabindex="-1"></a>            args,</span>
<span id="cb39-66"><a href="#cb39-66" aria-hidden="true" tabindex="-1"></a>            protocol_class,</span>
<span id="cb39-67"><a href="#cb39-67" aria-hidden="true" tabindex="-1"></a>            <span class="op">*</span>protocol_args,</span>
<span id="cb39-68"><a href="#cb39-68" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb39-69"><a href="#cb39-69" aria-hidden="true" tabindex="-1"></a>        debug<span class="op">=</span>args.debug,</span>
<span id="cb39-70"><a href="#cb39-70" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb39-71"><a href="#cb39-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-72"><a href="#cb39-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-73"><a href="#cb39-73" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> main_threaded_multi_accept(</span>
<span id="cb39-74"><a href="#cb39-74" aria-hidden="true" tabindex="-1"></a>    args: argparse.Namespace,</span>
<span id="cb39-75"><a href="#cb39-75" aria-hidden="true" tabindex="-1"></a>    protocol_class: <span class="bu">type</span>,</span>
<span id="cb39-76"><a href="#cb39-76" aria-hidden="true" tabindex="-1"></a>    <span class="op">*</span>protocol_args: Tuple</span>
<span id="cb39-77"><a href="#cb39-77" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb39-78"><a href="#cb39-78" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb39-79"><a href="#cb39-79" aria-hidden="true" tabindex="-1"></a><span class="co">    This is the main function for the server when it is running in</span></span>
<span id="cb39-80"><a href="#cb39-80" aria-hidden="true" tabindex="-1"></a><span class="co">    multi-threaded mode with multiple accept sockets.  Each thread</span></span>
<span id="cb39-81"><a href="#cb39-81" aria-hidden="true" tabindex="-1"></a><span class="co">    will have its own asyncio loop issue a create_server() call for</span></span>
<span id="cb39-82"><a href="#cb39-82" aria-hidden="true" tabindex="-1"></a><span class="co">    the given host/port and protocol.</span></span>
<span id="cb39-83"><a href="#cb39-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-84"><a href="#cb39-84" aria-hidden="true" tabindex="-1"></a><span class="co">    Arguments:</span></span>
<span id="cb39-85"><a href="#cb39-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-86"><a href="#cb39-86" aria-hidden="true" tabindex="-1"></a><span class="co">        args (argparse.Namespace): Supplies the command-line arguments.</span></span>
<span id="cb39-87"><a href="#cb39-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-88"><a href="#cb39-88" aria-hidden="true" tabindex="-1"></a><span class="co">        protocol_class (type): Supplies the protocol class to use.</span></span>
<span id="cb39-89"><a href="#cb39-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-90"><a href="#cb39-90" aria-hidden="true" tabindex="-1"></a><span class="co">        protocol_args (tuple): Supplies the arguments to pass to the</span></span>
<span id="cb39-91"><a href="#cb39-91" aria-hidden="true" tabindex="-1"></a><span class="co">            protocol class constructor.</span></span>
<span id="cb39-92"><a href="#cb39-92" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb39-93"><a href="#cb39-93" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> threading</span>
<span id="cb39-94"><a href="#cb39-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-95"><a href="#cb39-95" aria-hidden="true" tabindex="-1"></a>    threads <span class="op">=</span> []</span>
<span id="cb39-96"><a href="#cb39-96" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(args.threads):</span>
<span id="cb39-97"><a href="#cb39-97" aria-hidden="true" tabindex="-1"></a>        thread <span class="op">=</span> threading.Thread(</span>
<span id="cb39-98"><a href="#cb39-98" aria-hidden="true" tabindex="-1"></a>            target<span class="op">=</span>start_event_loop,</span>
<span id="cb39-99"><a href="#cb39-99" aria-hidden="true" tabindex="-1"></a>            args<span class="op">=</span>(args, protocol_class, <span class="op">*</span>protocol_args),</span>
<span id="cb39-100"><a href="#cb39-100" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb39-101"><a href="#cb39-101" aria-hidden="true" tabindex="-1"></a>        threads.append(thread)</span>
<span id="cb39-102"><a href="#cb39-102" aria-hidden="true" tabindex="-1"></a>        thread.start()</span>
<span id="cb39-103"><a href="#cb39-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-104"><a href="#cb39-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> thread <span class="kw">in</span> threads:</span>
<span id="cb39-105"><a href="#cb39-105" aria-hidden="true" tabindex="-1"></a>        thread.join()</span>
<span id="cb39-106"><a href="#cb39-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-107"><a href="#cb39-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-108"><a href="#cb39-108" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> main(args: Optional[argparse.Namespace] <span class="op">=</span> <span class="va">None</span>):</span>
<span id="cb39-109"><a href="#cb39-109" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb39-110"><a href="#cb39-110" aria-hidden="true" tabindex="-1"></a><span class="co">    Main entry point for parallelopedia.http.server module.</span></span>
<span id="cb39-111"><a href="#cb39-111" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb39-112"><a href="#cb39-112" aria-hidden="true" tabindex="-1"></a>    args <span class="op">=</span> parse_arguments()</span>
<span id="cb39-113"><a href="#cb39-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-114"><a href="#cb39-114" aria-hidden="true" tabindex="-1"></a>    logging.basicConfig(</span>
<span id="cb39-115"><a href="#cb39-115" aria-hidden="true" tabindex="-1"></a>        level<span class="op">=</span><span class="bu">getattr</span>(logging, args.log_level),</span>
<span id="cb39-116"><a href="#cb39-116" aria-hidden="true" tabindex="-1"></a>        <span class="bu">format</span><span class="op">=</span><span class="st">'</span><span class="sc">%(asctime)s</span><span class="st"> - </span><span class="sc">%(levelname)s</span><span class="st"> - </span><span class="sc">%(message)s</span><span class="st">'</span>,</span>
<span id="cb39-117"><a href="#cb39-117" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb39-118"><a href="#cb39-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-119"><a href="#cb39-119" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use multiple threads to load the application classes.</span></span>
<span id="cb39-120"><a href="#cb39-120" aria-hidden="true" tabindex="-1"></a>    app_classes <span class="op">=</span> get_classes_from_strings_parallel(</span>
<span id="cb39-121"><a href="#cb39-121" aria-hidden="true" tabindex="-1"></a>        args.app_classes,</span>
<span id="cb39-122"><a href="#cb39-122" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb39-123"><a href="#cb39-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-124"><a href="#cb39-124" aria-hidden="true" tabindex="-1"></a>    protocol_class <span class="op">=</span> get_class_from_string(args.protocol_class)</span>
<span id="cb39-125"><a href="#cb39-125" aria-hidden="true" tabindex="-1"></a>    protocol_args <span class="op">=</span> (app_classes,)</span>
<span id="cb39-126"><a href="#cb39-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-127"><a href="#cb39-127" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> args.threads <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb39-128"><a href="#cb39-128" aria-hidden="true" tabindex="-1"></a>        asyncio.run(</span>
<span id="cb39-129"><a href="#cb39-129" aria-hidden="true" tabindex="-1"></a>            main_async(</span>
<span id="cb39-130"><a href="#cb39-130" aria-hidden="true" tabindex="-1"></a>                args,</span>
<span id="cb39-131"><a href="#cb39-131" aria-hidden="true" tabindex="-1"></a>                protocol_class,</span>
<span id="cb39-132"><a href="#cb39-132" aria-hidden="true" tabindex="-1"></a>                <span class="op">*</span>protocol_args,</span>
<span id="cb39-133"><a href="#cb39-133" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb39-134"><a href="#cb39-134" aria-hidden="true" tabindex="-1"></a>            debug<span class="op">=</span>args.debug,</span>
<span id="cb39-135"><a href="#cb39-135" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb39-136"><a href="#cb39-136" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb39-137"><a href="#cb39-137" aria-hidden="true" tabindex="-1"></a>        main_threaded_multi_accept(</span>
<span id="cb39-138"><a href="#cb39-138" aria-hidden="true" tabindex="-1"></a>            args,</span>
<span id="cb39-139"><a href="#cb39-139" aria-hidden="true" tabindex="-1"></a>            protocol_class,</span>
<span id="cb39-140"><a href="#cb39-140" aria-hidden="true" tabindex="-1"></a>            <span class="op">*</span>protocol_args,</span>
<span id="cb39-141"><a href="#cb39-141" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb39-142"><a href="#cb39-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-143"><a href="#cb39-143" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:</span>
<span id="cb39-144"><a href="#cb39-144" aria-hidden="true" tabindex="-1"></a>    main()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="gpt2-http-app" class="level2">
<h2 class="anchored" data-anchor-id="gpt2-http-app">GPT2 HTTP App</h2>
<p>With the HTTP server scaffolding in place, we can now whip up a little <code>Gpt2App</code> class that has a <code>generate()</code> method. Incoming requests to the <code>/generate</code> endpoint will be routed to that routine by the server.</p>
<section id="synchronous-up-front-generation" class="level3">
<h3 class="anchored" data-anchor-id="synchronous-up-front-generation">Synchronous Up-Front Generation</h3>
<p>Now, we could take the simple approach, where the <code>Gpt2App.generate()</code> call goes off and calls <code>model.generate()</code> and then patiently waits for the entire response to be generated before sending anything back to the user.</p>
<p>That code would look something like this:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Gpt2App(HttpApp):</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    routes <span class="op">=</span> make_routes()</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    route <span class="op">=</span> router(routes)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">@route</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate(<span class="va">self</span>, request: Request,</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>                 <span class="op">*</span>args: List,</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>                 <span class="op">**</span>kwds: Dict) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> args[<span class="dv">0</span>]</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> get_model()</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> model.generate(prompt<span class="op">=</span>prompt)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>        respose <span class="op">=</span> text_response(request, result)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.server.send_response(response)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>But when have you ever interacted with an LLM via a web interface where it waits until it generates <em>all</em> of the response up-front before sending it back to you? Never; you can see it generate the response in real time, and that’s what we want to mimic here in this experiment.</p>
</section>
<section id="our-goals" class="level3">
<h3 class="anchored" data-anchor-id="our-goals">Our Goals</h3>
<p>The high-level goals for our solution are thus:</p>
<ol type="1">
<li><p>We want to send a generated token back to the user as soon as it becomes available.</p></li>
<li><p>We want to ensure the client receiving the token can display it as soon as they receive it—so we need to be cognizant of what HTTP transfer protocol we use to send bytes back. If we just used normal HTTP transfer encoding, the client would wait until we’ve sent <em>everything</em> before the user sees it, despite the fact that we’ve been trickling individual tokens to them the entire time.</p></li>
<li><p>We want to play nicely with the <code>asyncio</code> ecosystem upon which our hosting HTTP server is based—so we need to be cognizant of the current thread’s event loop, and make sure we don’t impede that thread’s ability to <em>concurrently</em> serve other clients that are being handled by the event loop.</p></li>
</ol>
<p>Thankfully, as we saw earlier with the implementation of the <code>GPT.generate()</code> routine, generating tokens in response to a prompt is inherently a <em>token-by-token</em> process. So the algorithm at least provides us with the means to obtain a single token at a time, which takes care of the first point.</p>
<p>Second, HTTP’s chunked-encoding transfer protocol will allow a HTTP client to immediately <em>“see”</em> the tokens we send back to it as soon as we send them, provided we enable <code>TCP_NODELAY</code> on the underlying socket to ensure the operating system sends the bytes out to the client as soon as we send them.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>If we didn’t do this, the default behavior of <a href="https://en.wikipedia.org/wiki/Nagle%27s_algorithm">Nagle’s algorithm</a> would apply, and the operating system would delay sending individual bytes back when we request, in the hope that it can accumulate more bytes to send all at once at a slightly later point in time. This is advantageous for maximizing throughput, but it impedes latency, and in our case, we want the lower latency afforded by immediately sending the bytes back to the client as soon as we generate them.</p>
</div>
</div>
<p><a href="https://en.wikipedia.org/wiki/Chunked_transfer_encoding">Chunked-encoding</a> works by setting an HTTP response header <code>Transfer-Encoding: chunked</code>, and then in the body, each chunk is transmitted by its length and then the chunk itself. The server communicates to the client that the transfer has completed once a zero-length chunk is received.</p>
<p>So, as long as we send our tokens back via chunked-encoding, any HTTP/1.1 client will be able to reassemble them back into the generated text, giving the visual appearance of real time model generation. That will take care of the second point.</p>
<p>Lastly, in order to play nice within the greater <code>asyncio</code> ecosystem, we need to give control back to the underlying thread’s <code>asyncio</code> event loop after we generate a token and yield a decoded text fragment, which can thankfully be done via a simple call to <code>await asyncio.sleep(0)</code>, provided we’re generating text from the model from within an <code>async</code> callback.</p>
<p>This ensures multiple <em>concurrent</em> clients being handled by our thread’s event loop will be handled fairly; they’ll all receive generated tokens at the same rate.</p>
</section>
<section id="asynchronous-token-by-token-generation" class="level3">
<h3 class="anchored" data-anchor-id="asynchronous-token-by-token-generation">Asynchronous Token-by-Token Generation</h3>
<p>The first thing we need to do is to change our <code>Gpt2App.generate()</code> call into something that is <code>async</code> compatible, in anticipation of some later code that we write needing to issue an <code>await asyncio.sleep(0)</code>, which can only be done within a call frame of an asynchronous method.</p>
<p>When our <code>Gpt2App.generate()</code> routine is called, we’re still within the context of the <code>asyncio</code> protocol’s <code>data_received()</code> routine, which is a normal, synchronous method, <em>not</em> an enlightened <code>async</code> method that can participate in an <code>asyncio</code> event loop.</p>
<p>So, in order to transition from a synchronous callback to an asynchronous one, we can use the current event loop’s <code>create_task()</code> routine to enqueue an <code>async</code> method for execution.</p>
<section id="step-1-have-generate-enqueue-an-async-generate_response." class="level4">
<h4 class="anchored" data-anchor-id="step-1-have-generate-enqueue-an-async-generate_response.">Step 1: Have generate() enqueue an async generate_response().</h4>
<p>Thus, our <code>Gpt2App.generate()</code> call will look something like this:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Gpt2App(HttpApp):</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">@route</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> generate(<span class="va">self</span>, request: Request,</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>                 <span class="op">*</span>args: List,</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>                 <span class="op">**</span>kwds: Dict) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract the "prompt" provided in the incoming request.</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> args[<span class="dv">0</span>]</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Obtain the event loop and schedule the response</span></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># generation via our async generation coroutine.</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We have to do it like this as at this point we're</span></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># still within the call frame of the data_received()</span></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># protocol callback, which isn't an async function.</span></span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>        loop <span class="op">=</span> asyncio.get_running_loop()</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>        async_task <span class="op">=</span> <span class="va">self</span>.generate_response(request, text, <span class="op">**</span>kwds)</span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>        loop.create_task(async_task)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="step-2-implement-an-async-generate_response" class="level4">
<h4 class="anchored" data-anchor-id="step-2-implement-an-async-generate_response">Step 2: Implement an async generate_response()</h4>
<p>Our asynchronous <code>generate_response()</code> routine will be the bridge between generating tokens from the model, and sending those tokens back to the client via chunked-encoding.</p>
<p>It is responsible for preparing the response to use chunked-encoding, and then enabling <code>TCP_NODELAY</code> on the socket.</p>
<p>Then, assuming that our model has an <code>async_generate_for()</code> routine, which we’ll implement in the next step, we perform an <code>async for</code> loop over that routine in order to obtain individual <em>decoded</em> tokens. As soon as we receive a token, we can send it back to the client via the <code>response</code> object’s <code>send_chunk()</code> routine.</p>
<p>Once we’ve exhausted the async generator (i.e.&nbsp;it either generated the maximum number of requested tokens, or it encountered a stop token), we can re-enable <code>TCP_NODELAY</code>, and then return.</p>
<p>A simplified version of the Python code is presented below. I have omitted most of the error handling and query parameter parsing code for simplicity; see the expandable code block at the end for the full version.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Gpt2App(HttpApp):</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">async</span> <span class="kw">def</span> generate_response(</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, request: Request,</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>        prompt: <span class="bu">str</span>,</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>kwds: Dict</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prepare a chunked-encoding response.</span></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> request.response</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>        response.code <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>        response.message <span class="op">=</span> <span class="st">'OK'</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>        response.chunked_response <span class="op">=</span> <span class="va">True</span></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>        response.content_type <span class="op">=</span> <span class="st">'text/plain'</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Obtain the model.</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> get_model()</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We want to enable TCP_NODELAY for the duration of</span></span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the response.  This ensures packets are sent</span></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># immediately without any internal buffering.</span></span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>            response.enable_tcp_nodelay()</span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>            enabled_nodelay <span class="op">=</span> <span class="va">True</span></span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a>            logging.error(<span class="ss">f'Error enabling TCP_NODELAY: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a>            enabled_nodelay <span class="op">=</span> <span class="va">False</span></span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Write the chunked header immediately.</span></span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>        response_bytes <span class="op">=</span> <span class="bu">bytes</span>(response)</span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="va">self</span>.write(response_bytes):</span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Encountered a disconnect, return.</span></span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># N.B. From herein, all data must be transferred to</span></span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a>        <span class="co">#      the client via chunked encoding with the</span></span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a>        <span class="co">#      `response.send_chunk()` routine.</span></span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Send the initial prompt text.</span></span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a>        response.send_chunk(prompt)</span>
<span id="cb42-44"><a href="#cb42-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-45"><a href="#cb42-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Obtain decoded tokens from the model one at a time</span></span>
<span id="cb42-46"><a href="#cb42-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># via an `async for` loop, sending the token back to</span></span>
<span id="cb42-47"><a href="#cb42-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the client as soon as it's available.</span></span>
<span id="cb42-48"><a href="#cb42-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">async</span> <span class="cf">for</span> decoded_token <span class="kw">in</span> model.generate_async_for(prompt):</span>
<span id="cb42-49"><a href="#cb42-49" aria-hidden="true" tabindex="-1"></a>            response.send_chunk(decoded_token)</span>
<span id="cb42-50"><a href="#cb42-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-51"><a href="#cb42-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Terminate the chunked-encoding response.</span></span>
<span id="cb42-52"><a href="#cb42-52" aria-hidden="true" tabindex="-1"></a>        response.end_chunks()</span>
<span id="cb42-53"><a href="#cb42-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-54"><a href="#cb42-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Disable TCP_NODELAY now that the response is complete.</span></span>
<span id="cb42-55"><a href="#cb42-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The reasoning behind this is that the client may have</span></span>
<span id="cb42-56"><a href="#cb42-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># issued the HTTP request with a keep-alive header, and</span></span>
<span id="cb42-57"><a href="#cb42-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># plans on reusing this connection for a different request</span></span>
<span id="cb42-58"><a href="#cb42-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># next, which won't necessarily want `TCP_NODELAY` active.</span></span>
<span id="cb42-59"><a href="#cb42-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> enabled_nodelay:</span>
<span id="cb42-60"><a href="#cb42-60" aria-hidden="true" tabindex="-1"></a>            response.disable_tcp_nodelay()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="gpt2app-generate-response-full" class="callout callout-style-simple callout-note no-icon callout-titled" title="Full Code for async Gpt2App.generate_response()">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Full Code for async Gpt2App.generate_response()
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The actual code has more robust error-handling facilities and support for extracting the query string parameters from the incoming request URI and converting them into keyword arguments suitable for passing to the model.</p>
<p>Additionally, we haven’t touched on how we initialize or obtain instances of our models yet, so the model-related code won’t make much sense until later in the article.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Gpt2App(HttpApp):</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    routes <span class="op">=</span> make_routes()</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>    route <span class="op">=</span> router(routes)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, server: HttpServer) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(server)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.printable <span class="op">=</span> PRINTABLE</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> is_connected(<span class="va">self</span>):</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># server.transport will be severed when the client</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># disconnects, so we can use this to determine if</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the client is still connected.</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>        server <span class="op">=</span> <span class="va">self</span>.server</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>        transport <span class="op">=</span> <span class="va">None</span></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>            transport <span class="op">=</span> server.transport</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">AttributeError</span>:</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">pass</span></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> transport <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> write(<span class="va">self</span>, response_bytes):</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>        server <span class="op">=</span> <span class="va">self</span>.server</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>        transport <span class="op">=</span> <span class="va">None</span></span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>            transport <span class="op">=</span> server.transport</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">AttributeError</span>:</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">pass</span></span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> transport <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>            transport.write(response_bytes)</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">async</span> <span class="kw">def</span> generate_response(</span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, request: Request, prompt: <span class="bu">str</span>, <span class="op">**</span>kwds: Dict</span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> request.response</span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a>        response.code <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a>        response.message <span class="op">=</span> <span class="st">'OK'</span></span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a>        response.chunked_response <span class="op">=</span> <span class="va">True</span></span>
<span id="cb43-44"><a href="#cb43-44" aria-hidden="true" tabindex="-1"></a>        response.content_type <span class="op">=</span> <span class="st">'text/plain'</span></span>
<span id="cb43-45"><a href="#cb43-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-46"><a href="#cb43-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> kwds <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb43-47"><a href="#cb43-47" aria-hidden="true" tabindex="-1"></a>            kwds <span class="op">=</span> {}</span>
<span id="cb43-48"><a href="#cb43-48" aria-hidden="true" tabindex="-1"></a>        max_length <span class="op">=</span> <span class="bu">min</span>(<span class="bu">int</span>(kwds.get(<span class="st">'max_length'</span>, <span class="dv">100</span>) <span class="kw">or</span> <span class="dv">100</span>), <span class="dv">1024</span>)</span>
<span id="cb43-49"><a href="#cb43-49" aria-hidden="true" tabindex="-1"></a>        top_k <span class="op">=</span> <span class="bu">min</span>(<span class="bu">int</span>(kwds.get(<span class="st">'top_k'</span>, <span class="dv">50</span>) <span class="kw">or</span> <span class="dv">50</span>), <span class="dv">50</span>)</span>
<span id="cb43-50"><a href="#cb43-50" aria-hidden="true" tabindex="-1"></a>        seed <span class="op">=</span> kwds.get(<span class="st">'seed'</span>, <span class="va">None</span>)</span>
<span id="cb43-51"><a href="#cb43-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> seed:</span>
<span id="cb43-52"><a href="#cb43-52" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb43-53"><a href="#cb43-53" aria-hidden="true" tabindex="-1"></a>                seed <span class="op">=</span> <span class="bu">int</span>(seed)</span>
<span id="cb43-54"><a href="#cb43-54" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span> <span class="pp">ValueError</span>:</span>
<span id="cb43-55"><a href="#cb43-55" aria-hidden="true" tabindex="-1"></a>                seed <span class="op">=</span> <span class="va">None</span></span>
<span id="cb43-56"><a href="#cb43-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> seed:</span>
<span id="cb43-57"><a href="#cb43-57" aria-hidden="true" tabindex="-1"></a>            seed <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="dv">2</span><span class="op">**</span><span class="dv">32</span> <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb43-58"><a href="#cb43-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-59"><a href="#cb43-59" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> kwds.get(<span class="st">'device'</span>, <span class="va">None</span>)</span>
<span id="cb43-60"><a href="#cb43-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-61"><a href="#cb43-61" aria-hidden="true" tabindex="-1"></a>        model_name <span class="op">=</span> kwds.get(<span class="st">'model'</span>, <span class="va">None</span>)</span>
<span id="cb43-62"><a href="#cb43-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model_name <span class="op">==</span> <span class="st">'gpt2-xl'</span>:</span>
<span id="cb43-63"><a href="#cb43-63" aria-hidden="true" tabindex="-1"></a>            models <span class="op">=</span> PRETRAINED_MODELS</span>
<span id="cb43-64"><a href="#cb43-64" aria-hidden="true" tabindex="-1"></a>            get_next <span class="op">=</span> get_next_pretrained_model</span>
<span id="cb43-65"><a href="#cb43-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb43-66"><a href="#cb43-66" aria-hidden="true" tabindex="-1"></a>            model_name <span class="op">=</span> <span class="st">'gpt2'</span></span>
<span id="cb43-67"><a href="#cb43-67" aria-hidden="true" tabindex="-1"></a>            models <span class="op">=</span> MODELS</span>
<span id="cb43-68"><a href="#cb43-68" aria-hidden="true" tabindex="-1"></a>            get_next <span class="op">=</span> get_next_model</span>
<span id="cb43-69"><a href="#cb43-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-70"><a href="#cb43-70" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> <span class="va">None</span></span>
<span id="cb43-71"><a href="#cb43-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> device <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb43-72"><a href="#cb43-72" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> device <span class="op">==</span> <span class="st">'cpu'</span>:</span>
<span id="cb43-73"><a href="#cb43-73" aria-hidden="true" tabindex="-1"></a>                model <span class="op">=</span> models[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb43-74"><a href="#cb43-74" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> device.startswith(<span class="st">'cuda:'</span>):</span>
<span id="cb43-75"><a href="#cb43-75" aria-hidden="true" tabindex="-1"></a>                <span class="cf">try</span>:</span>
<span id="cb43-76"><a href="#cb43-76" aria-hidden="true" tabindex="-1"></a>                    index <span class="op">=</span> <span class="bu">int</span>(device[<span class="dv">5</span>:])</span>
<span id="cb43-77"><a href="#cb43-77" aria-hidden="true" tabindex="-1"></a>                <span class="cf">except</span> <span class="pp">ValueError</span>:</span>
<span id="cb43-78"><a href="#cb43-78" aria-hidden="true" tabindex="-1"></a>                    index <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb43-79"><a href="#cb43-79" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> index <span class="op">&lt;</span> <span class="dv">0</span> <span class="kw">or</span> index <span class="op">&gt;=</span> NUM_GPUS:</span>
<span id="cb43-80"><a href="#cb43-80" aria-hidden="true" tabindex="-1"></a>                    index <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb43-81"><a href="#cb43-81" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> index <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb43-82"><a href="#cb43-82" aria-hidden="true" tabindex="-1"></a>                    model <span class="op">=</span> models[index]</span>
<span id="cb43-83"><a href="#cb43-83" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> device <span class="op">==</span> <span class="st">'cuda'</span>:</span>
<span id="cb43-84"><a href="#cb43-84" aria-hidden="true" tabindex="-1"></a>                model <span class="op">=</span> models[random.randint(<span class="dv">0</span>, NUM_GPUS <span class="op">-</span> <span class="dv">1</span>)]</span>
<span id="cb43-85"><a href="#cb43-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-86"><a href="#cb43-86" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> model:</span>
<span id="cb43-87"><a href="#cb43-87" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get a model.  If there are multiple models available, e.g. if we</span></span>
<span id="cb43-88"><a href="#cb43-88" aria-hidden="true" tabindex="-1"></a>            <span class="co"># have multiple GPUs, this will balance the load a bit.</span></span>
<span id="cb43-89"><a href="#cb43-89" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> get_next()</span>
<span id="cb43-90"><a href="#cb43-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-91"><a href="#cb43-91" aria-hidden="true" tabindex="-1"></a>        expose_headers <span class="op">=</span> (</span>
<span id="cb43-92"><a href="#cb43-92" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Access-Control-Expose-Headers: '</span></span>
<span id="cb43-93"><a href="#cb43-93" aria-hidden="true" tabindex="-1"></a>            <span class="st">'X-Max-Length, '</span></span>
<span id="cb43-94"><a href="#cb43-94" aria-hidden="true" tabindex="-1"></a>            <span class="st">'X-Top-K, '</span></span>
<span id="cb43-95"><a href="#cb43-95" aria-hidden="true" tabindex="-1"></a>            <span class="st">'X-Seed, '</span></span>
<span id="cb43-96"><a href="#cb43-96" aria-hidden="true" tabindex="-1"></a>            <span class="st">'X-Model-Name, '</span></span>
<span id="cb43-97"><a href="#cb43-97" aria-hidden="true" tabindex="-1"></a>            <span class="st">'X-Model-Device'</span></span>
<span id="cb43-98"><a href="#cb43-98" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb43-99"><a href="#cb43-99" aria-hidden="true" tabindex="-1"></a>        response.other_headers.extend([</span>
<span id="cb43-100"><a href="#cb43-100" aria-hidden="true" tabindex="-1"></a>            expose_headers,</span>
<span id="cb43-101"><a href="#cb43-101" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'X-Max-Length: </span><span class="sc">{</span>max_length<span class="sc">}</span><span class="ss">'</span>,</span>
<span id="cb43-102"><a href="#cb43-102" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'X-Top-K: </span><span class="sc">{</span>top_k<span class="sc">}</span><span class="ss">'</span>,</span>
<span id="cb43-103"><a href="#cb43-103" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'X-Seed: </span><span class="sc">{</span>seed<span class="sc">}</span><span class="ss">'</span>,</span>
<span id="cb43-104"><a href="#cb43-104" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'X-Model-Name: </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">'</span>,</span>
<span id="cb43-105"><a href="#cb43-105" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'X-Model-Device: </span><span class="sc">{</span>model<span class="sc">.</span>device<span class="sc">}</span><span class="ss">'</span>,</span>
<span id="cb43-106"><a href="#cb43-106" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb43-107"><a href="#cb43-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-108"><a href="#cb43-108" aria-hidden="true" tabindex="-1"></a>        <span class="co"># We want to enable TCP_NODELAY for the duration of</span></span>
<span id="cb43-109"><a href="#cb43-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the response.  This ensures packets are sent</span></span>
<span id="cb43-110"><a href="#cb43-110" aria-hidden="true" tabindex="-1"></a>        <span class="co"># immediately without any internal buffering.</span></span>
<span id="cb43-111"><a href="#cb43-111" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb43-112"><a href="#cb43-112" aria-hidden="true" tabindex="-1"></a>            response.enable_tcp_nodelay()</span>
<span id="cb43-113"><a href="#cb43-113" aria-hidden="true" tabindex="-1"></a>            enabled_nodelay <span class="op">=</span> <span class="va">True</span></span>
<span id="cb43-114"><a href="#cb43-114" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb43-115"><a href="#cb43-115" aria-hidden="true" tabindex="-1"></a>            logging.error(<span class="ss">f'Error enabling TCP_NODELAY: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb43-116"><a href="#cb43-116" aria-hidden="true" tabindex="-1"></a>            enabled_nodelay <span class="op">=</span> <span class="va">False</span></span>
<span id="cb43-117"><a href="#cb43-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-118"><a href="#cb43-118" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Write the chunked header immediately.</span></span>
<span id="cb43-119"><a href="#cb43-119" aria-hidden="true" tabindex="-1"></a>        response_bytes <span class="op">=</span> <span class="bu">bytes</span>(response)</span>
<span id="cb43-120"><a href="#cb43-120" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="va">self</span>.write(response_bytes):</span>
<span id="cb43-121"><a href="#cb43-121" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Encountered a disconnect, return.</span></span>
<span id="cb43-122"><a href="#cb43-122" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb43-123"><a href="#cb43-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-124"><a href="#cb43-124" aria-hidden="true" tabindex="-1"></a>        <span class="co"># N.B. From herein, all data must be transferred to</span></span>
<span id="cb43-125"><a href="#cb43-125" aria-hidden="true" tabindex="-1"></a>        <span class="co">#      the client via chunked encoding with the</span></span>
<span id="cb43-126"><a href="#cb43-126" aria-hidden="true" tabindex="-1"></a>        <span class="co">#      `response.send_chunk()` routine.</span></span>
<span id="cb43-127"><a href="#cb43-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-128"><a href="#cb43-128" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Send the initial prompt text.</span></span>
<span id="cb43-129"><a href="#cb43-129" aria-hidden="true" tabindex="-1"></a>        response.send_chunk(prompt)</span>
<span id="cb43-130"><a href="#cb43-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-131"><a href="#cb43-131" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Obtain an async generator instance to the model's</span></span>
<span id="cb43-132"><a href="#cb43-132" aria-hidden="true" tabindex="-1"></a>        <span class="co"># new async token generation routine.</span></span>
<span id="cb43-133"><a href="#cb43-133" aria-hidden="true" tabindex="-1"></a>        generate_tokens <span class="op">=</span> model.generate_async_for(</span>
<span id="cb43-134"><a href="#cb43-134" aria-hidden="true" tabindex="-1"></a>            prompt,</span>
<span id="cb43-135"><a href="#cb43-135" aria-hidden="true" tabindex="-1"></a>            max_length<span class="op">=</span>max_length,</span>
<span id="cb43-136"><a href="#cb43-136" aria-hidden="true" tabindex="-1"></a>            top_k<span class="op">=</span>top_k,</span>
<span id="cb43-137"><a href="#cb43-137" aria-hidden="true" tabindex="-1"></a>            seed<span class="op">=</span>seed,</span>
<span id="cb43-138"><a href="#cb43-138" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb43-139"><a href="#cb43-139" aria-hidden="true" tabindex="-1"></a>        <span class="cf">async</span> <span class="cf">for</span> decoded_token <span class="kw">in</span> generate_tokens:</span>
<span id="cb43-140"><a href="#cb43-140" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> decoded_token <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb43-141"><a href="#cb43-141" aria-hidden="true" tabindex="-1"></a>                <span class="co"># A non-printable token was generated,</span></span>
<span id="cb43-142"><a href="#cb43-142" aria-hidden="true" tabindex="-1"></a>                <span class="co"># terminating generation.</span></span>
<span id="cb43-143"><a href="#cb43-143" aria-hidden="true" tabindex="-1"></a>                response.send_chunk(</span>
<span id="cb43-144"><a href="#cb43-144" aria-hidden="true" tabindex="-1"></a>                    OOPS_NON_PRINTABLE_ENCOUNTERED</span>
<span id="cb43-145"><a href="#cb43-145" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb43-146"><a href="#cb43-146" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb43-147"><a href="#cb43-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-148"><a href="#cb43-148" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the client has forcibly disconnected,</span></span>
<span id="cb43-149"><a href="#cb43-149" aria-hidden="true" tabindex="-1"></a>            <span class="co"># terminate generation.</span></span>
<span id="cb43-150"><a href="#cb43-150" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> <span class="va">self</span>.is_connected():</span>
<span id="cb43-151"><a href="#cb43-151" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb43-152"><a href="#cb43-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-153"><a href="#cb43-153" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Otherwise, send the decoded token to the client</span></span>
<span id="cb43-154"><a href="#cb43-154" aria-hidden="true" tabindex="-1"></a>            <span class="co"># via chunked encoding.</span></span>
<span id="cb43-155"><a href="#cb43-155" aria-hidden="true" tabindex="-1"></a>            response.send_chunk(decoded_token)</span>
<span id="cb43-156"><a href="#cb43-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-157"><a href="#cb43-157" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Send the termination chunk.  This may fail at the</span></span>
<span id="cb43-158"><a href="#cb43-158" aria-hidden="true" tabindex="-1"></a>        <span class="co"># socket.send() level if the client has already</span></span>
<span id="cb43-159"><a href="#cb43-159" aria-hidden="true" tabindex="-1"></a>        <span class="co"># disconnected, which is harmless.</span></span>
<span id="cb43-160"><a href="#cb43-160" aria-hidden="true" tabindex="-1"></a>        response.end_chunks()</span>
<span id="cb43-161"><a href="#cb43-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-162"><a href="#cb43-162" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Disable TCP_NODELAY now that the response is complete.</span></span>
<span id="cb43-163"><a href="#cb43-163" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Again, this may fail at the socket level if the client</span></span>
<span id="cb43-164"><a href="#cb43-164" aria-hidden="true" tabindex="-1"></a>        <span class="co"># has already disconnected, which is harmless.</span></span>
<span id="cb43-165"><a href="#cb43-165" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> enabled_nodelay:</span>
<span id="cb43-166"><a href="#cb43-166" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb43-167"><a href="#cb43-167" aria-hidden="true" tabindex="-1"></a>                response.disable_tcp_nodelay()</span>
<span id="cb43-168"><a href="#cb43-168" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb43-169"><a href="#cb43-169" aria-hidden="true" tabindex="-1"></a>                msg <span class="op">=</span> <span class="ss">f'Error disabling TCP_NODELAY: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb43-170"><a href="#cb43-170" aria-hidden="true" tabindex="-1"></a>                logging.error(msg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="step-3-implement-an-async-gpt.async_generate_for" class="level4">
<h4 class="anchored" data-anchor-id="step-3-implement-an-async-gpt.async_generate_for">Step 3: Implement an async GPT.async_generate_for()</h4>
<p>In the code example above, we assumed the <code>GPT</code> model we’ve been using had grown a new <code>async</code> routine named <code>async_generate_for()</code>, which we’ll cover now.</p>
<p>This routine is essentially an <code>asyncio</code>-friendly version of the original <code>generate()</code> routine we wrote. It shares a lot of the same code, with a few notable tweaks in order to support the fact that it is being called from a callback that was enqueued on a thread’s <code>asyncio</code> event loop, and it is expected to yield a token as soon as it is available, and then pass control back to the event loop in order for it to service other clients before it continues with generating the next token.</p>
<p>It also has the notion of checking for <em>“printable”</em> characters. This came about when I was initially testing this code via <code>curl</code> which would sometimes balk and exit in the middle of streaming the response, citing that it encountered corrupted data or something like that.</p>
<p>After investigation, it turned out that sometimes, for whatever reason, the model just generates a junk, nonsensical token (like 65534, which is well outside the highest token number of 50384). I have no idea why it happens, although I’ll note it happens on the OpenAI GPT2 XL model available on HuggingFace (which we’ll discuss later) too, so, eh.</p>
<p>I deal with this by checking if we’ve generated a non-printable token after decoding it, and, if so, return -1 and terminate the loop. The <a href="#gpt2app-generate-response-full">full version</a> of the <code>Gpt2App.generate_response()</code> routine that we introduced above checks if we return -1, and if so, terminates generation with an oopsie message, e.g.:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>OOPS_NON_PRINTABLE_ENCOUNTERED <span class="op">=</span> (</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Oops! Non-printable token encountered.  Generation terminated.'</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="cf">async</span> <span class="cf">for</span> decoded_token <span class="kw">in</span> generate_tokens:</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> decoded_token <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># A non-printable token was generated,</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># terminating generation.</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>        response.send_chunk(</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>            OOPS_NON_PRINTABLE_ENCOUNTERED</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>After yielding a valid decoded token, we issue an <code>await asyncio.sleep(0)</code> call, which returns control back to the event loop for it to potentially handle other concurrent clients. If there are no other clients, or after it has handled all other enqueued work, generation resumes.</p>
<p>The full code follows, it is simple enough as-is that I didn’t feel the need to omit any details like in the prior example.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GPT:</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">async</span> <span class="kw">def</span> generate_async_for(</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, text: <span class="bu">str</span>, max_length: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1024</span>, top_k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">50</span>,</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>        seed: <span class="bu">int</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a><span class="co">        Asynchronously generate text from the model, yielding tokens</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="co">        one at a time as soon as they are available.</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a><span class="co">            text (str): Supplies the prompt.</span></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a><span class="co">            max_length (int): Supplies the maximum total length,</span></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a><span class="co">                including prompt.</span></span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a><span class="co">            top_k (int): Supplies the number of tokens to consider</span></span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a><span class="co">                at each generation step.</span></span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a><span class="co">            seed (int): Optionally supplies the manual seed to use</span></span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a><span class="co">                for the generator.  If None, the model's manual</span></span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a><span class="co">                seed will be used.</span></span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a><span class="co">            str: The generated text (including the initial prompt).</span></span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a><span class="co">        Yields:</span></span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a><span class="co">            byte: The newly generated decoded token.  If -1, a</span></span>
<span id="cb45-35"><a href="#cb45-35" aria-hidden="true" tabindex="-1"></a><span class="co">            non-printable token was generated, and generation</span></span>
<span id="cb45-36"><a href="#cb45-36" aria-hidden="true" tabindex="-1"></a><span class="co">            was terminated.</span></span>
<span id="cb45-37"><a href="#cb45-37" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb45-38"><a href="#cb45-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-39"><a href="#cb45-39" aria-hidden="true" tabindex="-1"></a>        enc <span class="op">=</span> <span class="va">self</span>.enc</span>
<span id="cb45-40"><a href="#cb45-40" aria-hidden="true" tabindex="-1"></a>        stop_token <span class="op">=</span> <span class="va">self</span>.stop_token</span>
<span id="cb45-41"><a href="#cb45-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-42"><a href="#cb45-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode the prompt -&gt; tensor of shape (1, T)</span></span>
<span id="cb45-43"><a href="#cb45-43" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> enc.encode(text)</span>
<span id="cb45-44"><a href="#cb45-44" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.tensor(</span>
<span id="cb45-45"><a href="#cb45-45" aria-hidden="true" tabindex="-1"></a>            tokens, dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span><span class="va">self</span>.device</span>
<span id="cb45-46"><a href="#cb45-46" aria-hidden="true" tabindex="-1"></a>        ).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb45-47"><a href="#cb45-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-48"><a href="#cb45-48" aria-hidden="true" tabindex="-1"></a>        sample_rng <span class="op">=</span> torch.Generator(device<span class="op">=</span><span class="va">self</span>.device)</span>
<span id="cb45-49"><a href="#cb45-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> seed <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb45-50"><a href="#cb45-50" aria-hidden="true" tabindex="-1"></a>            seed <span class="op">=</span> <span class="va">self</span>.manual_seed</span>
<span id="cb45-51"><a href="#cb45-51" aria-hidden="true" tabindex="-1"></a>        sample_rng.manual_seed(seed)</span>
<span id="cb45-52"><a href="#cb45-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-53"><a href="#cb45-53" aria-hidden="true" tabindex="-1"></a>        logging.debug(</span>
<span id="cb45-54"><a href="#cb45-54" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'[generate_async_for] Starting generation loop for </span><span class="sc">{</span>text<span class="sc">}</span><span class="ss"> '</span></span>
<span id="cb45-55"><a href="#cb45-55" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'with seed </span><span class="sc">{</span>seed<span class="sc">}</span><span class="ss">.'</span></span>
<span id="cb45-56"><a href="#cb45-56" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb45-57"><a href="#cb45-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-58"><a href="#cb45-58" aria-hidden="true" tabindex="-1"></a>        start_time <span class="op">=</span> time.perf_counter()</span>
<span id="cb45-59"><a href="#cb45-59" aria-hidden="true" tabindex="-1"></a>        count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb45-60"><a href="#cb45-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> x.size(<span class="dv">1</span>) <span class="op">&lt;</span> max_length:</span>
<span id="cb45-61"><a href="#cb45-61" aria-hidden="true" tabindex="-1"></a>            count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb45-62"><a href="#cb45-62" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb45-63"><a href="#cb45-63" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Forward pass, ignoring the returned loss.</span></span>
<span id="cb45-64"><a href="#cb45-64" aria-hidden="true" tabindex="-1"></a>                (logits, _) <span class="op">=</span> <span class="va">self</span>(x)</span>
<span id="cb45-65"><a href="#cb45-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-66"><a href="#cb45-66" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Take the logits at the last time-step (shape:</span></span>
<span id="cb45-67"><a href="#cb45-67" aria-hidden="true" tabindex="-1"></a>            <span class="co"># (1, vocab_size)).</span></span>
<span id="cb45-68"><a href="#cb45-68" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> logits[:, <span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb45-69"><a href="#cb45-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-70"><a href="#cb45-70" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Convert to probabilities.</span></span>
<span id="cb45-71"><a href="#cb45-71" aria-hidden="true" tabindex="-1"></a>            probs <span class="op">=</span> F.softmax(logits, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb45-72"><a href="#cb45-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-73"><a href="#cb45-73" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Top-k sampling.</span></span>
<span id="cb45-74"><a href="#cb45-74" aria-hidden="true" tabindex="-1"></a>            topk_probs, topk_indices <span class="op">=</span> torch.topk(</span>
<span id="cb45-75"><a href="#cb45-75" aria-hidden="true" tabindex="-1"></a>                probs, k<span class="op">=</span>top_k, dim<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb45-76"><a href="#cb45-76" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb45-77"><a href="#cb45-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-78"><a href="#cb45-78" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Sample the next token.</span></span>
<span id="cb45-79"><a href="#cb45-79" aria-hidden="true" tabindex="-1"></a>            next_idx <span class="op">=</span> torch.multinomial(</span>
<span id="cb45-80"><a href="#cb45-80" aria-hidden="true" tabindex="-1"></a>                topk_probs,</span>
<span id="cb45-81"><a href="#cb45-81" aria-hidden="true" tabindex="-1"></a>                num_samples<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb45-82"><a href="#cb45-82" aria-hidden="true" tabindex="-1"></a>                generator<span class="op">=</span>sample_rng,</span>
<span id="cb45-83"><a href="#cb45-83" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb45-84"><a href="#cb45-84" aria-hidden="true" tabindex="-1"></a>            next_token <span class="op">=</span> torch.gather(topk_indices, <span class="op">-</span><span class="dv">1</span>, next_idx)</span>
<span id="cb45-85"><a href="#cb45-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-86"><a href="#cb45-86" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the next token is the stop token, we're done.</span></span>
<span id="cb45-87"><a href="#cb45-87" aria-hidden="true" tabindex="-1"></a>            next_token_item <span class="op">=</span> next_token.item()</span>
<span id="cb45-88"><a href="#cb45-88" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> next_token_item <span class="op">==</span> stop_token:</span>
<span id="cb45-89"><a href="#cb45-89" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb45-90"><a href="#cb45-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-91"><a href="#cb45-91" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Append token to current sequence.  Although we only</span></span>
<span id="cb45-92"><a href="#cb45-92" aria-hidden="true" tabindex="-1"></a>            <span class="co"># yield a singular decoded token below, we still need</span></span>
<span id="cb45-93"><a href="#cb45-93" aria-hidden="true" tabindex="-1"></a>            <span class="co"># to keep track of the entire sequence for subsequent</span></span>
<span id="cb45-94"><a href="#cb45-94" aria-hidden="true" tabindex="-1"></a>            <span class="co"># generation steps.</span></span>
<span id="cb45-95"><a href="#cb45-95" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> torch.cat((x, next_token), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb45-96"><a href="#cb45-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-97"><a href="#cb45-97" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Decode the newly-generated token.  Note that a single</span></span>
<span id="cb45-98"><a href="#cb45-98" aria-hidden="true" tabindex="-1"></a>            <span class="co"># token will often be decoded to multiple characters.</span></span>
<span id="cb45-99"><a href="#cb45-99" aria-hidden="true" tabindex="-1"></a>            new_text_fragment <span class="op">=</span> enc.decode([next_token.item()])</span>
<span id="cb45-100"><a href="#cb45-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-101"><a href="#cb45-101" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If any of the characters in the decoded text</span></span>
<span id="cb45-102"><a href="#cb45-102" aria-hidden="true" tabindex="-1"></a>            <span class="co"># representation aren't printable, terminate</span></span>
<span id="cb45-103"><a href="#cb45-103" aria-hidden="true" tabindex="-1"></a>            <span class="co"># generation.</span></span>
<span id="cb45-104"><a href="#cb45-104" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> <span class="bu">all</span>(c <span class="kw">in</span> <span class="va">self</span>.printable <span class="cf">for</span> c <span class="kw">in</span> new_text_fragment):</span>
<span id="cb45-105"><a href="#cb45-105" aria-hidden="true" tabindex="-1"></a>                <span class="cf">yield</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb45-106"><a href="#cb45-106" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb45-107"><a href="#cb45-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-108"><a href="#cb45-108" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> new_text_fragment</span>
<span id="cb45-109"><a href="#cb45-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-110"><a href="#cb45-110" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Yield control back to the event loop before continuing</span></span>
<span id="cb45-111"><a href="#cb45-111" aria-hidden="true" tabindex="-1"></a>            <span class="co"># generation.  If we didn't do this, this client would</span></span>
<span id="cb45-112"><a href="#cb45-112" aria-hidden="true" tabindex="-1"></a>            <span class="co"># hog the thread's event loop, preventing other clients</span></span>
<span id="cb45-113"><a href="#cb45-113" aria-hidden="true" tabindex="-1"></a>            <span class="co"># associated with the loop from getting services.  (As</span></span>
<span id="cb45-114"><a href="#cb45-114" aria-hidden="true" tabindex="-1"></a>            <span class="co"># we're now running multiple threads in parallel, other</span></span>
<span id="cb45-115"><a href="#cb45-115" aria-hidden="true" tabindex="-1"></a>            <span class="co"># clients associated with event loops on other threads</span></span>
<span id="cb45-116"><a href="#cb45-116" aria-hidden="true" tabindex="-1"></a>            <span class="co"># would not be impacted.)</span></span>
<span id="cb45-117"><a href="#cb45-117" aria-hidden="true" tabindex="-1"></a>            <span class="cf">await</span> asyncio.sleep(<span class="dv">0</span>)</span>
<span id="cb45-118"><a href="#cb45-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-119"><a href="#cb45-119" aria-hidden="true" tabindex="-1"></a>        elapsed <span class="op">=</span> time.perf_counter() <span class="op">-</span> start_time</span>
<span id="cb45-120"><a href="#cb45-120" aria-hidden="true" tabindex="-1"></a>        logging.debug(</span>
<span id="cb45-121"><a href="#cb45-121" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"[generate_async_for] Generated </span><span class="sc">{</span>count<span class="sc">}</span><span class="ss"> tokens in "</span></span>
<span id="cb45-122"><a href="#cb45-122" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"</span><span class="sc">{</span>elapsed<span class="sc">:.2f}</span><span class="ss"> seconds (~</span><span class="sc">{</span>count <span class="op">/</span> elapsed<span class="sc">:.2f}</span><span class="ss"> tok/s)"</span></span>
<span id="cb45-123"><a href="#cb45-123" aria-hidden="true" tabindex="-1"></a>        )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This routine was the last piece we needed to implement to satisfy <a href="#our-goals">our three goals</a> captured earlier, so, we’re now ready to test it out!</p>
</section>
</section>
</section>
<section id="test-drive" class="level2">
<h2 class="anchored" data-anchor-id="test-drive">Test Drive!</h2>
<p>We can launch an instance of our multi-threaded HTTP web server with our new <code>Gpt2App</code> HTTP application via the command line as follows:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="ex">%</span> %] python <span class="at">-Xgil</span><span class="op">=</span>0 <span class="at">-m</span> parallelopedia.http.server <span class="at">--threads</span> 40 <span class="at">--app-classes</span> parallelopedia.gpt2.Gpt2App <span class="at">--port</span> 4444</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="ex">Traceback</span> <span class="er">(</span><span class="ex">most</span> recent call last<span class="kw">)</span><span class="bu">:</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>  <span class="ex">File</span> <span class="st">"&lt;frozen runpy&gt;"</span>, line 198, in _run_module_as_main</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>  <span class="ex">File</span> <span class="st">"&lt;frozen runpy&gt;"</span>, line 88, in _run_code</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>  <span class="ex">File</span> <span class="st">"/mnt/raid1/trent/src/parallelopedia/src/parallelopedia/http/server.py"</span>, line 1478, in <span class="op">&lt;</span>module<span class="op">&gt;</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">main()</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>    <span class="ex">~~~~^^</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>  <span class="ex">File</span> <span class="st">"/mnt/raid1/trent/src/parallelopedia/src/parallelopedia/http/server.py"</span>, line 1457, in main</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>    <span class="ex">get_class_from_string</span><span class="er">(</span><span class="ex">app_class</span><span class="kw">)</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    <span class="ex">~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>  <span class="ex">File</span> <span class="st">"/mnt/raid1/trent/src/parallelopedia/src/parallelopedia/util.py"</span>, line 128, in get_class_from_string</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>    <span class="ex">module</span> = __import__<span class="er">(</span><span class="ex">module_name</span><span class="kw">)</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>  <span class="ex">File</span> <span class="st">"/mnt/raid1/trent/src/parallelopedia/src/parallelopedia/gpt2.py"</span>, line 407, in <span class="op">&lt;</span>module<span class="op">&gt;</span></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>    <span class="ex">class</span> GPT<span class="er">(</span><span class="ex">nn.Module</span><span class="kw">)</span><span class="bu">:</span></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>    <span class="ex">...</span><span class="op">&lt;</span>679 lines<span class="op">&gt;</span>...</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>            <span class="er">)</span></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>  <span class="ex">File</span> <span class="st">"/mnt/raid1/trent/src/parallelopedia/src/parallelopedia/gpt2.py"</span>, line 905, in GPT</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>    <span class="ex">@torch.compile</span></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>     <span class="ex">^^^^^^^^^^^^^</span></span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>  <span class="ex">File</span> <span class="st">"/home/trent/mambaforge/envs/py313t/lib/python3.13t/site-packages/torch/__init__.py"</span>, line 2526, in compile</span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>    <span class="ex">raise</span> RuntimeError<span class="er">(</span></span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"torch.compile is not supported on Python built with GIL disabled"</span></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">)</span></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a><span class="ex">RuntimeError:</span> torch.compile is not supported on Python built with GIL disabled</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!-- vim:set ts=8 sw=2 sts=2 expandtab textwidth=78 -->


</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>I used 0.23.3, as that was the latest version available at the time, however, 0.23.4 has since been released, so you could try that too.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>And I’m sure I used the existing Python stdlib <code>http.server</code> code at the time as the basis; ain’t nobody got time to be writing new web servers from scratch.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Unfortunately, it doesn’t appear to work on Windows as-is; using the exact same code, only one thread can be seen running when the server is loaded. It’s not doing a round-robin between <em>all</em> threads, like you’d expect to see with the GIL enabled, there’s just a single sole thread attempting to service all incoming requests, with all other threads sitting idle. I don’t know if it’s because of something quirky with regards to additional, non-main-thread threads not getting their own event loop (hopefully easy to fix), or something more insidious related to how we’re misuing I/O completion ports behind the scenes in <code>IocpProactor()</code> now that we have free-threading (much harder to fix). I haven’t had time to investigate in more detail.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = true;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/trent\.me");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="tpn/website" data-repo-id="MDEwOlJlcG9zaXRvcnkxMjg2ODc3NTQ=" data-category="Blog" data-category-id="" data-mapping="pathname" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="dark" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="dark">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/tpn/website/edit/main/blog/posts/2025-xx-xx-pytorch-and-python-free-threading/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/tpn/website/issues/new/choose" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>