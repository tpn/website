{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6790c6a-b45d-4e9b-87bb-ff03fa6ca06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: gpt2-v1-setup\n",
    "#| echo: true\n",
    "#| code-fold: true\n",
    "\n",
    "# gpt2_v1.ipynb\n",
    "\n",
    "# ===================================================================\n",
    "# Imports\n",
    "# ===================================================================\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import subprocess\n",
    "import sys\n",
    "from textwrap import wrap\n",
    "import time\n",
    "\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# ===================================================================\n",
    "# Helper Timer Class\n",
    "# ===================================================================\n",
    "class ElapsedTimer:\n",
    "    \"\"\"\n",
    "    Context manager and reusable timer to measure elapsed time.\n",
    "\n",
    "    Example:\n",
    "        timer = elapsed_timer()\n",
    "        with timer:\n",
    "            do_something()\n",
    "        print(f'Elapsed: {timer.elapsed:.3f}')\n",
    "\n",
    "        # Re-enterable:\n",
    "        with timer:\n",
    "            do_something_else()\n",
    "        print(f'Elapsed: {timer.elapsed:.3f}')\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.start = None\n",
    "        self._elapsed = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time.perf_counter()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self._elapsed = time.perf_counter() - self.start\n",
    "\n",
    "    @property\n",
    "    def elapsed(self):\n",
    "        \"\"\"\n",
    "        Return the elapsed time for the most recent context.\n",
    "        \"\"\"\n",
    "        if self._elapsed is None:\n",
    "            raise ValueError(\"Timer has not been used in a context yet.\")\n",
    "        return self._elapsed\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# Globals\n",
    "# ===================================================================\n",
    "\n",
    "LOG_LEVEL = 'DEBUG'\n",
    "PARALLELOPEDIA_ROOT = os.environ['PARALLELOPEDIA_ROOT']\n",
    "PARALLELOPEDIA_DATA_DIR = join(PARALLELOPEDIA_ROOT, 'data')\n",
    "MODEL_CHECKPOINT = join(\n",
    "    PARALLELOPEDIA_DATA_DIR,\n",
    "    'model_19072.pt',\n",
    ")\n",
    "MODEL_DOWNLOAD_URL = (\n",
    "    \"https://huggingface.co/datasets/trentnelson/\"\n",
    "    \"parallelopedia-data-gpt2/resolve/main/model_19072.pt\"\n",
    ")\n",
    "\n",
    "# Download the model from huggingface if necessary.\n",
    "os.makedirs(PARALLELOPEDIA_DATA_DIR, exist_ok=True)\n",
    "\n",
    "if not exists(MODEL_CHECKPOINT):\n",
    "    print(f'Downloading {MODEL_DOWNLOAD_URL} via wget '\n",
    "          'this might take a while...')\n",
    "    args = [\n",
    "        \"wget\",\n",
    "        \"--quiet\",\n",
    "        MODEL_DOWNLOAD_URL,\n",
    "        \"-P\",\n",
    "        PARALLELOPEDIA_DATA_DIR,\n",
    "    ]\n",
    "    timer = ElapsedTimer()\n",
    "    with timer:\n",
    "        subprocess.run(args, check=True)\n",
    "    print(f'Downloaded model in {timer.elapsed:.3f} seconds.')\n",
    "    \n",
    "assert exists(MODEL_CHECKPOINT), \"Missing checkpoint.\"\n",
    "\n",
    "# ===================================================================\n",
    "# Logging\n",
    "# ===================================================================\n",
    "# N.B. We redirect logs to sys.stdout in order for Quarto to pick\n",
    "#      them up and include them in rendering the output.\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, LOG_LEVEL),\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    stream=sys.stdout\n",
    ")\n",
    "\n",
    "# ===================================================================\n",
    "# Setup\n",
    "# ===================================================================\n",
    "\n",
    "# Use bfloat16 for matmul precision where possible.\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# ===================================================================\n",
    "# GPT2 PyTorch Model Components\n",
    "# ===================================================================\n",
    "\n",
    "# Now define the classes making up our GPT2 implementation.\n",
    "# These map directly to the components introduced by the\n",
    "# now-seminal 2017 \"Attention Is All You Need\" paper.\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Causal self-attention for the GPT2 model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # Key, query, value projections for all heads, but in a batch.\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "\n",
    "        # Output projection.\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "\n",
    "        # Regularization.\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Batch size, sequence length, embedding dimensionality.\n",
    "        B, T, C = (x.size())\n",
    "\n",
    "        # Calculate query, key, values for all heads in\n",
    "        # batch and move head forward to be the batch dim.\n",
    "        #\n",
    "        # N.B. nh is \"number of heads\", hs is \"head size\",\n",
    "        #      and C (number of channels) is nh * hs.\n",
    "        #      E.g. in GPT-2 (124M), n_head=12, hs=64, so\n",
    "        #      nh*hs=C=768 channels in the Transformer.\n",
    "        qkv = self.c_attn(x)\n",
    "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
    "\n",
    "        head_dim = C // self.n_head\n",
    "\n",
    "        # (B, nh, T, hs)\n",
    "        k = k.view(B, T, self.n_head, head_dim).transpose(1, 2)\n",
    "\n",
    "        # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, head_dim).transpose(1, 2)\n",
    "\n",
    "        # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, head_dim).transpose(1, 2)\n",
    "\n",
    "        # Flash attention.\n",
    "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
    "\n",
    "        # Re-assemble all head outputs side by side.\n",
    "        y = (y.transpose(1, 2).contiguous().view(B, T, C))\n",
    "\n",
    "        # Output projection.\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-layer perceptron for the GPT2 model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
    "        self.gelu = nn.GELU(approximate='tanh')\n",
    "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer block for the GPT2 model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "# ===================================================================\n",
    "# GPT2 Supporting Classes\n",
    "# ===================================================================\n",
    "\n",
    "# N.B. These differ slightly from Andrej's classes in\n",
    "#      `train_gpt2.py`.  `GPTCheckpoint` is a helper\n",
    "#      class I wrote that has no analog in the former.\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    \"\"\"\n",
    "    Configuration class for GPT model.\n",
    "\n",
    "    Attributes:\n",
    "\n",
    "        block_size (int): Maximum sequence length.\n",
    "\n",
    "        vocab_size (int): Number of tokens.  GPT2 from\n",
    "            huggingface has a vocab size of 50257, which\n",
    "            includes 50,000 BPE merges, 256 byte tokens,\n",
    "            and 1 <|endoftext|> token.  However, Andrej\n",
    "            Karpathy's `build-nanogpt/train_gpt2.py`\n",
    "            uses a vocab size of 50304.  I vaguely recall\n",
    "            the explanation for this discrepancy as a local\n",
    "            optimization to yield better alignment sizes,\n",
    "            but I'm not 100% certain.\n",
    "\n",
    "            The local GPT2 training that we did on\n",
    "            edu_fineweb10b used 50304, so we will use\n",
    "            that here.\n",
    "\n",
    "        n_layer (int): Number of layers.\n",
    "\n",
    "        n_head (int): Number of attention heads.\n",
    "\n",
    "        n_embd (int): Embedding dimension.\n",
    "    \"\"\"\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50304\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 768\n",
    "\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# GPT2 Model Implementation\n",
    "# ===================================================================\n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config, device):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.manual_seed = 42\n",
    "\n",
    "        self.transformer = nn.ModuleDict(\n",
    "            dict(\n",
    "                wte=nn.Embedding(config.vocab_size, config.n_embd),\n",
    "                wpe=nn.Embedding(config.block_size, config.n_embd),\n",
    "                h=nn.ModuleList(\n",
    "                    [Block(config) for _ in range(config.n_layer)]\n",
    "                ),\n",
    "                ln_f=nn.LayerNorm(config.n_embd),\n",
    "            )\n",
    "        )\n",
    "        self.lm_head = nn.Linear(\n",
    "            config.n_embd, config.vocab_size, bias=False\n",
    "        )\n",
    "\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            std = 0.02\n",
    "            if hasattr(module, \"NANOGPT_SCALE_INIT\"):\n",
    "                std *= (2 * self.config.n_layer) ** -0.5\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the GPT model.\n",
    "\n",
    "        Args:\n",
    "            idx (torch.Tensor): Supplies the input tensor of shape\n",
    "                (B, T).\n",
    "            targets (torch.Tensor): Optionally supplies the target\n",
    "                tensor of shape (B, T) for computing the loss.\n",
    "\n",
    "        \"\"\"\n",
    "        (B, T) = idx.size()\n",
    "\n",
    "        # Forward the token and position embeddings.\n",
    "\n",
    "        # Shape (T)\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device)\n",
    "\n",
    "        # Position embeddings of shape (T, n_embd).\n",
    "        pos_emb = self.transformer.wpe(pos)\n",
    "\n",
    "        # Token embeddings of shape (B, T, n_embd).\n",
    "        tok_emb = self.transformer.wte(idx)\n",
    "\n",
    "        x = tok_emb + pos_emb\n",
    "\n",
    "        # Forward the blocks of the transformer.\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "\n",
    "        # Forward the final layernorm and the classifier.\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        # (B, T, vocab_size)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(\n",
    "                logits.view(-1, logits.size(-1)), targets.view(-1)\n",
    "            )\n",
    "\n",
    "        return (logits, loss)\n",
    "\n",
    "    @classmethod\n",
    "    def from_local_pretrained(\n",
    "        cls, model_path: str, map_location: str = \"cuda\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Load a model from a local checkpoint.\n",
    "\n",
    "        N.B. This is a new method based off GPT.from_pretrained\n",
    "             in Andrej Karpathy's train_gpt2.py.\n",
    "\n",
    "        Args:\n",
    "            cls (type): Supplies the class type.\n",
    "\n",
    "            model_path (str): Supplies the path to the model\n",
    "                checkpoint.\n",
    "\n",
    "            map_location (str): Supplies the device to which\n",
    "                the model will be mapped.\n",
    "        \"\"\"\n",
    "        with torch.serialization.safe_globals([GPTConfig]):\n",
    "            checkpoint = torch.load(\n",
    "                model_path,\n",
    "                map_location=map_location,\n",
    "            )\n",
    "\n",
    "        config = checkpoint[\"config\"]\n",
    "        config = GPTConfig(**checkpoint[\"config\"])\n",
    "        model = cls(config, device=map_location)\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "        model.eval()\n",
    "\n",
    "        msg = (\n",
    "            f\"Loaded model from step {checkpoint['step']}, \"\n",
    "            f\"val_loss {checkpoint['val_loss']}\"\n",
    "        )\n",
    "        logging.info(msg)\n",
    "        return model\n",
    "\n",
    "    def generate(\n",
    "        self, text: str, max_length: int = 1024, top_k: int = 50,\n",
    "        seed: int = None,\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Generate text from the model.\n",
    "\n",
    "        N.B. This is a new method based off the generation code\n",
    "             present in Andrej Karpathy's train_gpt2.py.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            text (str): Supplies the prompt.\n",
    "\n",
    "            max_length (int): Supplies the maximum total length,\n",
    "                including prompt.\n",
    "\n",
    "            top_k (int): Supplies the number of tokens to consider\n",
    "                at each generation step.\n",
    "\n",
    "            seed (int): Optionally supplies the manual seed to use\n",
    "                for the generator.  If None, the model's manual\n",
    "                seed will be used.\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            str: The generated text (including the initial prompt).\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        device = self.device\n",
    "        # Obtain our GPT2 tokenizer, and resolve the stop token.\n",
    "        enc = tiktoken.get_encoding(\"gpt2\")\n",
    "        stop_string = '<|endoftext|>'\n",
    "        stop_token = enc.n_vocab - 1\n",
    "        actual = enc.decode([stop_token])\n",
    "        assert actual == stop_string, (\n",
    "            f\"expected {stop_string}, got {actual}\"\n",
    "        )\n",
    "\n",
    "        # Encode the prompt.\n",
    "        tokens = enc.encode(text)\n",
    "        x = torch.tensor(\n",
    "            tokens, dtype=torch.long, device=device\n",
    "        ).unsqueeze(0)\n",
    "\n",
    "        # Create a random generator for reproducibility.\n",
    "        if seed is None:\n",
    "            seed = self.manual_seed\n",
    "        sample_rng = torch.Generator(device=device)\n",
    "        sample_rng.manual_seed(seed)\n",
    "\n",
    "        # Generate tokens up to our max length, or until we hit the\n",
    "        # stop token.\n",
    "        start = time.perf_counter()\n",
    "        count = 0\n",
    "        while x.size(1) < max_length:\n",
    "            count += 1\n",
    "            with torch.no_grad():\n",
    "                # Forward pass, ignoring the returned loss.\n",
    "                (logits, _) = self(x)\n",
    "\n",
    "            # Take the logits at the last time-step (shape:\n",
    "            # (1, vocab_size)).\n",
    "            logits = logits[:, -1, :]\n",
    "\n",
    "            # Convert to probabilities.\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "            # Top-k sampling.\n",
    "            topk_probs, topk_indices = torch.topk(\n",
    "                probs, k=top_k, dim=-1\n",
    "            )\n",
    "\n",
    "            # Sample the next token.\n",
    "            next_idx = torch.multinomial(\n",
    "                topk_probs, num_samples=1, generator=sample_rng\n",
    "            )\n",
    "            next_token = torch.gather(topk_indices, -1, next_idx)\n",
    "\n",
    "            # If the next token is the stop token, we're done.\n",
    "            if next_token.item() == stop_token:\n",
    "                break\n",
    "\n",
    "            # Otherwise, append the token to the current sequence\n",
    "            # and continue generation.\n",
    "            x = torch.cat((x, next_token), dim=1)\n",
    "\n",
    "        end = time.perf_counter()\n",
    "        elapsed = end - start\n",
    "        tokens_per_sec = float(count) / elapsed\n",
    "\n",
    "        msg = (\n",
    "            f'Generated {count} tokens in {elapsed:.2f} seconds '\n",
    "            f'({tokens_per_sec:.2f} tokens/sec)'\n",
    "        )\n",
    "        logging.debug(msg)\n",
    "\n",
    "        # Decode the output tokens and return the generated text,\n",
    "        # including the initial prompt.\n",
    "        output_tokens = x[0].tolist()\n",
    "        return enc.decode(output_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afa15731-cef4-4cf8-a8cd-7fa90f015ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 15:12:03,802 - INFO - Loaded model from step 19072, val_loss 3.0519702434539795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50304, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): GELU(approximate='tanh')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: gpt2-v1-load-model\n",
    "#| echo: true\n",
    "#| output: true\n",
    "#| error: true\n",
    "model = GPT.from_local_pretrained(\n",
    "    MODEL_CHECKPOINT,\n",
    "    map_location='cuda',\n",
    ")\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fafd7b-6b63-44cf-8d0d-1b2d977b5c5b",
   "metadata": {},
   "source": [
    "N.B. In order to achieve the variable-width output for the generated text depending on the type of device on which the article is being viewed (see [theme.scss](https://github.com/tpn/website/blob/main/theme.scss#L91)), each `generate()` example is replicated in triplicate, with varying `width=N` parameters to the `textwrap.wrap()` call.  So if you've downloaded this notebook and are wondering why there seems to be three versions of certain things when the article only depicts one---that's why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb4d6d8-ca4e-483b-b80c-23c2a00c3bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 15:12:05,068 - DEBUG - Generated 79 tokens in 0.77 seconds (102.55 tokens/sec)\n",
      "Albert Einstein's Theory of Relativity stated that the speed of light was approximately 10 000 of\n",
      "parsecs, whereas quantum physicists have suggested that, as we move further into the universe, the\n",
      "universe might grow older. The new experiment, conducted by researchers at the University of New Jersey,\n",
      "New York, and the University of California, Berkeley shows that photons travelling at the speed of light\n",
      "will be around 30 to 65 kilometres per second.\n"
     ]
    }
   ],
   "source": [
    "#| label: gpt2-v1-generate-1-desktop\n",
    "#| echo: true\n",
    "#| output: true\n",
    "#| error: true\n",
    "prompt = \"Albert Einstein's Theory of Relativity stated that\"\n",
    "result = model.generate(prompt, seed=42)\n",
    "print('\\n'.join(wrap(result, width=105)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b22e99-3a7d-43f9-909a-70409d82ac00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b5e57c-42cb-4217-9f91-9f7e058fdce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 15:12:05,620 - DEBUG - Generated 79 tokens in 0.55 seconds (144.83 tokens/sec)\n",
      "Albert Einstein's Theory of Relativity stated that the\n",
      "speed of light was approximately 10 000 of parsecs,\n",
      "whereas quantum physicists have suggested that, as we move\n",
      "further into the universe, the universe might grow older.\n",
      "The new experiment, conducted by researchers at the\n",
      "University of New Jersey, New York, and the University of\n",
      "California, Berkeley shows that photons travelling at the\n",
      "speed of light will be around 30 to 65 kilometres per\n",
      "second.\n"
     ]
    }
   ],
   "source": [
    "#| label: gpt2-v1-generate-1-tablet\n",
    "#| echo: true\n",
    "#| output: true\n",
    "#| error: true\n",
    "prompt = \"Albert Einstein's Theory of Relativity stated that\"\n",
    "result = model.generate(prompt, seed=42)\n",
    "print('\\n'.join(wrap(result, width=58)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867bc31e-abc3-46ec-814e-a1eabb3cb060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 15:12:06,179 - DEBUG - Generated 79 tokens in 0.55 seconds (143.23 tokens/sec)\n",
      "Albert Einstein's Theory of Relativity stated\n",
      "that the speed of light was approximately 10\n",
      "000 of parsecs, whereas quantum physicists\n",
      "have suggested that, as we move further into\n",
      "the universe, the universe might grow older.\n",
      "The new experiment, conducted by researchers\n",
      "at the University of New Jersey, New York,\n",
      "and the University of California, Berkeley\n",
      "shows that photons travelling at the speed of\n",
      "light will be around 30 to 65 kilometres per\n",
      "second.\n"
     ]
    }
   ],
   "source": [
    "#| label: gpt2-v1-generate-1-phone\n",
    "#| echo: true\n",
    "#| output: true\n",
    "#| error: true\n",
    "prompt = \"Albert Einstein's Theory of Relativity stated that\"\n",
    "result = model.generate(prompt, seed=42)\n",
    "print('\\n'.join(wrap(result, width=45)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d262863-de28-4ca7-b44b-1c87f9593a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 15:12:22,030 - DEBUG - Generated 1015 tokens in 15.84 seconds (64.07 tokens/sec)\n",
      "Albert Einstein's Theory of Relativity stated that the speed of light is the same as it is in two\n",
      "places, which means that a given speed can either be described by two different speed equations\n",
      "directly or they may be both equations. It is then assumed that the speed of light is the speed of\n",
      "the universe or the universe's existence relative to Earth. In relativity, a measure of the speed of\n",
      "light is the absolute speed of the light. As long as the speed of light is less than its speed in\n",
      "two different places, the absolute speed can be calculated. For example, the absolute speed is\n",
      "1/2990000000 (2,299,792,458) km/hr with an absolute speed about 10 times as fast as it is in two\n",
      "different places. Now we can use the following equation to describe the speed of light: E = C/C2 The\n",
      "speed of light, as a function of C, is a constant. By Einstein's definition of relativity, the speed\n",
      "of light is a constant. This is because light travels at its maximum speed along the direction (if\n",
      "it's travelling above the speed of light, the point where light must be observed is called\n",
      "\"aperture\" of the speed of light). The speed of light is about half as fast as the speed of light\n",
      "because the speed of light has a smaller varying velocity for each direction of radiation. The speed\n",
      "of light, as a function of C, is a constant. The speed of a wave is the constant measured along the\n",
      "direction of the wave relative to its location in space. E = C/C2 where E is the speed of light\n",
      "along the direction of the wave. Because the speed of the wave is the speed of the particle in the\n",
      "wave, and c the speed of the particle, E's is also given by the speed of light. For example, a light\n",
      "particle is moving from its place of greatest velocity to its location of greatest velocity. E.g. C\n",
      "= F/d, C = d/d For most materials and most other objects, the speed of light is the same for all\n",
      "wavelengths. The speed of light is, on the other hand, the speed of the energy form of a photon.\n",
      "E.g. c = C/d, C = e/d For most particles, light travels over one degree of separation and this is\n",
      "how photons interact with other particles. We can compare a particle's velocity to an object's\n",
      "velocity. The speed of light is measured by the distance between the particle's nose and the surface\n",
      "of the object. For example, a photon of light emits the energy of a single photon. If a photon of\n",
      "another type is fired at the same speed as the first, it will get out of the light, but a photon of\n",
      "the other type will not get back to the ground. The fractional energy will be reduced. The distance\n",
      "between two photons of the same type will be reduced to the square of their energies. E.g. C = C/C2,\n",
      "C = -D/d., D = 9/6 A photon of color does not have sufficient energy to be emitted by that color and\n",
      "is therefore subject to The speed of light is the change in velocity over time. This is a constant,\n",
      "but sometimes it is possible to express it like this: E = c2/e In relativity, the length of the\n",
      "distance is the length of time the length of wave is divided by the speed of light. E.g. a beam of\n",
      "light travelling at about 9.2 miles per second must travel at around 7.3 miles per second to get\n",
      "E.g. a beam moving at 3.2 miles per second must travel at around 8 miles per second to get E.g. a\n",
      "beam moving at 1.8 miles per second must travel at 9.0 miles per second to get E.g. an object going\n",
      "at 2.3 miles per second must travel at 1.8 miles per second to get E.g. a beam moving at 2.3 miles\n",
      "per second must travel at 3.4 miles per second to get E.g.. a beam traveling at 3.4 miles per second\n",
      "to get E.g.. a beam moving at 2.3 miles per second must travel at 3.8 miles per second to get E.g..\n",
      "a beam traveling at 3.8 miles per second to get E.g.. a beam moving at about 4.4 miles per second\n",
      "must travel at about 3.9 miles per second to get E.g.. a beam moving at 5.5 miles per second to get\n",
      "a beam moving at 5.9 miles per S.G.D.. is the same thing as a mass. The distance is a unit in terms\n",
      "of the speed of light. Determining the speed of light is an additional measure of the energy. For\n",
      "most things\n"
     ]
    }
   ],
   "source": [
    "#| label: gpt2-v1-generate-2-desktop\n",
    "#| echo: true\n",
    "#| output: true\n",
    "#| error: true\n",
    "result = model.generate(prompt, seed=20190903)\n",
    "print('\\n'.join(wrap(result, width=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8473f7-dd05-48e5-92ef-6154f781aa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 15:12:37,853 - DEBUG - Generated 1015 tokens in 15.82 seconds (64.18 tokens/sec)\n",
      "Albert Einstein's Theory of Relativity stated that the\n",
      "speed of light is the same as it is in two places,\n",
      "which means that a given speed can either be described\n",
      "by two different speed equations directly or they may\n",
      "be both equations. It is then assumed that the speed\n",
      "of light is the speed of the universe or the\n",
      "universe's existence relative to Earth. In relativity,\n",
      "a measure of the speed of light is the absolute speed\n",
      "of the light. As long as the speed of light is less\n",
      "than its speed in two different places, the absolute\n",
      "speed can be calculated. For example, the absolute\n",
      "speed is 1/2990000000 (2,299,792,458) km/hr with an\n",
      "absolute speed about 10 times as fast as it is in two\n",
      "different places. Now we can use the following\n",
      "equation to describe the speed of light: E = C/C2 The\n",
      "speed of light, as a function of C, is a constant. By\n",
      "Einstein's definition of relativity, the speed of\n",
      "light is a constant. This is because light travels at\n",
      "its maximum speed along the direction (if it's\n",
      "travelling above the speed of light, the point where\n",
      "light must be observed is called \"aperture\" of the\n",
      "speed of light). The speed of light is about half as\n",
      "fast as the speed of light because the speed of light\n",
      "has a smaller varying velocity for each direction of\n",
      "radiation. The speed of light, as a function of C, is\n",
      "a constant. The speed of a wave is the constant\n",
      "measured along the direction of the wave relative to\n",
      "its location in space. E = C/C2 where E is the speed\n",
      "of light along the direction of the wave. Because the\n",
      "speed of the wave is the speed of the particle in the\n",
      "wave, and c the speed of the particle, E's is also\n",
      "given by the speed of light. For example, a light\n",
      "particle is moving from its place of greatest velocity\n",
      "to its location of greatest velocity. E.g. C = F/d, C\n",
      "= d/d For most materials and most other objects, the\n",
      "speed of light is the same for all wavelengths. The\n",
      "speed of light is, on the other hand, the speed of the\n",
      "energy form of a photon. E.g. c = C/d, C = e/d For\n",
      "most particles, light travels over one degree of\n",
      "separation and this is how photons interact with other\n",
      "particles. We can compare a particle's velocity to an\n",
      "object's velocity. The speed of light is measured by\n",
      "the distance between the particle's nose and the\n",
      "surface of the object. For example, a photon of light\n",
      "emits the energy of a single photon. If a photon of\n",
      "another type is fired at the same speed as the first,\n",
      "it will get out of the light, but a photon of the\n",
      "other type will not get back to the ground. The\n",
      "fractional energy will be reduced. The distance\n",
      "between two photons of the same type will be reduced\n",
      "to the square of their energies. E.g. C = C/C2, C =\n",
      "-D/d., D = 9/6 A photon of color does not have\n",
      "sufficient energy to be emitted by that color and is\n",
      "therefore subject to The speed of light is the change\n",
      "in velocity over time. This is a constant, but\n",
      "sometimes it is possible to express it like this: E =\n",
      "c2/e In relativity, the length of the distance is the\n",
      "length of time the length of wave is divided by the\n",
      "speed of light. E.g. a beam of light travelling at\n",
      "about 9.2 miles per second must travel at around 7.3\n",
      "miles per second to get E.g. a beam moving at 3.2\n",
      "miles per second must travel at around 8 miles per\n",
      "second to get E.g. a beam moving at 1.8 miles per\n",
      "second must travel at 9.0 miles per second to get E.g.\n",
      "an object going at 2.3 miles per second must travel at\n",
      "1.8 miles per second to get E.g. a beam moving at 2.3\n",
      "miles per second must travel at 3.4 miles per second\n",
      "to get E.g.. a beam traveling at 3.4 miles per second\n",
      "to get E.g.. a beam moving at 2.3 miles per second\n",
      "must travel at 3.8 miles per second to get E.g.. a\n",
      "beam traveling at 3.8 miles per second to get E.g.. a\n",
      "beam moving at about 4.4 miles per second must travel\n",
      "at about 3.9 miles per second to get E.g.. a beam\n",
      "moving at 5.5 miles per second to get a beam moving at\n",
      "5.9 miles per S.G.D.. is the same thing as a mass. The\n",
      "distance is a unit in terms of the speed of light.\n",
      "Determining the speed of light is an additional\n",
      "measure of the energy. For most things\n"
     ]
    }
   ],
   "source": [
    "#| label: gpt2-v1-generate-2-tablet\n",
    "#| echo: true\n",
    "#| output: true\n",
    "#| error: true\n",
    "result = model.generate(prompt, seed=20190903)\n",
    "print('\\n'.join(wrap(result, width=54)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "125dbbe8-5180-4eba-bf77-58b2e288f410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-06 15:12:53,952 - DEBUG - Generated 1015 tokens in 16.09 seconds (63.08 tokens/sec)\n",
      "Albert Einstein's Theory of Relativity\n",
      "stated that the speed of light is the\n",
      "same as it is in two places, which means\n",
      "that a given speed can either be\n",
      "described by two different speed\n",
      "equations directly or they may be both\n",
      "equations. It is then assumed that the\n",
      "speed of light is the speed of the\n",
      "universe or the universe's existence\n",
      "relative to Earth. In relativity, a\n",
      "measure of the speed of light is the\n",
      "absolute speed of the light. As long as\n",
      "the speed of light is less than its\n",
      "speed in two different places, the\n",
      "absolute speed can be calculated. For\n",
      "example, the absolute speed is\n",
      "1/2990000000 (2,299,792,458) km/hr with\n",
      "an absolute speed about 10 times as fast\n",
      "as it is in two different places. Now we\n",
      "can use the following equation to\n",
      "describe the speed of light: E = C/C2\n",
      "The speed of light, as a function of C,\n",
      "is a constant. By Einstein's definition\n",
      "of relativity, the speed of light is a\n",
      "constant. This is because light travels\n",
      "at its maximum speed along the direction\n",
      "(if it's travelling above the speed of\n",
      "light, the point where light must be\n",
      "observed is called \"aperture\" of the\n",
      "speed of light). The speed of light is\n",
      "about half as fast as the speed of light\n",
      "because the speed of light has a smaller\n",
      "varying velocity for each direction of\n",
      "radiation. The speed of light, as a\n",
      "function of C, is a constant. The speed\n",
      "of a wave is the constant measured along\n",
      "the direction of the wave relative to\n",
      "its location in space. E = C/C2 where E\n",
      "is the speed of light along the\n",
      "direction of the wave. Because the speed\n",
      "of the wave is the speed of the particle\n",
      "in the wave, and c the speed of the\n",
      "particle, E's is also given by the speed\n",
      "of light. For example, a light particle\n",
      "is moving from its place of greatest\n",
      "velocity to its location of greatest\n",
      "velocity. E.g. C = F/d, C = d/d For most\n",
      "materials and most other objects, the\n",
      "speed of light is the same for all\n",
      "wavelengths. The speed of light is, on\n",
      "the other hand, the speed of the energy\n",
      "form of a photon. E.g. c = C/d, C = e/d\n",
      "For most particles, light travels over\n",
      "one degree of separation and this is how\n",
      "photons interact with other particles.\n",
      "We can compare a particle's velocity to\n",
      "an object's velocity. The speed of light\n",
      "is measured by the distance between the\n",
      "particle's nose and the surface of the\n",
      "object. For example, a photon of light\n",
      "emits the energy of a single photon. If\n",
      "a photon of another type is fired at the\n",
      "same speed as the first, it will get out\n",
      "of the light, but a photon of the other\n",
      "type will not get back to the ground.\n",
      "The fractional energy will be reduced.\n",
      "The distance between two photons of the\n",
      "same type will be reduced to the square\n",
      "of their energies. E.g. C = C/C2, C =\n",
      "-D/d., D = 9/6 A photon of color does\n",
      "not have sufficient energy to be emitted\n",
      "by that color and is therefore subject\n",
      "to The speed of light is the change in\n",
      "velocity over time. This is a constant,\n",
      "but sometimes it is possible to express\n",
      "it like this: E = c2/e In relativity,\n",
      "the length of the distance is the length\n",
      "of time the length of wave is divided by\n",
      "the speed of light. E.g. a beam of light\n",
      "travelling at about 9.2 miles per second\n",
      "must travel at around 7.3 miles per\n",
      "second to get E.g. a beam moving at 3.2\n",
      "miles per second must travel at around 8\n",
      "miles per second to get E.g. a beam\n",
      "moving at 1.8 miles per second must\n",
      "travel at 9.0 miles per second to get\n",
      "E.g. an object going at 2.3 miles per\n",
      "second must travel at 1.8 miles per\n",
      "second to get E.g. a beam moving at 2.3\n",
      "miles per second must travel at 3.4\n",
      "miles per second to get E.g.. a beam\n",
      "traveling at 3.4 miles per second to get\n",
      "E.g.. a beam moving at 2.3 miles per\n",
      "second must travel at 3.8 miles per\n",
      "second to get E.g.. a beam traveling at\n",
      "3.8 miles per second to get E.g.. a beam\n",
      "moving at about 4.4 miles per second\n",
      "must travel at about 3.9 miles per\n",
      "second to get E.g.. a beam moving at 5.5\n",
      "miles per second to get a beam moving at\n",
      "5.9 miles per S.G.D.. is the same thing\n",
      "as a mass. The distance is a unit in\n",
      "terms of the speed of light. Determining\n",
      "the speed of light is an additional\n",
      "measure of the energy. For most things\n"
     ]
    }
   ],
   "source": [
    "#| label: gpt2-v1-generate-2-phone\n",
    "#| echo: true\n",
    "#| output: true\n",
    "#| error: true\n",
    "result = model.generate(prompt, seed=20190903)\n",
    "print('\\n'.join(wrap(result, width=40)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313t",
   "language": "python",
   "name": "py313t"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
