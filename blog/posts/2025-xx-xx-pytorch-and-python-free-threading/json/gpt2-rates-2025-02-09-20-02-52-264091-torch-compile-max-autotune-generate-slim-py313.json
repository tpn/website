{
    "rates": [
        0.43211991122263116,
        240.7370770304193,
        252.10239404707087,
        251.54859419302156,
        251.1420697886388,
        251.91140360500685,
        252.21827165732194,
        252.75094061684538,
        252.01721822323742,
        252.5102460163623,
        251.48011194601514,
        247.96257214160448,
        253.05278001496828,
        250.56913835273204,
        251.87570958604553,
        250.27178825790554,
        247.27803327531316,
        248.9329966458875,
        251.7412647853925,
        250.71942683554497
    ],
    "model_config": {
        "block_size": 1024,
        "vocab_size": 50304,
        "n_layer": 12,
        "n_head": 12,
        "n_embd": 768
    },
    "args": {
        "log_level": "INFO",
        "model": "gpt2",
        "device": "cuda:3",
        "max_length": 100,
        "top_k": 50,
        "seed": 42,
        "prompt": "Einstein's Theory of Relativity states that",
        "torch_compile": true,
        "torch_jit": false,
        "torch_compile_fullgraph": false,
        "torch_compile_reduce_overhead": false,
        "torch_compile_max_autotune": true,
        "generate_slim": true,
        "rounds": 20,
        "wrap": 60,
        "note": "Explicit @torch.compile decorator on GPT.generate_slim"
    },
    "start_timestamp": "2025-02-09T19:58:52.122345",
    "end_timestamp": "2025-02-09T20:02:52.264203",
    "elapsed": "240.142",
    "device_name": "Tesla V100-DGXS-32GB",
    "conda_env_name": "py313",
    "is_gil_enabled": true,
    "note": "Explicit @torch.compile decorator on GPT.generate_slim"
}