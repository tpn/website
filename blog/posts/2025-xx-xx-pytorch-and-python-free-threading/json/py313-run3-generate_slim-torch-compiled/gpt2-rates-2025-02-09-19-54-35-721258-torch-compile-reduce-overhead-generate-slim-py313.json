{
    "rates": [
        0.4332240924892882,
        236.8174528559799,
        241.8303872496977,
        240.96103821262344,
        242.32727741487045,
        240.9074314001702,
        242.69551128756163,
        238.47018873186366,
        241.77345978336555,
        243.33900835288583,
        239.82402154432367,
        239.06623233647466,
        234.25722791304085,
        244.5753803819385,
        244.41971574664072,
        245.83600215291932,
        245.7582923556155,
        244.68073684609152,
        245.06912346086543,
        244.73572410614477
    ],
    "model_config": {
        "block_size": 1024,
        "vocab_size": 50304,
        "n_layer": 12,
        "n_head": 12,
        "n_embd": 768
    },
    "args": {
        "log_level": "INFO",
        "model": "gpt2",
        "device": "cuda:3",
        "max_length": 100,
        "top_k": 50,
        "seed": 42,
        "prompt": "Einstein's Theory of Relativity states that",
        "torch_compile": true,
        "torch_jit": false,
        "torch_compile_fullgraph": false,
        "torch_compile_reduce_overhead": true,
        "torch_compile_max_autotune": false,
        "generate_slim": true,
        "rounds": 20,
        "wrap": 60,
        "note": "Explicit @torch.compile decorator on GPT.generate_slim"
    },
    "start_timestamp": "2025-02-09T19:50:35.924090",
    "end_timestamp": "2025-02-09T19:54:35.721298",
    "elapsed": "239.797",
    "device_name": "Tesla V100-DGXS-32GB",
    "conda_env_name": "py313",
    "is_gil_enabled": true,
    "note": "Explicit @torch.compile decorator on GPT.generate_slim"
}