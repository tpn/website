<!DOCTYPE html>
<html>
    <!-- vim:set tw=100 ts=8 sw=4 et                                                            :-->
    <head>
        <title>Perfect Hash Table</title>
        <meta name="msvalidate.01" content="E828541C73A98C315E3D6B8C88EF6057" />
        <meta name="viewport" content="width=device-width, initial-scale=0.65, maximum-scale=1.0" />

        <!-- https://www.google.com/fonts#UsePlace:use/Collection:Lato:200,300,300italic -->
        <!--
        <meta name="viewport" content="width=device-width, min-width=1100px, initial-scale=0.7, maximum-scale=1.0, shrint-to-fit=no" />
        <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:200,300,300italic">
        <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:300,300i,400,400i">
        -->
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400" rel="stylesheet">
        <link rel="stylesheet" href="//oss.maxcdn.com/normalize/3.0.1/normalize.min.css">
        <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="../prism.css">
        <link rel="stylesheet" href="../home.css">
        <link rel="stylesheet" href="page.css">
        <script src="//oss.maxcdn.com/jquery/2.1.1/jquery.min.js"></script>
        <script src="../prism.js"></script>
        <script src="../home.js"></script>
        <script src="page.js"></script>
    </head>
    <body>

        <header class="header">
            <div class="header-logo" href="#">
                <!--
                <a class="homename" href="http://trent.me"><strong>T</strong>rent <strong>N</strong>elson</a>
                -->
                <a class="homename" href=".."><strong>T</strong>rent <strong>N</strong>elson</a>
            </div>
            <ul class="header-links">
                <li><a href="#home"><i class="fa fa-home"></i>Creating a Perfect Hash Table</a></li>
                <li><a href="#contents"><i class="fa fa-align-left"></i> Contents</a></li>
                <li><a href="https://github.com/tpn/tracer/tree/master/PerfectHashTable" target="_blank"><i class="fa fa-github"></i> GitHub</a></li>
                <li><a href="https://twitter.com/trentnelson" target="_blank"><i class="fa fa-twitter"></i> Twitter</a></li>
                <!--
                <li><a href="https://twitter.com/trentnelson" class="twitter-follow-button" data-show-count="false">Follow @trentnelson</a></li>
                -->
            </ul>
        </header>

        <a class="xref" name="home"></a>
        <section class="section section-hero">
            <div class="container">
                <h1>
                    Creating a Perfect Hash Table
                </h1>
                <h3>
                    A Performant, Parallel, Random Acyclic-Hypergraph Approach
                </h3>
            </div>
        </section>

        <section class="section section-summary">
            <div class="container">

                <small>
                    Current status: <strong>draft</strong>.  Last update: 5th June, 2018.
                    Target publish date: 7th June, 2018.

                    <!--
                    <a href="https://github.com/tpn/website/blob/master/perfect-hash-table/index.html">
                    View this page's source on GitHub.</a>-->

                <hr/>

                <h3>TL;DR</h3>
                <p>

                    This article documents a recent assignment regarding the implementation of a
                    perfect hash table.  I discuss the initial goal as a set of requirements, then
                    capture design decisions and provide an implementation overview.

                </p>
                </small>

                <hr/>
                <h2>Requirements</h2>
                <p>

                    Author a perfect hash table component that provides offline table
                    generation and fast lookup performance.  Assume a key and value width of
                    <code>ULONG</code> (32 bits).  Optimize for key set sizes ranging from
                    10,000 to 40,000 keys on average, with up to 100,000 keys on the high end.

                </p>

                <p>

                    Assume a key distribution similar to that of shared library address offsets;
                    not linear, but definitely not random, either.  Do not make assumptions about
                    the presence of leading or trailing zeros (i.e. alignment), although feel free
                    to optimize for this if it doesn't detract from the component's performance on
                    less predictable key sets.

                </p>

                <p>

                    Prioritize lookup speed over generation speed.  Optimize the lookup algorithm
                    to minimize latency involved in a single <code>Value = Lookup(Key)</code>
                    call.  Table generation will be done ahead of time, in a separate process, and
                    only needs to ensure that tables can be generated in a reasonable amount of
                    time given the size of the input key set.  Linear overhead is ideal, quadratic
                    less so, exponential would be infeasible.

                </p>

                <p>

                    Prioritize lookup speed over table size (memory requirements).  A larger table
                    size, within reason, is an acceptable trade-off if it yields a faster lookup
                    speed.  A minimal perfect hash table, where each key maps to exactly one table
                    location, is not a requirement, nor is it prohibited.

                </p>

                <p>

                    Note the inevitable tradeoff in size and performance with regards to the masking
                    method used by the implementation.  Modulus-oriented solutions, those that use
                    the % operator in C, tend to be slower (modulus division can take upward of 90
                    cycles), but yield smaller table sizes.  Solutions relying on power-of-2 based
                    table sizes boast much faster masking routines (e.g. <code>Input &amp;
                    (Size-1)</code>), but incur greater table size overhead.

                </p>

                <p>

                    The offline generation process takes, as its input, a key file.  The file will
                    be an array of <code>ULONG</code> keys (i.e. binary data).  The number of
                    elements in the array can be ascertained by dividing the file size by
                    <code>sizeof(ULONG)</code>.  It produces, as its output, a perfect hash table
                    file that can be subsequently loaded and used in separate processes.

                </p>

                <p>

                    Callers wishing to use a given perfect hash table will need to load the file
                    produced in the step above.  This will yield an interface from which the hash
                    table can be interacted with.  At a bare minimum, the interface should support
                    the following semantics:

                </p>

<pre class="code"><code class="language-c">extern PULONG Table;
ULONG Lookup(ULONG Key) { return Table[PerfectHashFunction(Key)]; }
VOID Insert(ULONG Key, ULONG Value) { Table[PerfectHashFunction(Key)] = Value; }
</code></pre>

                <p>

                    The interface requirements are flexible and can be extended as long as the
                    criteria above are met at a bare minimum.

                </p>

                <p>

                    The behavior of looking up or inserting a key that wasn't in the original input
                    set is undefined.  That is, the implementation is not required to detect or
                    protect against this scenario &mdash; that is the responsibility of the caller.

                </p>

                <p>

                    Feel free to review existing works on the topic, particularly the cmph open
                    source project, the GNU gperf library, and the plethora of papers on the subject
                    of perfect hashing and minimal perfect hashing.

                </p>

            </div>
        </section>
        <hr/>

        <section class="section section-toc">
            <div class="container">

                <a class="xref" name="contents"></a>
                <h1>Contents</h1>

                <p>
                    <ul class="toc-list">

                        <li>

                            <a href="#getting-started">Getting Started</a>

                        </li>

                        <li>

                            <a href="#algorithm-decisions">Algorithm Decisions</a>

                        </li>

                        <li>

                            <a href="#initial-design-decisions">Initial Design Decisions</a>

                        </li>

                        <li>

                            <a href="#implementation-notes">Implementation Notes</a>

                        </li>

                        <li>

                            <a href="#code-walkthrough">Code Walkthrough</a>

                        </li>

                    </ul>
                </p>
            </div>
        </section>
        <hr/>

        <section class="section section-body">
            <div class="container">

                <a class="xref" name="getting-started"></a>
                <h1>Getting Started</h1>

                <p>

                    This was an interesting project.  I'd never written a perfect hash table before,
                    nor was I familiar with the landscape for doing such a thing.  I spent about
                    three days reviewing existing work, including the <a
                    href="http://cmph.sourceforge.net">cmph</a> project's source code.  (I ended up
                    collecting about 147 (!) documents on the topic (papers, PhD thesis, slides,
                    etc) in my <a href="https://github.com/tpn/pdfs">PDFs</a> repo over the course
                    of the project.)

                </p>

                <a class="xref" name="algorithm-decisions"></a>
                <h1>Algorithm Decisions</h1>

                <p>

                    The algorithm I settled on is the acyclic random 2-part hypergraph (or r-graph,
                    where r = 2).  The algorithm works as follows: for each key, generate two
                    independent hash values.  Mask these values such that they fall within the
                    confines of the number of <em>vertices</em> picked for the table (more on this
                    later; for now, assume the number of <em>vertices</em> exceeds the number of
                    keys, or <em>edges</em> by at least 2x).  These masked hash values now become
                    the two vertices, and are added to a graph structure by a connecting edge.  The
                    edge is simply the 0..N index being used for enumeration, e.g.:

                </p>

<pre class="code"><code class="language-c">for (Index = 0; Index &lt; NumberOfKeys; Index++) {

    Key = Keys[Index];

    Hash1 = HashFunction1(Key);
    Hash2 = HashFunction2(Key);

    Vertex1 = MaskHashFunction(Hash1);
    Vertex2 = MaskHashFunction(Hash2);

    Edge = Index;

    GraphAddEdge(Graph, Edge, Vertex1, Vertex2);
}</code></pre>

                <p>

                    Once constructed, the graph is assessed to determine whether or not it is
                    acyclic.  If the graph is acyclic, it means every vertex has at most 1 degree
                    of connectivity to other vertices.  We want an acyclic graph.  If it's not
                    acyclic, the attempt has failed, the graph is thrown away, and a new attempt
                    is made, using new random seed data to drive the two hash functions.  Once
                    an acyclic graph is found, it's relatively straight forward to convert this
                    into a data structure that can be used as a perfect hash table.

                </p>

                <p>

                    This algorithm first has roots in <a href="https://github.com/tpn/pdfs/blob/master/A%20Versatile%20Graph%20Structure%20for%20Edge-Oriented%20Graph%20Algorithms%20-%201987%20(Ebert1987AVD).pdf">
                    A Versatile Data Structure for Edge-Oriented Graph Algorithms (Ebert, 1987)</a>.
                    Its application to perfect hashing appears in <a
                    href="https://github.com/tpn/pdfs/blob/master/A%20Family%20of%20Perfect%20Hashing%20Methods%20-%201996%20(TR0242).pdf">
                    A Family of Perfect Hashing Methods (Majewski, Wormald, Havas, Czech, 1996)</a>,
                    where they focus on more rigorous proofs of the runtime complexity associated
                    with acyclic r-graphs, extending on the work in their earlier paper, <a
                    href="https://github.com/tpn/pdfs/blob/3dc05fb22d87d86117802a2dc206926c79981ca3/Graphs,%20Hypergraphs%20and%20Hashing.pdf">Graphs, Hypergraphs and Hashing (1994)</a>, and their initial works on
                    the matter, <a
                    href="https://github.com/tpn/pdfs/blob/master/An%20Optimal%20Algorithm%20for%20Generating%20Minimal%20Perfect%20Hash%20Functions%20-%201992%20(10.1.1.51.5566).pdf">
                    An Optimal Algorithm for generating Minimal Perfect Hash Functions (Majewski,
                    Havas, Czech, 1992)</a>.

                </p>

                <p>

                    There is one thing that stood out in their 1996 paper (page 9) that I was able
                    to verify experimentally (after finally hacking the
                    <a href="https://github.com/tpn/cmph-2.0/blob/master/src/chm.c">CHM</a> algorithm
                    in the CMHP project into a working state).  To summarize, sans heavy math notation: the
                    probability that we find a perfect hash solution by identifying an acyclic
                    r-graph (r = 2) is 99.9% within 18 iterations.  On average, a solution is found
                    in &radic;3 attempts.

                </p>

                <p>

                    This is referred to as a <a
                    href="https://en.wikipedia.org/wiki/Geometric_distribution">geometric
                    distribution</a>, something I hadn't come across before.  It is a very desirable
                    trait, especially for this particular problem.  In essence, the more we do it,
                    the more likely we'll figure it out.  Assuming there is a solution (i.e. the
                    hash function is performing properly), the chance of us not solving it is provably
                    infinitesimal, which is neat.

                </p>

                <p>

                    I made the following notes around day 3 of the project:

                </p>

                <div class="blockquote"><small>

                    <p>

                        In my experiments, even with 10 million random keys, graph creation took about
                        6-7 seconds on the 64-bit release build.  On average it found a solution usually
                        within 1-3 iterations.  The worst-case I saw was 7 iterations.

                    </p>


                    <p>

                        The nice thing about the graph creation step is that each iteration can be
                        palmed off to a threadpool worker, such that you can attempt to find a graph
                        solution in parallel up to NCPU.  On my 12 core box at home, there is a very
                        high probability I'll find a solution in the first batch of 12 iterations
                        submitted in parallel &mdash; thus, my clock time for solving the perfect hash
                        stays relatively consistent at 6-7 seconds, give or take.

                    </p>


                    <p>

                        This algorithm is not the fastest, nor the most state-of-the-art, nor does
                        it have the lowest bits-per-key storage requirement, nor will I be aiming
                        for a minimal perfect hash function.  However, it's simple (relatively),
                        I understand it, I can explain it on a whiteboard without having to
                        continually reference a paper, and it's definitely fast enough in the
                        generation stage based on our target static key sets.  It's also old; graph
                        theory has flourished since the 60s, and this particular algorithm came onto
                        the scene in 1992, and has been cited widely.

                    </p>

                    <p>

                        (The current state-of-the-art depicted in papers like <a
                        href="https://github.com/tpn/pdfs/blob/master/Fast%20Scalable%20Construction%20of%20(Minimal%20Perfect%20Hash)%20Functions%20-%2022%20Mar%202016,%20v2%20(1603.04330).pdf">
                        Fast Scalable Construction of (Minimal Perfect Hash) Functions (Genuzio,
                        Ottaviano, Vigna, 2016)</a> use "lazy Gaussian elimination" to try tackle
                        the minimal perfect hash problem on ultra-large key sets (in the billions
                        and above).  That is interesting, but not a wise choice for me to tackle in
                        a week, nor does it improve on our target static key sets, which are very
                        modest in size in comparison.)

                    </p>

                    <p>

                        Another reason I'm favoring the algorithm I've chosen is that because the
                        generation stage is so cheap, relatively, and we have that nice
                        probabilistic guarantee that we'll "probably" find a solution by iteration
                        18... that gives us a lot of leeway with regards to experimenting with the
                        underlying hash functions used.  I envision there being much faster, non-mod
                        based hash functions we can experiment with, that actually have relatively
                        poor "randomness" qualities unless a particularly good seed is found.
                        Combined with the threadpool infrastructure for submitting iterations in
                        parallel, I have a hunch that I'll be able to find some very fast hash
                        functions that can still be solved in an acceptable amount of time.  This
                        will help greatly with our evaluation time; reducing the latency and CPU
                        cycles required to perform the lookup.

                    </p>

                    <p>

                        There is one large risk item associated with my current plan: the key
                        validation step of the cmph command line program just flat-out isn't working
                        properly.  The graph generation step <strong>*appears*</strong> to be doing
                        the right thing, at least with regards to finding cyclic graphs and
                        discarding them, etc.  The validation step works on small key sizes,
                        however, after about 500, I'm seeing rampant conflicts and severe
                        degradation of the underlying hash functions (i.e. everything is hashing to
                        394 or 85 or something).

                    </p>

                </small></div>

                <p>

                    The last paragraph depicts some of the issues I had trying to get the cmph
                    program to validate the perfect hash tables it was supposedly generating.  Try
                    as I might, I just couldn't get the thing to generate solutions that were
                    actually valid (despite it reporting that they were valid) after a few hours
                    of fiddling.

                </p>

                <p>

                    More impressively, though, is that the bug survived and still exists in my
                    complete reimplementation of their initial modulus-oriented masking approach.
                    This only became apparent in the latter stages of the project, when I authored
                    more robust validation and test logic.  Thankfully though, my power-of-2 based
                    approach <strong>does</strong> work, and it's a lot faster, so, who knows.  The
                    modulus functionality was only implemented for a reference point, I didn't
                    anticipate using it as the final "fast" version of the perfect hash solution, so
                    I haven't investigated why it doesn't work properly any further.  It's a little
                    disconcerting, though.

                </p>

                <a class="xref" name="initial-design-decisions"></a>
                <h1>Initial Design Decisions</h1>

                <p>

                    A few of the initial guiding sentiments regarding the design follow:

                    <ul>

                        <li>

                            I wanted to be able to easily mix and match different algorithms, hash
                            functions and masking types.  I figured this would make experimentation
                            easier, and generally promote sensible de-coupling of internal
                            components.  Thus, the main interface for creating a perfect hash table
                            is parameterized by three enums for the desired algorithm, hash function
                            and masking type, respectively.  This is then stored with the table, such
                            that the loading component knows which implementations to use when setting
                            up an interface to the hash table.

                        </li>

                    </ul>

                    <ul>

                        <li>

                            The problem parallelizes incredibly well.  The more threads you can have
                            looking for an acylic graph, the better.  There was no way I was
                            implementing this as a single-threaded solution; it's rare to get a
                            problem so well suited to a multithreaded approach, and the threadpool
                            scaffolding provided by NT is sublime, so that was a no-brainer.
                            <br/>

                            <small>

                            (In fact, the way that it is currently written, you can't actually solve
                            the graph <strong>*without*</strong> using a threadpool.  You can
                            dictate the level of concurrency you want, and specifying 1 means the
                            threadpool only gets 1 thread, which makes debugging easier, but there
                            is no way to isolate the solving process to avoid this.  This is by
                            design.)

                            </small>

                        </li>

                    </ul>

                    <ul>

                        <li>

                            Memory map all the things.  All file system interaction is achieved via
                            sections and memory maps.  There is a separate threadpool used for
                            handling file-oriented work (such as saving the solution to disk in
                            parallel whilst the main thread verifies it is correct &mdash; which
                            it will be unless we've got internal bugs).  Memory mappings are used
                            for the source .keys file, the resulting .pht1 file for the perfect
                            hash table, and the .pht1:Info NTFS stream used to capture metadata
                            about the perfect hash table (such as which algorithm, hash function,
                            and masking function was used, sizes, stats etc).

                        </li>

                    </ul>

                    <ul>


                        <li>

                            For handling testing, due to the limited time constraints, I went for a
                            big-bang systems level "self-test".  Coupled with aggressive internal
                            ASSERT()ing, this worked out pretty well.  A self-test .exe is provided,
                            which, when pointed at a data directory and given a set of algorithm,
                            hash and mask IDs, will process all *.keys files in the directory; for
                            each one, a perfect hash file is created, the on-disk version is then
                            loaded and subsequently tested.  This is all handled by the routine
                            <a
                            href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/SelfTestPerfectHashTable.c">
                            SelfTestPerfectHashTable</a>, which also serves as a good example for
                            how to exercise the entire system end-to-end.

                        </li>

                    </ul>

                </p>

                <a class="xref" name="implementation-notes"></a>
                <h1>Implementation Notes</h1>

                <small>

                    (The following section serves as a general introduction to the project's
                    organization, concepts, files, etc.  It aims to provide a bit of
                    background context to some of the idioms that will be observed when reviewing
                    the code.  The next section, <a href="#code-walkthrough">Code Walkthrough</a>,
                    digs into the implementation details in a more end-to-end type fashion.)

                </small>

                <p>

                    From an implementation perspective, I decided to develop the component as part
                    of my <a href="https://github.com/tpn/tracer">tracer</a> project for two
                    reasons: a) the tracer project already has a lot of scaffolding in place
                    (especially for the boring bits) that I'd be able to re-use, which is useful
                    when time-constrained, and b) a perfect hash table is actually a pretty
                    neat component that I can see my self using down the track.

                </p>

                <p>

                    The implementation is creatively-named <a
                    href="https://github.com/tpn/tracer/tree/master/PerfectHashTable">PerfectHashTable</a>,
                    and is a DLL.

                </p>

                <p>

                    The <a
                    href="https://github.com/tpn/tracer/tree/master/PerfectHashTableSelfTestExe">PerfectHashTableSelfTestExe</a>
                    project, also very creatively-named, is the standalone self-test .exe.

                </p>

                <p>

                    Development of the project was done in Visual Studio 2017 via the
                    <a href="https://github.com/tpn/tracer/tree/master/PerfectHashTable.sln">PerfectHashTable.sln</a>
                    solution, which includes Debug, Release, PGInstrument and PGOptimize
                    configurations.

                </p>

                <p>

                    The coding style and conventions are the same as the rest of the tracer project:
                    Cutler Normal Form C, heavily commented, and generally very NT-esque in style.

                </p>

                <p>

                    Components in the tracer project have an interesting restriction in that they
                    can't use the C runtime library in any way (due to the need to potentially be
                    remote injected into a target process, and not wanting to deal with varying
                    levels of C runtime availability).  Instead, they make extensive, exclusive
                    use of the NT runtime primitives afforded by <code>ntdll.dll</code>,
                    <code>kernel32.dll</code>, and <code>ntoskrnl.exe</code>.  This
                    functionality is wrapped up by a component named
                    <a href="https://github.com/tpn/tracer/tree/master/Rtl">Rtl</a> (inspired by the
                    NT runtime library of the same name).  There is a huge structure named
                    <a
                    href="https://github.com/tpn/tracer/blob/7fc2741b27e5705f4dc93f5dbf1280e08d7dfa8a/Rtl/Rtl.h#L6380">RTL</a>,
                    which contains the kitchen sink of things we need across all components, as well
                    as function pointers to DDK-type functionality normally not available if you're
                    including <code>&lt;Windows.h&gt;</code> (such as bitmaps, AVL tables, prefix
                    tables, etc).

                    <small>(Note: one of the original design objectives of the RTL structure was to
                    facilitate writing components that could run in both kernel and user mode
                    without needing recompilation or #ifdefs.  That is, you could author and test
                    the vast majority of your functionality in user mode, where development,
                    debugging and testing is easier, without needing to deploy it into the kernel
                    until much later in the development lifecycle.)</small>

                </p>

                <p>

                    The reason for mentioning this is that the first two parameters for every public
                    function of the PerfectHashTable component are usually <code>Rtl</code> and
                    <code>Allocator</code>.  E.g.:


                </p>


<pre class="code"><code class="language-c">_Use_decl_annotations_
BOOLEAN
CreatePerfectHashTable(
    PRTL Rtl,
    PALLOCATOR Allocator,
    PPERFECT_HASH_TABLE_CONTEXT Context,
    PERFECT_HASH_TABLE_ALGORITHM_ID AlgorithmId,
    PERFECT_HASH_TABLE_MASK_FUNCTION_ID MaskFunctionId,
    PERFECT_HASH_TABLE_HASH_FUNCTION_ID HashFunctionId,
    PULARGE_INTEGER NumberOfTableElementsPointer,
    PPERFECT_HASH_TABLE_KEYS Keys,
    PCUNICODE_STRING HashTablePath
    )</code></pre>

                <p>

                    The <a
                    href="https://github.com/tpn/tracer/blob/7fc2741b27e5705f4dc93f5dbf1280e08d7dfa8a/Rtl/Memory.h#L464">ALLOCATOR</a>
                    structure encapsulates the memory management functions like
                    <code>Calloc()</code> and <code>Free()</code>, such that we're not dependent
                    upon CRT linkage to equivalent functions.  Initially, it just had the basic set
                    of routines required to mimic Python's <code>PyMemAllocatorEx</code> structure:
                    <code>malloc()</code>, <code>calloc()</code>, <code>realloc()</code> and
                    <code>free()</code>.  However, since then, it grew to support a plethora of
                    routines, many of which driven by the TraceStore component (which offers an
                    <code>ALLOCATOR</code>-based interface, such that all memory requests are
                    fulfilled by memory-map backed stores that track the address assignments and
                    facilitate re-mapping in a separate process at the same address), but also
                    more general functions such as aligned memory allocators.

                </p>

                <p>

                    Long story short, if your see <code>Rtl</code> our <code>Allocator</code>
                    variables anywhere, it's just our runtime glue or memory allocator
                    stuff.

                </p>

                <p>

                    Moving on, all public functions get a SAL-annotated function pointer typedef in
                    the main public header file (<a
                    href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTable.h">PerfectHashTable.h</a>).
                    Functions are defined for creating and destroying keys and perfect hash tables,
                    creating and destroying contexts (a context is required to create a table), and
                    loading a previously-created table.

                <p>

                    I use the same API pattern I used for the
                    <a href="https://github.com/tpn/tracer/tree/master/StringTable2">StringTable2</a>
                    component, which I discuss
                    <a href="https://trent.me/is-prefix-of-string-in-table/#implementation-considerations">here</a>.
                    This involves defining a structure named
                    <a
                    href="https://github.com/tpn/tracer/blob/515692eb7da838079f482e7ada27c6bda59617eb/PerfectHashTable/PerfectHashTable.h#L561">PERFECT_HASH_TABLE_API</a>,
                    and an inline function,
                    <a
                    href="https://github.com/tpn/tracer/blob/515692eb7da838079f482e7ada27c6bda59617eb/PerfectHashTable/PerfectHashTable.h#L624">LoadPerfectHashTableApi()</a>.

                </p>

                <p>

                    The structure looks like this:

                </p>

<pre class="code"><code class="language-c">typedef struct _Struct_size_bytes_(SizeOfStruct) _PERFECT_HASH_TABLE_API {

    //
    // Size of the structure, in bytes.  This is filled in automatically by
    // LoadPerfectHashTableApi() based on the initial SizeOfAnyApi parameter.
    //

    _In_range_(sizeof(struct _PERFECT_HASH_TABLE_API),
               sizeof(struct _PERFECT_HASH_TABLE_API_EX)) ULONG SizeOfStruct;

    //
    // Number of function pointers contained in the structure.  This is filled
    // in automatically by LoadPerfectHashTableApi() based on the initial
    // SizeOfAnyApi parameter divided by the size of a function pointer.
    //

    ULONG NumberOfFunctions;

    //
    // Begin function pointers.
    //

    union {
        PVOID FirstFunctionPointer;
        PSET_C_SPECIFIC_HANDLER SetCSpecificHandler;
    };

    PLOAD_PERFECT_HASH_TABLE_KEYS LoadPerfectHashTableKeys;
    PDESTROY_PERFECT_HASH_TABLE_KEYS DestroyPerfectHashTableKeys;

    PCREATE_PERFECT_HASH_TABLE_CONTEXT CreatePerfectHashTableContext;
    PDESTROY_PERFECT_HASH_TABLE_CONTEXT DestroyPerfectHashTableContext;

    PCREATE_PERFECT_HASH_TABLE CreatePerfectHashTable;
    PLOAD_PERFECT_HASH_TABLE LoadPerfectHashTable;
    PTEST_PERFECT_HASH_TABLE TestPerfectHashTable;

    PINITIALIZE_PERFECT_HASH_TABLE_ALLOCATOR InitializePerfectHashAllocator;

    PINITIALIZE_PERFECT_HASH_TABLE_ALLOCATOR_FROM_RTL_BOOTSTRAP
        InitializePerfectHashAllocatorFromRtlBootstrap;

} PERFECT_HASH_TABLE_API;
typedef PERFECT_HASH_TABLE_API *PPERFECT_HASH_TABLE_API;

</code></pre>

                <p>

                    And the loader routine looks like this:

                </p>

<pre class="code"><code class="language-c">FORCEINLINE
BOOLEAN
LoadPerfectHashTableApi(
    _In_ PRTL Rtl,
    _Inout_ HMODULE *ModulePointer,
    _In_opt_ PUNICODE_STRING ModulePath,
    _In_ ULONG SizeOfAnyApi,
    _Out_writes_bytes_all_(SizeOfAnyApi) PPERFECT_HASH_TABLE_ANY_API AnyApi
    )
/*++

Routine Description:

    Loads the perfect hash table module and resolves all API functions for
    either the PERFECT_HASH_TABLE_API or PERFECT_HASH_TABLE_API_EX structure.
    The desired API is indicated by the SizeOfAnyApi parameter.

    Example use:

        PERFECT_HASH_TABLE_API_EX GlobalApi;
        PPERFECT_HASH_TABLE_API_EX Api;

        Success = LoadPerfectHashApi(Rtl,
                                     NULL,
                                     NULL,
                                     sizeof(GlobalApi),
                                     (PPERFECT_HASH_TABLE_ANY_API)&amp;GlobalApi);
        ASSERT(Success);
        Api = &amp;GlobalApi;

    In this example, the extended API will be provided as our sizeof(GlobalApi)
    will indicate the structure size used by PERFECT_HASH_TABLE_API_EX.

Arguments:

    Rtl - Supplies a pointer to an initialized RTL structure.

    ModulePointer - Optionally supplies a pointer to an existing module handle
        for which the API symbols are to be resolved.  May be NULL.  If not
        NULL, but the pointed-to value is NULL, then this parameter will
        receive the handle obtained by LoadLibrary() as part of this call.
        If the string table module is no longer needed, but the program will
        keep running, the caller should issue a FreeLibrary() against this
        module handle.

    ModulePath - Optionally supplies a pointer to a UNICODE_STRING structure
        representing a path name of the string table module to be loaded.
        If *ModulePointer is not NULL, it takes precedence over this parameter.
        If NULL, and no module has been provided via *ModulePointer, loading
        will be attempted via LoadLibraryA("PerfectHashTable.dll")'.

    SizeOfAnyApi - Supplies the size, in bytes, of the underlying structure
        pointed to by the AnyApi parameter.

    AnyApi - Supplies the address of a structure which will receive resolved
        API function pointers.  The API furnished will depend on the size
        indicated by the SizeOfAnyApi parameter.

Return Value:

    TRUE on success, FALSE on failure.

--*/
</code></pre>

                <p>

                    This is a little quirky, but I've found it to be a useful way to
                    dynamically load and use small components at runtime without requiring
                    any static linking or dll export/import glue.

                </p>

                <p>

                    Publicly, the keys and context structures are opaque.  Routines are exposed to
                    create them and destroy them, and that's it.  The structure details are reserved
                    for main private header for the component,
                    <a
                    href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTablePrivate.h">PerfectHashTablePrivate.h</a>,
                    which is available for inclusion by all of our internal .c files.  Pre-compiled
                    headers are used, such that the only file each individual .c file needs to
                    include is <a
                    href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/stdafx.h">stdafx.h</a>.

                </p>

                <p>

                    The actual perfect hash table interface that implements the required
                    <code>Insert()</code> and <code>Lookup</code> is actually exposed as a COM-esque
                    vtbl structure named <a
                    href="https://github.com/tpn/tracer/blob/515692eb7da838079f482e7ada27c6bda59617eb/PerfectHashTable/PerfectHashTable.h#L438">
                    PERFECT_HASH_TABLE_VTBL</a>.  It's not technically a COM interface, as we don't
                    expose a <code>QueryInterface()</code> function pointer in the first slot, but
                    it has the same initial <code>IUnknown</code> layout, and leverages the
                    reference counting facilities implied by <code>AddRef()</code> and
                    <code>Release()</code> to manage lifetime.  (This differs from all of the other
                    structures, which will typically have both a Create and Destroy-type method.)
                    The structure, with an accompanying definition of the loader function pointer
                    and all public vtbl methods for interacting with the perfect hash table, looks
                    like this:

                </p>

<pre class="code"><code class="language-c">//
// Forward definition of the interface.
//

typedef struct _PERFECT_HASH_TABLE_VTBL PERFECT_HASH_TABLE_VTBL;
typedef PERFECT_HASH_TABLE_VTBL *PPERFECT_HASH_TABLE_VTBL;
typedef PERFECT_HASH_TABLE_VTBL **PPPERFECT_HASH_TABLE;

//
// Define a minimal vtbl encapsulation structure if we're a public
// (i.e. non-internal) build.  The actual structure is defined in
// PerfectHashTablePrivate.h.
//

#ifndef _PERFECT_HASH_TABLE_INTERNAL_BUILD
typedef struct _PERFECT_HASH_TABLE {
    PPERFECT_HASH_TABLE_VTBL Vtbl;
} PERFECT_HASH_TABLE;
#else
typedef struct _PERFECT_HASH_TABLE PERFECT_HASH_TABLE;
#endif
typedef PERFECT_HASH_TABLE *PPERFECT_HASH_TABLE;

typedef
_Check_return_
_Success_(return != 0)
BOOLEAN
(NTAPI LOAD_PERFECT_HASH_TABLE)(
    _In_ PRTL Rtl,
    _In_ PALLOCATOR Allocator,
    _In_opt_ PPERFECT_HASH_TABLE_KEYS Keys,
    _In_ PCUNICODE_STRING Path,
    _Out_ PPERFECT_HASH_TABLE *TablePointer
    );
typedef LOAD_PERFECT_HASH_TABLE *PLOAD_PERFECT_HASH_TABLE;

//
// Define the public perfect hash table functions.
//

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_INSERT)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONG Key,
    _In_ ULONG Value,
    _Out_opt_ PULONG PreviousValue
    );
typedef PERFECT_HASH_TABLE_INSERT *PPERFECT_HASH_TABLE_INSERT;

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_LOOKUP)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONG Key,
    _Out_ PULONG Value
    );
typedef PERFECT_HASH_TABLE_LOOKUP *PPERFECT_HASH_TABLE_LOOKUP;

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_DELETE)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONG Key,
    _Out_opt_ PULONG PreviousValue
    );
typedef PERFECT_HASH_TABLE_DELETE *PPERFECT_HASH_TABLE_DELETE;

//
// Given a key, this routine returns the relative index of the key in the
// underlying hash table.  This is guaranteed to be within the bounds of the
// table size.
//

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_INDEX)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONG Key,
    _In_ PULONG Index
    );
typedef PERFECT_HASH_TABLE_INDEX *PPERFECT_HASH_TABLE_INDEX;

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_HASH)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONG Input,
    _Out_ PULONGLONG Hash
    );
typedef PERFECT_HASH_TABLE_HASH *PPERFECT_HASH_TABLE_HASH;

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_MASK_HASH)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONG Input,
    _Out_ PULONG Masked
    );
typedef PERFECT_HASH_TABLE_MASK_HASH *PPERFECT_HASH_TABLE_MASK_HASH;

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_MASK_INDEX)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONGLONG Input,
    _Out_ PULONG Masked
    );
typedef PERFECT_HASH_TABLE_MASK_INDEX *PPERFECT_HASH_TABLE_MASK_INDEX;

//
// Loaded hash tables are reference counted using the AddRef()/Release() COM
// semantics.  The number of AddRef() calls should match the number of Release()
// calls.  The resources will be released when the final Release() is called.
//

typedef
ULONG
(NTAPI PERFECT_HASH_TABLE_ADD_REF)(
    _In_ PPERFECT_HASH_TABLE Table
    );
typedef PERFECT_HASH_TABLE_ADD_REF *PPERFECT_HASH_TABLE_ADD_REF;

typedef
ULONG
(NTAPI PERFECT_HASH_TABLE_RELEASE)(
    _In_ PPERFECT_HASH_TABLE Table
    );
typedef PERFECT_HASH_TABLE_RELEASE *PPERFECT_HASH_TABLE_RELEASE;

//
// The interface as a vtbl.  Note that we're *almost* a valid COM interface,
// except for the NULL pointer that will occupy the first slot where the impl
// for QueryInterface() is meant to live.
//

typedef struct _PERFECT_HASH_TABLE_VTBL {
    PVOID Unused;
    PPERFECT_HASH_TABLE_ADD_REF AddRef;
    PPERFECT_HASH_TABLE_RELEASE Release;
    PPERFECT_HASH_TABLE_INSERT Insert;
    PPERFECT_HASH_TABLE_LOOKUP Lookup;
    PPERFECT_HASH_TABLE_DELETE Delete;
    PPERFECT_HASH_TABLE_INDEX Index;
    PPERFECT_HASH_TABLE_HASH Hash;
    PPERFECT_HASH_TABLE_MASK_HASH MaskHash;
    PPERFECT_HASH_TABLE_MASK_INDEX MaskIndex;
} PERFECT_HASH_TABLE_VTBL;
typedef PERFECT_HASH_TABLE_VTBL *PPERFECT_HASH_TABLE_VTBL;</code></pre>


                <p>

                    The COM-style vtbl pattern worked quite nicely here, and provided the perfect
                    amount of exposure between the public and private definitions of the table
                    interface.  It allows us to mix and match who provides what with regards to
                    the vtbl function pointers, based on the selected algorithm, hash function
                    and masking type.  The
                    <a
                    href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTableConstants.h">PerfectHashTableConstants.h</a>
                    file exposes an internal routine named
                    <a
                    href="https://github.com/tpn/tracer/blob/515692eb7da838079f482e7ada27c6bda59617eb/PerfectHashTable/PerfectHashTableConstants.h#L86">InitializeExtendedVtbl</a>,
                    which looks like this:

                </p>

<pre class="code"><code class="language-c">//
// Helper inline routine for initializing the extended vtbl interface.
//

FORCEINLINE
VOID
InitializeExtendedVtbl(
    _In_ PPERFECT_HASH_TABLE Table,
    _Inout_ PPERFECT_HASH_TABLE_VTBL_EX Vtbl
    )
{
    Vtbl-&gt;AddRef = PerfectHashTableAddRef;
    Vtbl-&gt;Release = PerfectHashTableRelease;
    Vtbl-&gt;Insert = PerfectHashTableInsert;
    Vtbl-&gt;Lookup = PerfectHashTableLookup;
    Vtbl-&gt;Delete = PerfectHashTableDelete;
    Vtbl-&gt;Index = IndexRoutines[Table-&gt;AlgorithmId];
    Vtbl-&gt;Hash = HashRoutines[Table-&gt;HashFunctionId];
    Vtbl-&gt;MaskHash = MaskHashRoutines[Table-&gt;MaskFunctionId];
    Vtbl-&gt;MaskIndex = MaskIndexRoutines[Table-&gt;MaskFunctionId];
    Vtbl-&gt;SeededHash = SeededHashRoutines[Table-&gt;HashFunctionId];
    Table-&gt;Vtbl = Vtbl;
}</code></pre>

                <p>

                    Note that, thanks to COM, the first five routines can actually be serviced by
                    generic, algorithm-agnostic implementations.  That is, because the
                    <code><a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTableInsert.c">Insert()</a></code>,
                    <code><a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTableLookup.c">Lookup()</a></code>,
                    and
                    <code><a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTableDelete.c">Delete()</a></code>

                    routines simply use the <code>Index()</code> routine to
                    obtain the array offset for the given input key, they don't
                    need to know anything about the backend algorithm, hash or
                    masking type.  This actually makes all of these functions
                    very simple, as can be seen below:

                </p>

                <div class="tab-box language box-table-functions">
                    <ul class="tabs">
                        <li data-content="content-table-functions-insert">Insert</li>
                        <li data-content="content-table-functions-lookup">Lookup</li>
                        <li data-content="content-table-functions-delete">Delete</li>
                        <li data-content="content-table-functions-addref">AddRef</li>
                        <li data-content="content-table-functions-release">Release</li>
                    </ul>
                    <div class="content">
<pre class="code content-table-functions-insert"><code class="language-c">_Use_decl_annotations_
HRESULT
PerfectHashTableInsert(
    PPERFECT_HASH_TABLE Table,
    ULONG Key,
    ULONG Value,
    PULONG PreviousValue
    )
/*++

Routine Description:

    Looks up given key in a perfect hash table and returns the value set by
    the Insert() routine.  If no insertion has taken place for this key, this
    routine guarantees to return 0 as the value.

    N.B. If Key did not appear in the original set the hash table was created
         from, the behavior of this routine is undefined.  (In practice, the
         key will hash to either an existing key's location or an empty slot,
         so there is potential to corrupt the table in the sense that previously
         inserted values will be trampled over.)

Arguments:

    Table - Supplies a pointer to the table to insert the key/value into.

    Key - Supplies the key to insert.

    Value - Supplies the value to insert.

    PreviousValue - Optionally supplies a pointer that will receive the previous
        value at the relevant table location prior to this insertion.  If no
        prior insertion, the previous value is guaranteed to be 0.

Return Value:

    S_OK in all normal operating conditions.  E_FAIL may be returned in some
    cases when passed a key not in the original input set.  The PreviousValue
    parameter, if non-NULL, will be cleared in this case.

--*/
{
    ULONG Index;
    ULONG Existing;
    HRESULT Result;

    //
    // Obtain the index for this key.
    //

    Result = Table-&gt;Vtbl-&gt;Index(Table, Key, &amp;Index);

    if (FAILED(Result)) {

        //
        // Clear the caller's pointer if applicable and return error.
        //

        if (ARGUMENT_PRESENT(PreviousValue)) {
            *PreviousValue = 0;
        }

        return E_FAIL;
    }

    //
    // Get the existing value.
    //

    Existing = Table-&gt;Values[Index];

    //
    // Write the new value.
    //

    Table-&gt;Values[Index] = Value;

    //
    // Update the caller's pointer if applicable.
    //

    if (ARGUMENT_PRESENT(PreviousValue)) {
        *PreviousValue = Existing;
    }

    return S_OK;
}</code></pre>
<pre class="code content-table-functions-lookup"><code class="language-c">_Use_decl_annotations_
HRESULT
PerfectHashTableLookup(
    PPERFECT_HASH_TABLE Table,
    ULONG Key,
    PULONG Value
    )
/*++

Routine Description:

    Looks up given key in a perfect hash table and returns the value set by
    the Insert() routine.  If no insertion has taken place for this key, this
    routine guarantees to return 0 as the value.

    N.B. If key did not appear in the original set the hash table was created
         from, the behavior of this routine is undefined.  (In practice, the
         value returned will be the value for some other key in the table that
         hashes to the same location -- or potentially an empty slot in the
         table.)

Arguments:

    Table - Supplies a pointer to the table for which the key lookup is to be
        performed.

    Key - Supplies the key to look up.

    Value - Receives the vaue for the given key.

Return Value:

    S_OK in all normal operating conditions.  E_FAIL may be returned in some
    cases when passed a key not in the original input set.  The Value parameter
    will be set to NULL in this case.

--*/
{
    ULONG Index;
    HRESULT Result;

    //
    // Obtain the index for this key.
    //

    Result = Table-&gt;Vtbl-&gt;Index(Table, Key, &amp;Index);

    if (FAILED(Result)) {

        //
        // Clear the caller's pointers and return the error code.
        //

        *Value = 0;
        return E_FAIL;
    }

    *Value = Table-&gt;Values[Index];

    return S_OK;
}</code></pre>
<pre class="code content-table-functions-delete"><code class="language-c">_Use_decl_annotations_
HRESULT
PerfectHashTableDelete(
    PPERFECT_HASH_TABLE Table,
    ULONG Key,
    PULONG PreviousValue
    )
/*++

Routine Description:

    Deletes a key from a perfect hash table, optionally returning the value
    prior to deletion back to the caller.  Deletion simply clears the value
    associated with the key, and thus, is a simple O(1) operation.  Deleting
    a key that has not yet been inserted has no effect other than potentially
    returning 0 as the previous value.  That is, a caller can safely issue
    deletes of keys regardless of whether or not said keys were inserted first.

    N.B. If key did not appear in the original set the hash table was created
         from, the behavior of this routine is undefined.  (In practice, the
         key will hash to either an existing key's location or an empty slot,
         so there is potential to corrupt the table in the sense that a
         previously inserted value for an unrelated, valid key will be cleared.)

Arguments:

    Table - Supplies a pointer to the table for which the key is to be deleted.

    Key - Supplies the key to insert.

    PreviousValue - Optionally supplies a pointer that will receive the previous
        value at the relevant table location prior to this deletion.  If no
        prior insertion, the previous value is guaranteed to be 0.

Return Value:

    S_OK in all normal operating conditions.  E_FAIL may be returned in some
    cases when passed a key not in the original input set.  The PreviousValue
    parameter, if non-NULL, will be cleared in this case.

--*/
{
    ULONG Index;
    ULONG Existing;
    HRESULT Result;

    //
    // Obtain the index for this key.
    //

    Result = Table-&gt;Vtbl-&gt;Index(Table, Key, &amp;Index);

    if (FAILED(Result)) {

        //
        // Clear the caller's pointer if applicable and return error.
        //

        if (ARGUMENT_PRESENT(PreviousValue)) {
            *PreviousValue = 0;
        }

        return E_FAIL;
    }

    //
    // Get the existing value.
    //

    Existing = Table-&gt;Values[Index];

    //
    // Clear the value.
    //

    Table-&gt;Values[Index] = 0;

    //
    // Update the caller's pointer if applicable.
    //

    if (ARGUMENT_PRESENT(PreviousValue)) {
        *PreviousValue = Existing;
    }

    return S_OK;
}</code></pre>
<pre class="code content-table-functions-addref"><code class="language-c">_Use_decl_annotations_
ULONG
PerfectHashTableAddRef(
    PPERFECT_HASH_TABLE Table
    )
/*++

Routine Description:

    Increments the reference count for a perfect hash table.

Arguments:

    Table - Supplies a pointer to the table for which the reference count
        is to be incremented.

Return Value:

    The new reference count.

--*/
{
    return InterlockedIncrement(&amp;Table-&gt;ReferenceCount);
}</code></pre>
<pre class="code content-table-functions-release"><code class="language-c">_Use_decl_annotations_
ULONG
PerfectHashTableRelease(
    PPERFECT_HASH_TABLE Table
    )
/*++

Routine Description:

    Decrements the reference count associated with a perfect hash table.  If
    this is the last reference, the table is destroyed.

Arguments:

    Table - Supplies a pointer to the table for which the reference count
        is to be decremented.

Return Value:

    The new reference count.

--*/
{
    ULONG Count = InterlockedDecrement(&amp;Table-&gt;ReferenceCount);
    PPERFECT_HASH_TABLE TablePointer = Table;

    if (Count &gt; 0) {
        return Count;
    }

    DestroyPerfectHashTable(&amp;TablePointer, NULL);

    return Count;
}</code></pre>
                    </div>
                </div>

                <!--
                <p>

                    I prefer this COM-style vtbl approach to the cmph project's approach, which
                    uses giant switch statements to select appropriate backends, e.g.:

                </p>

<pre class="code"><code class="language-c">
cmph_t *cmph_new(cmph_config_t *mph)
{
	cmph_t *mphf = NULL;
	double c = mph-&gt;c;

	DEBUGP("Creating mph with algorithm %s\n", cmph_names[mph-&gt;algo]);
	switch (mph-&gt;algo)
	{
		case CMPH_CHM:
			DEBUGP("Creating chm hash\n");
			mphf = chm_new(mph, c);
			break;
		case CMPH_BMZ: /* included - Fabiano */
			DEBUGP("Creating bmz hash\n");
			mphf = bmz_new(mph, c);
			break;
		case CMPH_BMZ8: /* included - Fabiano */
			DEBUGP("Creating bmz8 hash\n");
			mphf = bmz8_new(mph, c);
			break;
		case CMPH_BRZ: /* included - Fabiano */
			DEBUGP("Creating brz hash\n");
			if (c &gt;= 2.0) brz_config_set_algo(mph, CMPH_FCH);
			else brz_config_set_algo(mph, CMPH_BMZ8);
			mphf = brz_new(mph, c);
			break;
		case CMPH_FCH: /* included - Fabiano */
			DEBUGP("Creating fch hash\n");
			mphf = fch_new(mph, c);
			break;
		case CMPH_BDZ: /* included - Fabiano */
			DEBUGP("Creating bdz hash\n");
			mphf = bdz_new(mph, c);
			break;
		case CMPH_BDZ_PH: /* included - Fabiano */
			DEBUGP("Creating bdz_ph hash\n");
			mphf = bdz_ph_new(mph, c);
			break;
		case CMPH_CHD_PH: /* included - Fabiano */
			DEBUGP("Creating chd_ph hash\n");
			mphf = chd_ph_new(mph, c);
			break;
		case CMPH_CHD: /* included - Fabiano */
			DEBUGP("Creating chd hash\n");
			mphf = chd_new(mph, c);
			break;
		default:
			assert(0);
	}
	return mphf;
}

int cmph_dump(cmph_t *mphf, FILE *f)
{
	switch (mphf-&gt;algo)
	{
		case CMPH_CHM:
			return chm_dump(mphf, f);
		case CMPH_BMZ: /* included - Fabiano */
			return bmz_dump(mphf, f);
		case CMPH_BMZ8: /* included - Fabiano */
			return bmz8_dump(mphf, f);
		case CMPH_BRZ: /* included - Fabiano */
			return brz_dump(mphf, f);
		case CMPH_FCH: /* included - Fabiano */
			return fch_dump(mphf, f);
		case CMPH_BDZ: /* included - Fabiano */
			return bdz_dump(mphf, f);
		case CMPH_BDZ_PH: /* included - Fabiano */
			return bdz_ph_dump(mphf, f);
		case CMPH_CHD_PH: /* included - Fabiano */
			return chd_ph_dump(mphf, f);
		case CMPH_CHD: /* included - Fabiano */
			return chd_dump(mphf, f);
		default:
			assert(0);
	}
	assert(0);
	return 0;
}
</code></pre>
                -->

                <p>

                    The <code>Index()</code> routine is algorithm-specific, and forms the backbone of
                    the perfect hash table functionality: the ability to take a key and return a
                    unique index that can be used to offset into an array of data.

                </p>

                <p>

                    Here's what the <code>
                    <a
                    href="https://github.com/tpn/tracer/blob/db04ecfbd9162c838c4d747d745b10d786890cd3/PerfectHashTable/Chm_01.c#L3291">Index()</a></code>
                    routine looks like for our CHM algorithm implementation.  Note that it too
                    leverages the COM interface for driving the hash and masking routines.

                </p>

<pre class="code"><code class="language-c">_Use_decl_annotations_
HRESULT
PerfectHashTableIndexImplChm01(
    PPERFECT_HASH_TABLE Table,
    ULONG Key,
    PULONG Index
    )
/*++

Routine Description:

    Looks up given key in a perfect hash table and returns its index.

    N.B. If Key did not appear in the original set the hash table was created
         from, the behavior of this routine is undefined.  (In practice, the
         key will hash to either an existing key's location or an empty slot,
         so there is potential for returning a non-unique index.)

Arguments:

    Table - Supplies a pointer to the table for which the key lookup is to be
        performed.

    Key - Supplies the key to look up.

    Index - Receives the index associated with this key.  The index will be
        between 0 and NumberOfKeys-1, and can be safely used to offset directly
        into an appropriately sized array (e.g. Table-&gt;Values[]).

Return Value:

    S_OK on success, E_FAIL if the underlying hash function returned a failure.
    This will happen if the two hash values for a key happen to be identical.
    It shouldn't happen once a perfect graph has been created (i.e. it only
    happens when attempting to solve the graph).  The Index parameter will
    be cleared in the case of E_FAIL.

--*/
{
    ULONG Masked;
    ULONG Vertex1;
    ULONG Vertex2;
    ULONG MaskedLow;
    ULONG MaskedHigh;
    PULONG Assigned;
    ULONGLONG Combined;
    ULARGE_INTEGER Hash;

    //
    // Hash the incoming key into the 64-bit representation, which is two
    // 32-bit ULONGs in disguise, each one driven by a separate seed value.
    //

    if (FAILED(Table-&gt;Vtbl-&gt;Hash(Table, Key, &amp;Hash.QuadPart))) {
        goto Error;
    }

    //
    // Mask each hash value such that it falls within the confines of the
    // number of vertices.  That is, make sure the value is between 0 and
    // Table-&gt;NumberOfVertices-1.
    //

    if (FAILED(Table-&gt;Vtbl-&gt;MaskHash(Table, Hash.LowPart, &amp;MaskedLow))) {
        goto Error;
    }

    if (FAILED(Table-&gt;Vtbl-&gt;MaskHash(Table, Hash.HighPart, &amp;MaskedHigh))) {
        goto Error;
    }

    //
    // Obtain the corresponding vertex values for the masked high and low hash
    // values.  These are derived from the "assigned" array that we construct
    // during the creation routine's assignment step (GraphAssign()).
    //

    Assigned = Table-&gt;Data;

    Vertex1 = Assigned[MaskedLow];
    Vertex2 = Assigned[MaskedHigh];

    //
    // Combine the two values, then perform the index masking operation, such
    // that our final index into the array falls within the confines of the
    // number of edges, or keys, in the table.  That is, make sure the index
    // value is between 0 and Table-&gt;Keys-&gt;NumberOfElements-1.
    //

    Combined = (ULONGLONG)Vertex1 + (ULONGLONG)Vertex2;

    if (FAILED(Table-&gt;Vtbl-&gt;MaskIndex(Table, Combined, &amp;Masked))) {
        goto Error;
    }

    //
    // Update the caller's pointer and return success.  The resulting index
    // value represents the array offset index for this given key in the
    // underlying table, and is guaranteed to be unique amongst the original
    // keys in the input set.
    //

    *Index = Masked;

    return S_OK;

Error:

    //
    // Clear the caller's pointer and return failure.  We should only hit this
    // point if the caller supplies a key that both: a) wasn't in the original
    // input set, and b) happens to result in a hash value where both the high
    // part and low part are identical, which is rare, but not impossible.
    //

    *Index = 0;

    return E_FAIL;
}
</code></pre>

                <p>

                    This routine lives in our
                    <a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/Chm_01.c">Chm_01.c</a>
                    file, which is our only algorithm backend at the moment.  This file, together
                    with its counterpart
                    <a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/Chm_01.h">Chm_01.h</a>
                    header, features all of the algorithm-specific structures and routines related
                    to the implementation.  It is here we define the graph structures specific to
                    the CHM algorithm: <code>GRAPH_DIMENSIONS</code>, <code>GRAPH_INFO</code>, and
                    <code>GRAPH</code>.

                </p>

                <div class="tab-box language box-chm01-structs">
                    <ul class="tabs">
                        <li data-content="content-chm01-structs-graph_dimensions">GRAPH_DIMENSIONS</li>
                        <li data-content="content-chm01-structs-graph_info">GRAPH_INFO</li>
                        <li data-content="content-chm01-structs-graph">GRAPH</li>
                    </ul>
                    <div class="content">
<pre class="code content-chm01-structs-graph_dimensions"><code class="language-c">//
// Define the primary dimensions governing the graph size.
//

typedef struct _GRAPH_DIMENSIONS {

    //
    // Number of edges in the graph.  This corresponds to the number of keys
    // in our input set.  If modulus masking is active, the number of keys and
    // the number of edges will be identical.  Otherwise, the number of edges
    // will be the number of keys rounded up to a power of 2.
    //

    ULONG NumberOfEdges;

    //
    // Total number of edges in the graph.  This will be twice the size of the
    // NumberOfEdges value above, due to the quirky way the underlying r-graph
    // algorithm captures two hash values in the same list and offsets the
    // second set after the first, e.g.:
    //
    //      Edge2 = Edge1 + Graph-&gt;NumberOfEdges;
    //

    ULONG TotalNumberOfEdges;

    //
    // Number of vertices in the graph.  This will vary based on the masking
    // type.  It is doubled every time a graph resize event is encountered.
    //

    ULONG NumberOfVertices;

    //
    // The number of edges in the graph, rounded up to a power of 2, and then
    // shifted the appropriate amount to extract the exponent part for 2^n.
    //

    BYTE NumberOfEdgesPowerOf2Exponent;

    //
    // As above, but rounded up to the next power of 2 first.
    //

    BYTE NumberOfEdgesNextPowerOf2Exponent;

    //
    // The same exponent logic applied to the number of vertices as per the
    // NumberOfVertices field above.
    //

    BYTE NumberOfVerticesPowerOf2Exponent;

    //
    // And again for the next value.
    //

    BYTE NumberOfVerticesNextPowerOf2Exponent;

} GRAPH_DIMENSIONS;
C_ASSERT(sizeof(GRAPH_DIMENSIONS) == 16);
typedef GRAPH_DIMENSIONS *PGRAPH_DIMENSIONS;</code></pre>
<pre class="code content-chm01-structs-graph_info"><code class="language-c">//
// Define various memory offsets associated with a given graph structure.
// This allows parallel worker threads to reset their local GRAPH instance
// back to the initial state each time they want to try a new random seed.
//

typedef struct _GRAPH_INFO {

    //
    // Number of pages consumed by the entire graph and all backing arrays.
    //

    ULONG NumberOfPagesPerGraph;

    //
    // Page size (e.g. 4096, 2MB).
    //

    ULONG PageSize;

    //
    // Total number of graphs created.  This will match the maximum concurrency
    // level of the upstream context.
    //

    ULONG NumberOfGraphs;

    //
    // Number of RTL_BITMAP structures used by the graph.
    //

    USHORT NumberOfBitmaps;

    //
    // Size of the GRAPH structure.
    //

    USHORT SizeOfGraphStruct;

    //
    // System allocation granularity.  We align the memory map for the on-disk
    // structure using this value initially.
    //

    ULONG AllocationGranularity;

    //
    // If a masking type other than modulus is active, the AbsoluteEdge() needs
    // a way to mask edge values that exceed the number of edges in the table.
    // It does this via EdgeMask, which is initialized to the number of edges
    // (which will be power-of-2 sized for non-modulus masking), minus 1, such
    // that all lower bits will be set.
    //

    ULONG EdgeMask;

    //
    // Also capture the mask required to isolate vertices.
    //

    ULONG VertexMask;

    //
    // Graph dimensions.  This information is duplicated in the graph due to
    // it being accessed frequently.
    //

    GRAPH_DIMENSIONS Dimensions;

    //
    // Pointer to the owning context.
    //

    PPERFECT_HASH_TABLE_CONTEXT Context;

    //
    // Base address of the entire graph allocation.
    //

    union {
        PVOID BaseAddress;
        struct _GRAPH *FirstGraph;
    };

    //
    // Array sizes.
    //

    ULONGLONG EdgesSizeInBytes;
    ULONGLONG NextSizeInBytes;
    ULONGLONG FirstSizeInBytes;
    ULONGLONG PrevSizeInBytes;
    ULONGLONG AssignedSizeInBytes;
    ULONGLONG ValuesSizeInBytes;

    //
    // Deleted edges bitmap buffer size.
    //

    ULONGLONG DeletedEdgesBitmapBufferSizeInBytes;

    //
    // Visited vertices bitmap buffer size.
    //

    ULONGLONG VisitedVerticesBitmapBufferSizeInBytes;

    //
    // Assigned bitmap buffer size.
    //

    ULONGLONG AssignedBitmapBufferSizeInBytes;

    //
    // Index bitmap buffer size.
    //

    ULONGLONG IndexBitmapBufferSizeInBytes;

    //
    // The allocation size of the graph, including structure size and all
    // array and bitmap buffer sizes.
    //

    ULONGLONG AllocSize;

    //
    // Allocation size rounded up to the nearest page size multiple.
    //

    ULONGLONG FinalSize;

} GRAPH_INFO;
typedef GRAPH_INFO *PGRAPH_INFO;</pre></code>
<pre class="code content-chm01-structs-graph"><code class="language-c">//
// Define the graph structure.  This represents an r-graph, or a hypergraph,
// or an r-partite 2-uniform graph, or any other seemingly unlimited number
// of names floating around in academia for what appears to be exactly the
// same thing.
//

typedef struct _Struct_size_bytes_(SizeOfStruct) _GRAPH {

    //
    // List entry used to push the graph onto the context's work list.
    //

    SLIST_ENTRY ListEntry;

    //
    // Edge and vertex masks that can be used when non-modulus masking is in
    // place.  Both of these values are duplicated from the info structure as
    // they are accessed frequently.
    //
    //

    ULONG EdgeMask;
    ULONG VertexMask;

    //
    // Duplicate the mask type, as well, as this directs AbsoluteEdge()'s
    // decision to use the two masks above.
    //

    PERFECT_HASH_TABLE_MASK_FUNCTION_ID MaskFunctionId;

    //
    // Duplicate the number of keys, as this is also frequently referenced.
    //

    ULONG NumberOfKeys;

    //
    // Structure size, in bytes.
    //

    _Field_range_(== , sizeof(struct _GRAPH)) ULONG SizeOfStruct;

    //
    // Graph flags.
    //

    GRAPH_FLAGS Flags;

    //
    // Pointer to the info structure describing various sizes.
    //

    PGRAPH_INFO Info;

    //
    // Graph attempt.  This ID is derived from an interlocked increment against
    // Context-&gt;Attempts, and represents the attempt number across all threads.
    //

    ULONGLONG Attempt;

    //
    // A localized attempt number that reflects the number of attempts made
    // by just this thread.
    //

    ULONG ThreadAttempt;

    //
    // Thread ID of the thread that owns us.  Each callback thread is provided
    // a single graph, and will attempt to solve the perfect hash table until
    // told otherwise.  Thus, there's a 1:1 relationship between graph instance
    // and owning thread.
    //

    ULONG ThreadId;

    //
    // Counter that is incremented each time we delete an edge during the
    // acyclic graph detection stage.
    //

    ULONG DeletedEdgeCount;

    //
    // Counter that is incremented each time we visit a vertex during the
    // assignment stage.
    //

    ULONG VisitedVerticesCount;

    //
    // Capture collisions during assignment step.
    //

    ULONG Collisions;

    //
    // Inline the GRAPH_DIMENSIONS structure.  This is available from the
    // GRAPH_INFO structure, however, it's accessed frequently, so we inline
    // it to avoid the extra level of indirection.
    //

    union {

        struct {
            ULONG NumberOfEdges;
            ULONG TotalNumberOfEdges;
            ULONG NumberOfVertices;
            BYTE NumberOfEdgesPowerOf2Exponent;
            BYTE NumberOfEdgesNextPowerOf2Exponent;
            BYTE NumberOfVerticesPowerOf2Exponent;
            BYTE NumberOfVerticesNextPowerOf2Exponent;
        };

        GRAPH_DIMENSIONS Dimensions;
    };

    //
    // Duplicate the context pointer.  (This is also available from Info.)
    //

    PPERFECT_HASH_TABLE_CONTEXT Context;

    //
    // Edges array.  The number of elements in this array is governed by the
    // TotalNumberOfEdges field, and will be twice the number of edges.
    //

    PEDGE Edges;

    //
    // Array of the "next" edge array, as per the referenced papers.  The number
    // of elements in this array is also governed by TotalNumberOfEdges.
    //

    PEDGE Next;

    //
    // Array of vertices.  Number of elements is governed by the
    // NumberOfVertices field.
    //

    PVERTEX First;

    //
    // The original CHM paper in 1996 references a "prev" array to "facilitate
    // fast deletion".  However, the chmp project appears to have switched to
    // using bitmaps.  Let's reserve a slot for the "prev" array anyway.
    //

    PVERTEX Prev;

    //
    // Array of assigned vertices.  Number of elements is governed by the
    // NumberOfVertices field.
    //

    PVERTEX Assigned;

    //
    // Array of values indexed by the offsets in the Assigned array.  This
    // essentially allows us to simulate a loaded table that supports the
    // Insert(), Index() and Lookup() routines as part of graph validation.
    //

    PULONG Values;

    //
    // Bitmap used to capture deleted edges as part of the acyclic detection
    // stage.  The SizeOfBitMap will reflect TotalNumberOfEdges.
    //

    RTL_BITMAP DeletedEdges;

    //
    // Bitmap used to capture vertices visited as part of the assignment stage.
    // The SizeOfBitMap will reflect NumberOfVertices.
    //

    RTL_BITMAP VisitedVertices;

    //
    // Bitmap used to test the correctness of the Assigned array.
    //

    RTL_BITMAP AssignedBitmap;

    //
    // Bitmap used to track indices during the assignment step.
    //

    RTL_BITMAP IndexBitmap;

    //
    // Capture the seeds used for each hash function employed by the graph.
    //

    ULONG NumberOfSeeds;

    struct {
        union {
            struct {
                union {
                    ULONG Seed1;
                    ULONG FirstSeed;
                };
                ULONG Seed2;
            };
            ULARGE_INTEGER Seeds12;
        };
        union {
            struct {
                ULONG Seed3;
                union {
                    ULONG Seed4;
                    ULONG LastSeed;
                };
            };
            ULARGE_INTEGER Seeds34;
        };
    };

} GRAPH;
typedef GRAPH *PGRAPH;</code></pre>
                    </div>
                </div>

                <p>

                    In general, the structures and functions defined in our
                    <a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTablePrivate.h">PerfectHashTablePrivate.h</a>
                    file are algorithm agnostic.  That is, they don't deal with the notion of a
                    graph, as that's an implementation detail of the CHM algorithm.

                </p>

                <a class="xref" name="code-walkthrough"></a>
                <h1>Code Walkthrough</h1>

                <p>

                    WIP.

                </p>

                <hr/>

                <!--
                <h3>Contact</h3>
                <p>

                    Like the article?  Let me know!  E-mail: &#116;&#114;&#101;&#110;&#116;&#64;&#116;&#114;&#101;&#110;&#116;&#46;&#109;&#101;

                </p>
                -->

            </div>

        </section>

        <script type="text/javascript">
            // Google Analytics
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-24686252-1', 'auto');
            ga('send', 'pageview');
        </script>

        <section class="section section-footer">
            <div class="container">
                <small><small>
                    <p>
                        <a
                        href="https://github.com/tpn/website/blob/master/perfect-hash-table/index.html">
                        View this page's source on GitHub.</a>
                    </p>
                </small></small>
                <p>
                    <a href="https://twitter.com/trentnelson" class="twitter-follow-button" data-show-count="false">Follow @trentnelson</a>
                    <iframe src="https://ghbtns.com/github-btn.html?user=tpn&type=follow" frameborder="0" scrolling="0" width="170px" height="20px"></iframe>
                </p>
                </small>
            </div>
        </section>

        <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

    </body>
</html>
