<!DOCTYPE html>
<html>
    <!-- vim:set tw=100 ts=8 sw=4 et                                                            :-->
    <head>
        <title>Perfect Hash Table</title>
        <meta name="msvalidate.01" content="E828541C73A98C315E3D6B8C88EF6057" />
        <meta name="viewport" content="width=device-width, initial-scale=0.65, maximum-scale=1.0" />

        <!-- https://www.google.com/fonts#UsePlace:use/Collection:Lato:200,300,300italic -->
        <!--
        <meta name="viewport" content="width=device-width, min-width=1100px, initial-scale=0.7, maximum-scale=1.0, shrint-to-fit=no" />
        <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:200,300,300italic">
        <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:300,300i,400,400i">
        -->
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400" rel="stylesheet">
        <link rel="stylesheet" href="//oss.maxcdn.com/normalize/3.0.1/normalize.min.css">
        <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="../prism.css">
        <link rel="stylesheet" href="../home.css">
        <link rel="stylesheet" href="page.css">
        <script src="//oss.maxcdn.com/jquery/2.1.1/jquery.min.js"></script>
        <script src="../prism.js"></script>
        <script src="../home.js"></script>
        <script src="page.js"></script>
    </head>
    <body>

        <header class="header">
            <div class="header-logo" href="#">
                <!--
                <a class="homename" href="http://trent.me"><strong>T</strong>rent <strong>N</strong>elson</a>
                -->
                <a class="homename" href=".."><strong>T</strong>rent <strong>N</strong>elson</a>
            </div>
            <ul class="header-links">
                <li><a href="#home"><i class="fa fa-home"></i>Creating a Perfect Hash Table</a></li>
                <li><a href="#contents"><i class="fa fa-align-left"></i> Contents</a></li>
                <li><a href="https://github.com/tpn/tracer/tree/master/PerfectHashTable" target="_blank"><i class="fa fa-github"></i> GitHub</a></li>
                <li><a href="https://twitter.com/trentnelson" target="_blank"><i class="fa fa-twitter"></i> Twitter</a></li>
                <!--
                <li><a href="https://twitter.com/trentnelson" class="twitter-follow-button" data-show-count="false">Follow @trentnelson</a></li>
                -->
            </ul>
        </header>

        <a class="xref" name="home"></a>
        <section class="section section-hero">
            <div class="container">
                <h1>
                    Creating a Perfect Hash Table
                </h1>
                <h3>
                    A Performant, Parallel, Random Acyclic-Hypergraph Approach
                </h3>
            </div>
        </section>

        <section class="section section-summary">
            <div class="container">

                <small>
                    Current status: <strong>draft</strong>.  Last update: 7th June, 2018.
                    Target publish date: Monday, 11th June, 2018.

                    <!--
                    <a href="https://github.com/tpn/website/blob/master/perfect-hash-table/index.html">
                    View this page's source on GitHub.</a>-->

                <hr/>

                <h3>TL;DR</h3>
                <p>

                    This article documents a recent assignment regarding the implementation of a
                    perfect hash table.  I discuss the initial goal as a set of requirements, then
                    capture design decisions and provide an implementation overview.

                </p>
                </small>

                <hr/>
                <h2>Requirements</h2>
                <p>

                    Author a perfect hash table component that provides offline table
                    generation and fast lookup performance.  Assume a key and value width of
                    <code>ULONG</code> (32 bits).  Optimize for key set sizes ranging from
                    10,000 to 40,000 keys on average, with up to 100,000 keys on the high end.

                </p>

                <p>

                    Assume a key distribution similar to that of shared library address offsets;
                    not linear, but definitely not random, either.  Do not make assumptions about
                    the presence of leading or trailing zeros (i.e. alignment), although feel free
                    to optimize for this if it doesn't detract from the component's performance on
                    less predictable key sets.

                </p>

                <p>

                    Prioritize lookup speed over generation speed.  Optimize the lookup algorithm
                    to minimize latency involved in a single <code>Value = Lookup(Key)</code>
                    call.  Table generation will be done ahead of time, in a separate process, and
                    only needs to ensure that tables can be generated in a reasonable amount of
                    time given the size of the input key set.  Linear overhead is ideal, quadratic
                    less so, exponential would be infeasible.

                </p>

                <p>

                    Prioritize lookup speed over table size (memory requirements).  A larger table
                    size, within reason, is an acceptable trade-off if it yields a faster lookup
                    speed.  A minimal perfect hash table, where each key maps to exactly one table
                    location, is not a requirement, nor is it prohibited.

                </p>

                <p>

                    Note the inevitable tradeoff in size and performance with regards to the masking
                    method used by the implementation.  Modulus-oriented solutions, those that use
                    the % operator in C, tend to be slower (modulus division can take upward of 90
                    cycles), but yield smaller table sizes.  Solutions relying on power-of-2 based
                    table sizes boast much faster masking routines (e.g. <code>Input &amp;
                    (Size-1)</code>), but incur greater table size overhead.

                </p>

                <p>

                    The offline generation process takes, as its input, a key file.  The file will
                    be an array of <code>ULONG</code> keys (i.e. binary data).  The number of
                    elements in the array can be ascertained by dividing the file size by
                    <code>sizeof(ULONG)</code>.  It produces, as its output, a perfect hash table
                    file that can be subsequently loaded and used in separate processes.

                </p>

                <p>

                    Callers wishing to use a given perfect hash table will need to load the file
                    produced in the step above.  This will yield an interface from which the hash
                    table can be interacted with.  At a bare minimum, the interface should support
                    the following semantics:

                </p>

<pre class="code"><code class="language-c">extern PULONG Table;
ULONG Lookup(ULONG Key) { return Table[PerfectHashFunction(Key)]; }
VOID Insert(ULONG Key, ULONG Value) { Table[PerfectHashFunction(Key)] = Value; }
</code></pre>

                <p>

                    The interface requirements are flexible and can be extended as long as the
                    criteria above are met at a bare minimum.

                </p>

                <p>

                    The behavior of looking up or inserting a key that wasn't in the original input
                    set is undefined.  That is, the implementation is not required to detect or
                    protect against this scenario &mdash; that is the responsibility of the caller.

                </p>

                <p>

                    Feel free to review existing works on the topic, particularly the cmph open
                    source project, the GNU gperf library, and the plethora of papers on the subject
                    of perfect hashing and minimal perfect hashing.

                </p>

            </div>
        </section>
        <hr/>

        <section class="section section-toc">
            <div class="container">

                <a class="xref" name="contents"></a>
                <h1>Contents</h1>

                <p>
                    <ul class="toc-list">

                        <li>

                            <a href="#getting-started">Getting Started</a>

                        </li>

                        <li>

                            <a href="#algorithm-decisions">Algorithm Decisions</a>

                        </li>

                        <li>

                            <a href="#initial-design-decisions">Initial Design Decisions</a>

                        </li>

                        <li>

                            <a href="#implementation-notes">Implementation Notes</a>

                        </li>

                        <li>

                            <a href="#code-walkthrough">Code Walkthrough</a>

                            <ul>

                                <li>

                                    <a href="#test-data">Preparing Test Data</a>

                                </li>

                                <li>

                                    <a href="#running-self-test">Running the Self-Test</a>

                                </li>

                                <li>

                                    <a href="#the-info-stream">The <code>:Info</code> Stream</a>

                                </li>

                                <li>

                                    <a href="#self-test-overview">Self-Test Overview</a>

                                </li>

                                <li>

                                    <a href="#context-creation">Context Creation</a>

                                    <ul>

                                        <li>

                                            <a href="#PERFECT_HASH_TABLE_CONTEXT">PERFECT_HASH_TABLE_CONTEXT</a>

                                        </li>

                                        <li>

                                            <a href="#CreatePerfectHashTableContext">CreatePerfectHashTableContext()</a>

                                        </li>

                                    </ul>

                                </li>

                                <li>

                                    <a href="#key-loading">Key Loading</a>

                                    <ul>

                                        <li>

                                            <a href="#PERFECT_HASH_TABLE_KEYS">PERFECT_HASH_TABLE_KEYS</a>

                                        </li>

                                        <li>

                                            <a href="#LoadPerfectHashTableKeys">LoadPerfectHashTableKeys()</a>

                                        </li>

                                    </ul>

                                </li>

                                <li>

                                    <a href="#perfect-hash-table-creation">Perfect Hash Table Creation</a>

                                    <ul>

                                        <li>

                                            <a href="#PERFECT_HASH_TABLE">PERFECT_HASH_TABLE</a>

                                        </li>

                                        <li>

                                            <a href="#CreatePerfectHashTable">CreatePerfectHashTable()</a>

                                        </li>

                                    </ul>

                                </li>

                            </ul>

                        </li>

                    </ul>
                </p>
            </div>
        </section>
        <hr/>

        <section class="section section-body">
            <div class="container">

                <a class="xref" name="getting-started"></a>
                <h1>Getting Started</h1>

                <p>

                    This was an interesting project.  I'd never written a perfect hash table before,
                    nor was I familiar with the landscape for doing such a thing.  I spent about
                    three days reviewing existing work, including the <a
                    href="http://cmph.sourceforge.net">cmph</a> project's source code.  (I ended up
                    collecting about 147 (!) documents on the topic (papers, PhD thesis, slides,
                    etc) in my <a href="https://github.com/tpn/pdfs">PDFs</a> repo over the course
                    of the project.)

                </p>

                <a class="xref" name="algorithm-decisions"></a>
                <h1>Algorithm Decisions</h1>

                <p>

                    The algorithm I settled on is the acyclic random 2-part hypergraph (or r-graph,
                    where r = 2).  The algorithm works as follows: for each key, generate two
                    independent hash values.  Mask these values such that they fall within the
                    confines of the number of <em>vertices</em> picked for the table (more on this
                    later; for now, assume the number of <em>vertices</em> exceeds the number of
                    keys, or <em>edges</em> by at least 2x).  These masked hash values now become
                    the two vertices, and are added to a graph structure by a connecting edge.  The
                    edge is simply the 0..N index being used for enumeration, e.g.:

                </p>

<pre class="code"><code class="language-c">for (Index = 0; Index &lt; NumberOfKeys; Index++) {

    Key = Keys[Index];

    Hash1 = HashFunction1(Key);
    Hash2 = HashFunction2(Key);

    Vertex1 = MaskHashFunction(Hash1);
    Vertex2 = MaskHashFunction(Hash2);

    Edge = Index;

    GraphAddEdge(Graph, Edge, Vertex1, Vertex2);
}</code></pre>

                <p>

                    Once constructed, the graph is assessed to determine whether or not it is
                    acyclic.  If the graph is acyclic, it means every vertex has at most 1 degree
                    of connectivity to other vertices.  We want an acyclic graph.  If it's not
                    acyclic, the attempt has failed, the graph is thrown away, and a new attempt
                    is made, using new random seed data to drive the two hash functions.  Once
                    an acyclic graph is found, it's relatively straight forward to convert this
                    into a data structure that can be used as a perfect hash table.

                </p>

                <p>

                    This algorithm first has roots in <a href="https://github.com/tpn/pdfs/blob/master/A%20Versatile%20Graph%20Structure%20for%20Edge-Oriented%20Graph%20Algorithms%20-%201987%20(Ebert1987AVD).pdf">
                    A Versatile Data Structure for Edge-Oriented Graph Algorithms (Ebert, 1987)</a>.
                    Its application to perfect hashing appears in <a
                    href="https://github.com/tpn/pdfs/blob/master/A%20Family%20of%20Perfect%20Hashing%20Methods%20-%201996%20(TR0242).pdf">
                    A Family of Perfect Hashing Methods (Majewski, Wormald, Havas, Czech, 1996)</a>,
                    where they focus on more rigorous proofs of the runtime complexity associated
                    with acyclic r-graphs, extending on the work in their earlier paper, <a
                    href="https://github.com/tpn/pdfs/blob/3dc05fb22d87d86117802a2dc206926c79981ca3/Graphs,%20Hypergraphs%20and%20Hashing.pdf">Graphs, Hypergraphs and Hashing (1994)</a>, and their initial works on
                    the matter, <a
                    href="https://github.com/tpn/pdfs/blob/master/An%20Optimal%20Algorithm%20for%20Generating%20Minimal%20Perfect%20Hash%20Functions%20-%201992%20(10.1.1.51.5566).pdf">
                    An Optimal Algorithm for generating Minimal Perfect Hash Functions (Majewski,
                    Havas, Czech, 1992)</a>.

                </p>

                <p>

                    There is one thing that stood out in their 1996 paper (page 9) that I was able
                    to verify experimentally (after finally hacking the
                    <a href="https://github.com/tpn/cmph-2.0/blob/master/src/chm.c">CHM</a> algorithm
                    in the CMHP project into a working state).  To summarize, sans heavy math notation: the
                    probability that we find a perfect hash solution by identifying an acyclic
                    r-graph (r = 2) is 99.9% within 18 iterations.  On average, a solution is found
                    in &radic;3 attempts.

                </p>

                <p>

                    This is referred to as a <a
                    href="https://en.wikipedia.org/wiki/Geometric_distribution">geometric
                    distribution</a>, something I hadn't come across before.  It is a very desirable
                    trait, especially for this particular problem.  In essence, the more we do it,
                    the more likely we'll figure it out.  Assuming there is a solution (i.e. the
                    hash function is performing properly), the chance of us not solving it is provably
                    infinitesimal, which is neat.

                </p>

                <p>

                    Consider a gambler who is going all-in on heads against the Universe in an
                    infinite game of coin toss.  We are the Universe.  Play it long enough, and
                    we'll eventually see a tail.

                </p>

                <p>

                    I made the following notes around day 3 of the project:

                </p>

                <div class="blockquote"><small>

                    <p>

                        In my experiments, even with 10 million random keys, graph creation took about
                        6-7 seconds on the 64-bit release build.  On average it found a solution usually
                        within 1-3 iterations.  The worst-case I saw was 7 iterations.

                    </p>


                    <p>

                        The nice thing about the graph creation step is that each iteration can be
                        palmed off to a threadpool worker, such that you can attempt to find a graph
                        solution in parallel up to NCPU.  On my 12 core box at home, there is a very
                        high probability I'll find a solution in the first batch of 12 iterations
                        submitted in parallel &mdash; thus, my clock time for solving the perfect hash
                        stays relatively consistent at 6-7 seconds, give or take.

                    </p>


                    <p>

                        This algorithm is not the fastest, nor the most state-of-the-art, nor does
                        it have the lowest bits-per-key storage requirement, nor will I be aiming
                        for a minimal perfect hash function.  However, it's simple (relatively),
                        I understand it, I can explain it on a whiteboard without having to
                        continually reference a paper, and it's definitely fast enough in the
                        generation stage based on our target static key sets.  It's also old; graph
                        theory has flourished since the 60s, and this particular algorithm came onto
                        the scene in 1992, and has been cited widely.

                    </p>

                    <p>

                        (The current state-of-the-art depicted in papers like <a
                        href="https://github.com/tpn/pdfs/blob/master/Fast%20Scalable%20Construction%20of%20(Minimal%20Perfect%20Hash)%20Functions%20-%2022%20Mar%202016,%20v2%20(1603.04330).pdf">
                        Fast Scalable Construction of (Minimal Perfect Hash) Functions (Genuzio,
                        Ottaviano, Vigna, 2016)</a> use "lazy Gaussian elimination" to try tackle
                        the minimal perfect hash problem on ultra-large key sets (in the billions
                        and above).  That is interesting, but not a wise choice for me to tackle in
                        a week, nor does it improve on our target static key sets, which are very
                        modest in size in comparison.)

                    </p>

                    <p>

                        Another reason I'm favoring the algorithm I've chosen is that because the
                        generation stage is so cheap, relatively, and we have that nice
                        probabilistic guarantee that we'll "probably" find a solution by iteration
                        18... that gives us a lot of leeway with regards to experimenting with the
                        underlying hash functions used.  I envision there being much faster, non-mod
                        based hash functions we can experiment with, that actually have relatively
                        poor "randomness" qualities unless a particularly good seed is found.
                        Combined with the threadpool infrastructure for submitting iterations in
                        parallel, I have a hunch that I'll be able to find some very fast hash
                        functions that can still be solved in an acceptable amount of time.  This
                        will help greatly with our evaluation time; reducing the latency and CPU
                        cycles required to perform the lookup.

                    </p>

                    <p>

                        There is one large risk item associated with my current plan: the key
                        validation step of the cmph command line program just flat-out isn't working
                        properly.  The graph generation step <strong>*appears*</strong> to be doing
                        the right thing, at least with regards to finding cyclic graphs and
                        discarding them, etc.  The validation step works on small key sizes,
                        however, after about 500, I'm seeing rampant conflicts and severe
                        degradation of the underlying hash functions (i.e. everything is hashing to
                        394 or 85 or something).

                    </p>

                </small></div>

                <p>

                    The last paragraph depicts some of the issues I had trying to get the cmph
                    program to validate the perfect hash tables it was supposedly generating.  Try
                    as I might, I just couldn't get the thing to generate solutions that were
                    actually valid (despite it reporting that they were valid) after a few hours
                    of fiddling.

                </p>

                <p>

                    More impressively, though, is that the bug survived and still exists in my
                    complete reimplementation of their initial modulus-oriented masking approach.
                    This only became apparent in the latter stages of the project, when I authored
                    more robust validation and test logic.  Thankfully though, my power-of-2 based
                    approach <strong>does</strong> work, and it's a lot faster, so, who knows.  The
                    modulus functionality was only implemented for a reference point, I didn't
                    anticipate using it as the final "fast" version of the perfect hash solution, so
                    I haven't investigated why it doesn't work properly any further.  It's a little
                    disconcerting, though.

                </p>

                <a class="xref" name="initial-design-decisions"></a>
                <h1>Initial Design Decisions</h1>

                <p>

                    A few of the initial guiding sentiments regarding the design follow:

                    <ul>

                        <li>

                            I wanted to be able to easily mix and match different algorithms, hash
                            functions and masking types.  I figured this would make experimentation
                            easier, and generally promote sensible de-coupling of internal
                            components.  Thus, the main interface for creating a perfect hash table
                            is parameterized by three enums for the desired

                            <a href="https://github.com/tpn/tracer/blob/c7092c78aac4e01baf324815f7fbc888cdb6faa0/PerfectHashTable/PerfectHashTable.h#L62">
                            algorithm</a>,

                            <a
                            href="https://github.com/tpn/tracer/blob/c7092c78aac4e01baf324815f7fbc888cdb6faa0/PerfectHashTable/PerfectHashTable.h#L111">
                            hash function</a>, and

                            <a
                            href="https://github.com/tpn/tracer/blob/c7092c78aac4e01baf324815f7fbc888cdb6faa0/PerfectHashTable/PerfectHashTable.h#L170">
                            masking type</a>, respectively.  These identifiers, depicted below, are
                            also stored with the on-disk representation of the perfect hash table,
                            such that the loading component knows which implementations to select
                            when preparing an interface for use.

                <a class="xref" name="enums"></a>
                <div class="tab-box language box-enums">
                    <ul class="tabs">
                        <li data-content="content-enums-algorithm">Algorithm</li>
                        <li data-content="content-enums-hash-function">Hash Function</li>
                        <li data-content="content-enums-masking-type">Masking Type</li>
                    </ul>
                    <div class="content">
<pre class="code content-enums-algorithm"><code class="language-c">//
// Define an enumeration for identifying which backend algorithm variant to
// use for creating the perfect hash table.
//

typedef enum _PERFECT_HASH_TABLE_ALGORITHM_ID {

    //
    // Explicitly define a null algorithm to take the 0-index slot.
    // This makes enum validation easier.
    //

    PerfectHashTableNullAlgorithmId = 0,

    //
    // Begin valid algorithms.
    //

    PerfectHashTableDefaultAlgorithmId = 1,
    PerfectHashTableChm01AlgorithmId = 1,

    //
    // End valid algorithms.
    //

    //
    // N.B. Keep the next value last.
    //

    PerfectHashTableInvalidAlgorithmId,

} PERFECT_HASH_TABLE_ALGORITHM_ID;
typedef PERFECT_HASH_TABLE_ALGORITHM_ID *PPERFECT_HASH_TABLE_ALGORITHM_ID;

//
// Provide a simple inline algorithm validation routine.
//

FORCEINLINE
BOOLEAN
IsValidPerfectHashTableAlgorithmId(
    _In_ PERFECT_HASH_TABLE_ALGORITHM_ID AlgorithmId
    )
{
    return (
        AlgorithmId &gt; PerfectHashTableNullAlgorithmId &amp;&amp;
        AlgorithmId &lt; PerfectHashTableInvalidAlgorithmId
    );
}
</code></pre>
<pre class="code content-enums-hash-function"><code class="language-c">//
// Define an enumeration for identifying which hash function variant to use.
//

typedef enum _PERFECT_HASH_TABLE_HASH_FUNCTION_ID {

    //
    // Explicitly define a null algorithm to take the 0-index slot.
    // This makes enum validation easier.
    //

    PerfectHashTableNullHashFunctionId              = 0,

    //
    // Begin valid hash functions.
    //

    PerfectHashTableHashCrc32RotateFunctionId       = 1,
    PerfectHashTableDefaultHashFunctionId           = 1,

    PerfectHashTableHashJenkinsFunctionId           = 2,

    //
    // N.B. The following three hash functions are purposefully terrible from
    //      the perspective of generating a good distribution of hash values.
    //      They all have very simple operations and are intended to test the
    //      theory that even with a poor hash function, once we find the right
    //      seed, the hash quality is unimportant.
    //

    PerfectHashTableHashRotateXorFunctionId         = 3,
    PerfectHashTableHashAddSubXorFunctionId         = 4,
    PerfectHashTableHashXorFunctionId               = 5,

    //
    // End valid hash functions.
    //

    //
    // N.B. Keep the next value last.
    //

    PerfectHashTableInvalidHashFunctionId,

} PERFECT_HASH_TABLE_HASH_FUNCTION_ID;
typedef PERFECT_HASH_TABLE_HASH_FUNCTION_ID
      *PPERFECT_HASH_TABLE_HASH_FUNCTION_ID;

//
// Provide a simple inline hash function validation routine.
//

FORCEINLINE
BOOLEAN
IsValidPerfectHashTableHashFunctionId(
    _In_ PERFECT_HASH_TABLE_HASH_FUNCTION_ID HashFunctionId
    )
{
    return (
        HashFunctionId &gt; PerfectHashTableNullHashFunctionId &amp;&amp;
        HashFunctionId &lt; PerfectHashTableInvalidHashFunctionId
    );
}
</code></pre>
<pre class="code content-enums-masking-type"><code class="language-c">//
// Define an enumeration for identifying the type of table masking used by the
// underlying perfect hash table.  This has performance and size implications.
// Modulus masking typically results in smaller tables at the expenses of slower
// modulus-based hash functions.  Non-modulus masking requires power-of-2 sized
// tables, which will be larger, but the resulting mask function can be done
// by logical AND instructions, which are fast.
//

typedef enum _PERFECT_HASH_TABLE_MASK_FUNCTION_ID {

    //
    // Null masking type.
    //

    PerfectHashTableNullMaskFunctionId          = 0,

    //
    // Being valid masking types.
    //

    PerfectHashTableModulusMaskFunctionId       = 1,

    PerfectHashTableAndMaskFunctionId           = 2,
    PerfectHashTableDefaultMaskFunctionId       = 2,

    PerfectHashTableXorAndMaskFunctionId        = 3,
    PerfectHashTableFoldAutoMaskFunctionId      = 4,
    PerfectHashTableFoldOnceMaskFunctionId      = 5,
    PerfectHashTableFoldTwiceMaskFunctionId     = 6,
    PerfectHashTableFoldThriceMaskFunctionId    = 7,

    //
    // End valid masking types.
    //

    //
    // N.B. Keep the next value last.
    //

    PerfectHashTableInvalidMaskFunctionId,


} PERFECT_HASH_TABLE_MASK_FUNCTION_ID;
typedef PERFECT_HASH_TABLE_MASK_FUNCTION_ID
      *PPERFECT_HASH_TABLE_MASK_FUNCTION_ID;

//
// Provide a simple inline masking type validation routine.
//

FORCEINLINE
BOOLEAN
IsValidPerfectHashTableMaskFunctionId(
    _In_ PERFECT_HASH_TABLE_MASK_FUNCTION_ID MaskFunctionId
    )
{
    return (
        MaskFunctionId &gt; PerfectHashTableNullMaskFunctionId &amp;&amp;
        MaskFunctionId &lt; PerfectHashTableInvalidMaskFunctionId
    );
}

//
// Masking tends to fall into one of two buckets: modulus and not-modulus.
// Provide an inline routine that guarantees to match all current and future
// modulus masking function IDs.
//

FORCEINLINE
BOOLEAN
IsModulusMasking(
    _In_ PERFECT_HASH_TABLE_MASK_FUNCTION_ID MaskFunctionId
    )
{
    return MaskFunctionId == PerfectHashTableModulusMaskFunctionId;
}
</code></pre>
                            </div>
                        </div>


                        </li>

                    </ul>

                    <ul>

                        <li>

                            The problem parallelizes incredibly well.  The more threads you can have
                            looking for an acylic graph, the better.  There was no way I was
                            implementing this as a single-threaded solution; it's rare to get a
                            problem so well suited to a multithreaded approach, and the threadpool
                            scaffolding provided by NT is sublime, so, that was a no-brainer.
                            <br/>

                            <small>

                            (In fact, the way that it is currently written, you can't actually solve
                            the graph <strong>*without*</strong> using a threadpool.  You can
                            dictate the level of concurrency you want, and specifying 1 means the
                            threadpool only gets 1 thread, which makes debugging easier, but there
                            is no way to isolate the solving process to avoid this.  This is by
                            design.)

                            </small>

                        </li>

                    </ul>

                    <ul>

                        <li>

                            Memory map all the things.  All file system interaction is achieved via
                            sections and memory maps.  There is a separate threadpool used for
                            handling file-oriented work (such as saving the solution to disk in
                            parallel whilst the main thread verifies it is correct &mdash; which
                            it will be unless we've got internal bugs).  Memory mappings are used
                            for the source .keys file, the resulting .pht1 file for the perfect
                            hash table, and the .pht1:Info NTFS stream used to capture metadata
                            about the perfect hash table (such as which algorithm, hash function,
                            and masking function was used, sizes, stats etc).

                        </li>

                    </ul>

                    <ul>


                        <li>

                            For handling testing, due to the limited time constraints, I went for a
                            big-bang systems level "self-test".  Coupled with aggressive internal
                            ASSERT()ing, this worked out pretty well.  A self-test .exe is provided,
                            which, when pointed at a data directory and given a set of algorithm,
                            hash and mask IDs, will process all *.keys files in the directory; for
                            each one, a perfect hash file is created, the on-disk version is then
                            loaded and subsequently tested.  This is all handled by the routine
                            <a
                            href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/SelfTestPerfectHashTable.c">
                            SelfTestPerfectHashTable</a>, which also serves as a good example for
                            how to exercise the entire system end-to-end.

                        </li>

                    </ul>

                </p>

                <a class="xref" name="implementation-notes"></a>
                <h1>Implementation Notes</h1>

                <small>

                    (The following section serves as a general introduction to the project's
                    organization, concepts, files, etc.  It aims to provide a bit of
                    background context to some of the idioms that will be observed when reviewing
                    the code.  The next section, <a href="#code-walkthrough">Code Walkthrough</a>,
                    digs into the implementation details in a more end-to-end type fashion.)

                </small>

                <p>

                    From an implementation perspective, I decided to develop the component as part
                    of my <a href="https://github.com/tpn/tracer">tracer</a> project for two
                    reasons: a) the tracer project already has a lot of scaffolding in place
                    (especially for the boring bits) that I'd be able to re-use, which is useful
                    when time-constrained, and b) a perfect hash table is actually a pretty
                    neat component that I can see my self using down the track.

                </p>

                <p>

                    The implementation is creatively-named <a
                    href="https://github.com/tpn/tracer/tree/master/PerfectHashTable">PerfectHashTable</a>,
                    and is a DLL.

                </p>

                <p>

                    The <a
                    href="https://github.com/tpn/tracer/tree/master/PerfectHashTableSelfTestExe">PerfectHashTableSelfTestExe</a>
                    project, also very creatively-named, is the standalone self-test .exe.

                </p>

                <p>

                    Development of the project was done in Visual Studio 2017 via the
                    <a href="https://github.com/tpn/tracer/tree/master/PerfectHashTable.sln">PerfectHashTable.sln</a>
                    solution, which includes Debug, Release, PGInstrument and PGOptimize
                    configurations.

                </p>

                <p>

                    The coding style and conventions are the same as the rest of the tracer project:
                    Cutler Normal Form C, heavily commented, and generally very NT-esque in style.

                </p>

                <p>

                    Components in the tracer project have an interesting restriction in that they
                    can't use the C runtime library in any way (due to the need to potentially be
                    remote injected into a target process, and not wanting to deal with varying
                    levels of C runtime availability).  Instead, they make extensive, exclusive
                    use of the NT runtime primitives afforded by <code>ntdll.dll</code>,
                    <code>kernel32.dll</code>, and <code>ntoskrnl.exe</code>.  This
                    functionality is wrapped up by a component named
                    <a href="https://github.com/tpn/tracer/tree/master/Rtl">Rtl</a> (inspired by the
                    NT runtime library of the same name).  There is a huge structure named
                    <a
                    href="https://github.com/tpn/tracer/blob/7fc2741b27e5705f4dc93f5dbf1280e08d7dfa8a/Rtl/Rtl.h#L6380">RTL</a>,
                    which contains the kitchen sink of things we need across all components, as well
                    as function pointers to DDK-type functionality normally not available if you're
                    including <code>&lt;Windows.h&gt;</code> (such as bitmaps, AVL tables, prefix
                    tables, etc).

                    <small>(Note: one of the original design objectives of the RTL structure was to
                    facilitate writing components that could run in both kernel and user mode
                    without needing recompilation or #ifdefs.  That is, you could author and test
                    the vast majority of your functionality in user mode, where development,
                    debugging and testing is easier, without needing to deploy it into the kernel
                    until much later in the development lifecycle.)</small>

                </p>

                <p>

                    The reason for mentioning this is that the first two parameters for every public
                    function of the PerfectHashTable component are usually <code>Rtl</code> and
                    <code>Allocator</code>.  E.g.:


                </p>


<pre class="code"><code class="language-c">_Use_decl_annotations_
BOOLEAN
CreatePerfectHashTable(
    PRTL Rtl,
    PALLOCATOR Allocator,
    PPERFECT_HASH_TABLE_CONTEXT Context,
    PERFECT_HASH_TABLE_ALGORITHM_ID AlgorithmId,
    PERFECT_HASH_TABLE_MASK_FUNCTION_ID MaskFunctionId,
    PERFECT_HASH_TABLE_HASH_FUNCTION_ID HashFunctionId,
    PULARGE_INTEGER NumberOfTableElementsPointer,
    PPERFECT_HASH_TABLE_KEYS Keys,
    PCUNICODE_STRING HashTablePath
    )</code></pre>

                <p>

                    The <a
                    href="https://github.com/tpn/tracer/blob/7fc2741b27e5705f4dc93f5dbf1280e08d7dfa8a/Rtl/Memory.h#L464">ALLOCATOR</a>
                    structure encapsulates the memory management functions like
                    <code>Calloc()</code> and <code>Free()</code>, such that we're not dependent
                    upon CRT linkage to equivalent functions.  Initially, it just had the basic set
                    of routines required to mimic Python's <code>PyMemAllocatorEx</code> structure:
                    <code>malloc()</code>, <code>calloc()</code>, <code>realloc()</code> and
                    <code>free()</code>.  However, since then, it grew to support a plethora of
                    routines, many of which driven by the TraceStore component, but also more
                    general functions, such as aligned memory allocation.

                </p>

                <p>

                    Short story long: if you see <code>Rtl</code> our <code>Allocator</code>
                    variables anywhere, it's just our runtime glue or memory allocator
                    stuff.

                </p>

                <p>

                    Moving on, all public functions get a SAL-annotated function pointer typedef in
                    the main public header file (<a
                    href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTable.h">PerfectHashTable.h</a>).
                    Functions are defined for creating and destroying keys and perfect hash tables,
                    creating and destroying contexts (a context is required to create a table), and
                    loading a previously-created table.

                <p>

                    I use the same API pattern I used for the
                    <a href="https://github.com/tpn/tracer/tree/master/StringTable2">StringTable2</a>
                    component, which I discuss
                    <a href="https://trent.me/is-prefix-of-string-in-table/#implementation-considerations">here</a>.
                    This involves defining a structure named
                    <a
                    href="https://github.com/tpn/tracer/blob/515692eb7da838079f482e7ada27c6bda59617eb/PerfectHashTable/PerfectHashTable.h#L561">PERFECT_HASH_TABLE_API</a>,
                    and an inline function,
                    <a
                    href="https://github.com/tpn/tracer/blob/515692eb7da838079f482e7ada27c6bda59617eb/PerfectHashTable/PerfectHashTable.h#L624">LoadPerfectHashTableApi()</a>.

                </p>

                <p>

                    The structure looks like this:

                </p>

<pre class="code"><code class="language-c">typedef struct _Struct_size_bytes_(SizeOfStruct) _PERFECT_HASH_TABLE_API {

    //
    // Size of the structure, in bytes.  This is filled in automatically by
    // LoadPerfectHashTableApi() based on the initial SizeOfAnyApi parameter.
    //

    _In_range_(sizeof(struct _PERFECT_HASH_TABLE_API),
               sizeof(struct _PERFECT_HASH_TABLE_API_EX)) ULONG SizeOfStruct;

    //
    // Number of function pointers contained in the structure.  This is filled
    // in automatically by LoadPerfectHashTableApi() based on the initial
    // SizeOfAnyApi parameter divided by the size of a function pointer.
    //

    ULONG NumberOfFunctions;

    //
    // Begin function pointers.
    //

    union {
        PVOID FirstFunctionPointer;
        PSET_C_SPECIFIC_HANDLER SetCSpecificHandler;
    };

    PLOAD_PERFECT_HASH_TABLE_KEYS LoadPerfectHashTableKeys;
    PDESTROY_PERFECT_HASH_TABLE_KEYS DestroyPerfectHashTableKeys;

    PCREATE_PERFECT_HASH_TABLE_CONTEXT CreatePerfectHashTableContext;
    PDESTROY_PERFECT_HASH_TABLE_CONTEXT DestroyPerfectHashTableContext;

    PCREATE_PERFECT_HASH_TABLE CreatePerfectHashTable;
    PLOAD_PERFECT_HASH_TABLE LoadPerfectHashTable;
    PTEST_PERFECT_HASH_TABLE TestPerfectHashTable;

    PINITIALIZE_PERFECT_HASH_TABLE_ALLOCATOR InitializePerfectHashAllocator;

    PINITIALIZE_PERFECT_HASH_TABLE_ALLOCATOR_FROM_RTL_BOOTSTRAP
        InitializePerfectHashAllocatorFromRtlBootstrap;

} PERFECT_HASH_TABLE_API;
typedef PERFECT_HASH_TABLE_API *PPERFECT_HASH_TABLE_API;

</code></pre>

                <p>

                    And the loader routine looks like this:

                </p>

<pre class="code"><code class="language-c">FORCEINLINE
BOOLEAN
LoadPerfectHashTableApi(
    _In_ PRTL Rtl,
    _Inout_ HMODULE *ModulePointer,
    _In_opt_ PUNICODE_STRING ModulePath,
    _In_ ULONG SizeOfAnyApi,
    _Out_writes_bytes_all_(SizeOfAnyApi) PPERFECT_HASH_TABLE_ANY_API AnyApi
    )
/*++

Routine Description:

    Loads the perfect hash table module and resolves all API functions for
    either the PERFECT_HASH_TABLE_API or PERFECT_HASH_TABLE_API_EX structure.
    The desired API is indicated by the SizeOfAnyApi parameter.

    Example use:

        PERFECT_HASH_TABLE_API_EX GlobalApi;
        PPERFECT_HASH_TABLE_API_EX Api;

        Success = LoadPerfectHashApi(Rtl,
                                     NULL,
                                     NULL,
                                     sizeof(GlobalApi),
                                     (PPERFECT_HASH_TABLE_ANY_API)&amp;GlobalApi);
        ASSERT(Success);
        Api = &amp;GlobalApi;

    In this example, the extended API will be provided as our sizeof(GlobalApi)
    will indicate the structure size used by PERFECT_HASH_TABLE_API_EX.

Arguments:

    Rtl - Supplies a pointer to an initialized RTL structure.

    ModulePointer - Optionally supplies a pointer to an existing module handle
        for which the API symbols are to be resolved.  May be NULL.  If not
        NULL, but the pointed-to value is NULL, then this parameter will
        receive the handle obtained by LoadLibrary() as part of this call.
        If the string table module is no longer needed, but the program will
        keep running, the caller should issue a FreeLibrary() against this
        module handle.

    ModulePath - Optionally supplies a pointer to a UNICODE_STRING structure
        representing a path name of the string table module to be loaded.
        If *ModulePointer is not NULL, it takes precedence over this parameter.
        If NULL, and no module has been provided via *ModulePointer, loading
        will be attempted via LoadLibraryA("PerfectHashTable.dll")'.

    SizeOfAnyApi - Supplies the size, in bytes, of the underlying structure
        pointed to by the AnyApi parameter.

    AnyApi - Supplies the address of a structure which will receive resolved
        API function pointers.  The API furnished will depend on the size
        indicated by the SizeOfAnyApi parameter.

Return Value:

    TRUE on success, FALSE on failure.

--*/
</code></pre>

                <p>

                    This is a little quirky, but I've found it to be a useful way to
                    dynamically load and use small components at runtime without requiring
                    any static linking or dll export/import glue.

                </p>

                <p>

                    Publicly, the keys and context structures are opaque.  Routines are exposed to
                    create them and destroy them, and that's it.  The structure details are reserved
                    for main private header for the component,
                    <a
                    href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTablePrivate.h">PerfectHashTablePrivate.h</a>,
                    which is available for inclusion by all of our internal .c files.  Pre-compiled
                    headers are used, such that the only file each individual .c file needs to
                    include is <a
                    href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/stdafx.h">stdafx.h</a>.

                </p>

                <p>

                    The actual perfect hash table interface that implements the required
                    <code>Insert()</code> and <code>Lookup()</code> is actually exposed as a
                    COM-style vtbl structure named
                    <a href="https://github.com/tpn/tracer/blob/515692eb7da838079f482e7ada27c6bda59617eb/PerfectHashTable/PerfectHashTable.h#L438">
                    PERFECT_HASH_TABLE_VTBL</a>.  It's not technically a COM interface, as we don't
                    expose a <code>QueryInterface()</code> function pointer in the first slot, but
                    it has the same initial <code>IUnknown</code> layout, and leverages the
                    reference counting facilities implied by <code>AddRef()</code> and
                    <code>Release()</code> to manage lifetime.  (This differs from all of the other
                    structures, which will typically have both a Create and Destroy-type method.)
                    The structure, with an accompanying definition of the loader function pointer
                    and all public vtbl methods for interacting with the perfect hash table, looks
                    like this:

                </p>

<pre class="code"><code class="language-c">//
// Forward definition of the interface.
//

typedef struct _PERFECT_HASH_TABLE_VTBL PERFECT_HASH_TABLE_VTBL;
typedef PERFECT_HASH_TABLE_VTBL *PPERFECT_HASH_TABLE_VTBL;
typedef PERFECT_HASH_TABLE_VTBL **PPPERFECT_HASH_TABLE;

//
// Define a minimal vtbl encapsulation structure if we're a public
// (i.e. non-internal) build.  The actual structure is defined in
// PerfectHashTablePrivate.h.
//

#ifndef _PERFECT_HASH_TABLE_INTERNAL_BUILD
typedef struct _PERFECT_HASH_TABLE {
    PPERFECT_HASH_TABLE_VTBL Vtbl;
} PERFECT_HASH_TABLE;
#else
typedef struct _PERFECT_HASH_TABLE PERFECT_HASH_TABLE;
#endif
typedef PERFECT_HASH_TABLE *PPERFECT_HASH_TABLE;

typedef
_Check_return_
_Success_(return != 0)
BOOLEAN
(NTAPI LOAD_PERFECT_HASH_TABLE)(
    _In_ PRTL Rtl,
    _In_ PALLOCATOR Allocator,
    _In_opt_ PPERFECT_HASH_TABLE_KEYS Keys,
    _In_ PCUNICODE_STRING Path,
    _Out_ PPERFECT_HASH_TABLE *TablePointer
    );
typedef LOAD_PERFECT_HASH_TABLE *PLOAD_PERFECT_HASH_TABLE;

//
// Define the public perfect hash table functions.
//

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_INSERT)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONG Key,
    _In_ ULONG Value,
    _Out_opt_ PULONG PreviousValue
    );
typedef PERFECT_HASH_TABLE_INSERT *PPERFECT_HASH_TABLE_INSERT;

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_LOOKUP)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONG Key,
    _Out_ PULONG Value
    );
typedef PERFECT_HASH_TABLE_LOOKUP *PPERFECT_HASH_TABLE_LOOKUP;

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_DELETE)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONG Key,
    _Out_opt_ PULONG PreviousValue
    );
typedef PERFECT_HASH_TABLE_DELETE *PPERFECT_HASH_TABLE_DELETE;

//
// Given a key, this routine returns the relative index of the key in the
// underlying hash table.  This is guaranteed to be within the bounds of the
// table size.
//

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_INDEX)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONG Key,
    _In_ PULONG Index
    );
typedef PERFECT_HASH_TABLE_INDEX *PPERFECT_HASH_TABLE_INDEX;

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_HASH)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONG Input,
    _Out_ PULONGLONG Hash
    );
typedef PERFECT_HASH_TABLE_HASH *PPERFECT_HASH_TABLE_HASH;

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_MASK_HASH)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONG Input,
    _Out_ PULONG Masked
    );
typedef PERFECT_HASH_TABLE_MASK_HASH *PPERFECT_HASH_TABLE_MASK_HASH;

typedef
HRESULT
(NTAPI PERFECT_HASH_TABLE_MASK_INDEX)(
    _In_ PPERFECT_HASH_TABLE Table,
    _In_ ULONGLONG Input,
    _Out_ PULONG Masked
    );
typedef PERFECT_HASH_TABLE_MASK_INDEX *PPERFECT_HASH_TABLE_MASK_INDEX;

//
// Loaded hash tables are reference counted using the AddRef()/Release() COM
// semantics.  The number of AddRef() calls should match the number of Release()
// calls.  The resources will be released when the final Release() is called.
//

typedef
ULONG
(NTAPI PERFECT_HASH_TABLE_ADD_REF)(
    _In_ PPERFECT_HASH_TABLE Table
    );
typedef PERFECT_HASH_TABLE_ADD_REF *PPERFECT_HASH_TABLE_ADD_REF;

typedef
ULONG
(NTAPI PERFECT_HASH_TABLE_RELEASE)(
    _In_ PPERFECT_HASH_TABLE Table
    );
typedef PERFECT_HASH_TABLE_RELEASE *PPERFECT_HASH_TABLE_RELEASE;

//
// The interface as a vtbl.  Note that we're *almost* a valid COM interface,
// except for the NULL pointer that will occupy the first slot where the impl
// for QueryInterface() is meant to live.
//

typedef struct _PERFECT_HASH_TABLE_VTBL {
    PVOID Unused;
    PPERFECT_HASH_TABLE_ADD_REF AddRef;
    PPERFECT_HASH_TABLE_RELEASE Release;
    PPERFECT_HASH_TABLE_INSERT Insert;
    PPERFECT_HASH_TABLE_LOOKUP Lookup;
    PPERFECT_HASH_TABLE_DELETE Delete;
    PPERFECT_HASH_TABLE_INDEX Index;
    PPERFECT_HASH_TABLE_HASH Hash;
    PPERFECT_HASH_TABLE_MASK_HASH MaskHash;
    PPERFECT_HASH_TABLE_MASK_INDEX MaskIndex;
} PERFECT_HASH_TABLE_VTBL;
typedef PERFECT_HASH_TABLE_VTBL *PPERFECT_HASH_TABLE_VTBL;</code></pre>


                <p>

                    The COM-style vtbl pattern worked quite nicely here, and provided the perfect
                    amount of exposure between the public and private definitions of the table
                    interface.  It allows us to mix and match who provides what with regards to
                    the vtbl function pointers, based on the selected algorithm, hash function
                    and masking type.  The
                    <a
                    href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTableConstants.h">PerfectHashTableConstants.h</a>
                    file exposes an internal routine named
                    <a
                    href="https://github.com/tpn/tracer/blob/515692eb7da838079f482e7ada27c6bda59617eb/PerfectHashTable/PerfectHashTableConstants.h#L86">InitializeExtendedVtbl</a>,
                    which looks like this:

                </p>

<pre class="code"><code class="language-c">//
// Helper inline routine for initializing the extended vtbl interface.
//

FORCEINLINE
VOID
InitializeExtendedVtbl(
    _In_ PPERFECT_HASH_TABLE Table,
    _Inout_ PPERFECT_HASH_TABLE_VTBL_EX Vtbl
    )
{
    Vtbl-&gt;AddRef = PerfectHashTableAddRef;
    Vtbl-&gt;Release = PerfectHashTableRelease;
    Vtbl-&gt;Insert = PerfectHashTableInsert;
    Vtbl-&gt;Lookup = PerfectHashTableLookup;
    Vtbl-&gt;Delete = PerfectHashTableDelete;
    Vtbl-&gt;Index = IndexRoutines[Table-&gt;AlgorithmId];
    Vtbl-&gt;Hash = HashRoutines[Table-&gt;HashFunctionId];
    Vtbl-&gt;MaskHash = MaskHashRoutines[Table-&gt;MaskFunctionId];
    Vtbl-&gt;MaskIndex = MaskIndexRoutines[Table-&gt;MaskFunctionId];
    Vtbl-&gt;SeededHash = SeededHashRoutines[Table-&gt;HashFunctionId];
    Table-&gt;Vtbl = Vtbl;
}</code></pre>

                <p>

                    Note that, thanks to COM, the first five routines can actually be serviced by
                    generic, algorithm-agnostic implementations.  That is, because the
                    <code><a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTableInsert.c">Insert()</a></code>,
                    <code><a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTableLookup.c">Lookup()</a></code>,
                    and
                    <code><a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTableDelete.c">Delete()</a></code>

                    routines simply use the <code>Index()</code> routine to
                    obtain the array offset for the given input key, they don't
                    need to know anything about the backend algorithm, hash or
                    masking type.  This actually makes all of these functions
                    very simple, as can be seen below:

                </p>

                <div class="tab-box language box-table-functions">
                    <ul class="tabs">
                        <li data-content="content-table-functions-insert">Insert</li>
                        <li data-content="content-table-functions-lookup">Lookup</li>
                        <li data-content="content-table-functions-delete">Delete</li>
                        <li data-content="content-table-functions-addref">AddRef</li>
                        <li data-content="content-table-functions-release">Release</li>
                    </ul>
                    <div class="content">
<pre class="code content-table-functions-insert"><code class="language-c">_Use_decl_annotations_
HRESULT
PerfectHashTableInsert(
    PPERFECT_HASH_TABLE Table,
    ULONG Key,
    ULONG Value,
    PULONG PreviousValue
    )
/*++

Routine Description:

    Looks up given key in a perfect hash table and returns the value set by
    the Insert() routine.  If no insertion has taken place for this key, this
    routine guarantees to return 0 as the value.

    N.B. If Key did not appear in the original set the hash table was created
         from, the behavior of this routine is undefined.  (In practice, the
         key will hash to either an existing key's location or an empty slot,
         so there is potential to corrupt the table in the sense that previously
         inserted values will be trampled over.)

Arguments:

    Table - Supplies a pointer to the table to insert the key/value into.

    Key - Supplies the key to insert.

    Value - Supplies the value to insert.

    PreviousValue - Optionally supplies a pointer that will receive the previous
        value at the relevant table location prior to this insertion.  If no
        prior insertion, the previous value is guaranteed to be 0.

Return Value:

    S_OK in all normal operating conditions.  E_FAIL may be returned in some
    cases when passed a key not in the original input set.  The PreviousValue
    parameter, if non-NULL, will be cleared in this case.

--*/
{
    ULONG Index;
    ULONG Existing;
    HRESULT Result;

    //
    // Obtain the index for this key.
    //

    Result = Table-&gt;Vtbl-&gt;Index(Table, Key, &amp;Index);

    if (FAILED(Result)) {

        //
        // Clear the caller's pointer if applicable and return error.
        //

        if (ARGUMENT_PRESENT(PreviousValue)) {
            *PreviousValue = 0;
        }

        return E_FAIL;
    }

    //
    // Get the existing value.
    //

    Existing = Table-&gt;Values[Index];

    //
    // Write the new value.
    //

    Table-&gt;Values[Index] = Value;

    //
    // Update the caller's pointer if applicable.
    //

    if (ARGUMENT_PRESENT(PreviousValue)) {
        *PreviousValue = Existing;
    }

    return S_OK;
}</code></pre>
<pre class="code content-table-functions-lookup"><code class="language-c">_Use_decl_annotations_
HRESULT
PerfectHashTableLookup(
    PPERFECT_HASH_TABLE Table,
    ULONG Key,
    PULONG Value
    )
/*++

Routine Description:

    Looks up given key in a perfect hash table and returns the value set by
    the Insert() routine.  If no insertion has taken place for this key, this
    routine guarantees to return 0 as the value.

    N.B. If key did not appear in the original set the hash table was created
         from, the behavior of this routine is undefined.  (In practice, the
         value returned will be the value for some other key in the table that
         hashes to the same location -- or potentially an empty slot in the
         table.)

Arguments:

    Table - Supplies a pointer to the table for which the key lookup is to be
        performed.

    Key - Supplies the key to look up.

    Value - Receives the vaue for the given key.

Return Value:

    S_OK in all normal operating conditions.  E_FAIL may be returned in some
    cases when passed a key not in the original input set.  The Value parameter
    will be set to NULL in this case.

--*/
{
    ULONG Index;
    HRESULT Result;

    //
    // Obtain the index for this key.
    //

    Result = Table-&gt;Vtbl-&gt;Index(Table, Key, &amp;Index);

    if (FAILED(Result)) {

        //
        // Clear the caller's pointers and return the error code.
        //

        *Value = 0;
        return E_FAIL;
    }

    *Value = Table-&gt;Values[Index];

    return S_OK;
}</code></pre>
<pre class="code content-table-functions-delete"><code class="language-c">_Use_decl_annotations_
HRESULT
PerfectHashTableDelete(
    PPERFECT_HASH_TABLE Table,
    ULONG Key,
    PULONG PreviousValue
    )
/*++

Routine Description:

    Deletes a key from a perfect hash table, optionally returning the value
    prior to deletion back to the caller.  Deletion simply clears the value
    associated with the key, and thus, is a simple O(1) operation.  Deleting
    a key that has not yet been inserted has no effect other than potentially
    returning 0 as the previous value.  That is, a caller can safely issue
    deletes of keys regardless of whether or not said keys were inserted first.

    N.B. If key did not appear in the original set the hash table was created
         from, the behavior of this routine is undefined.  (In practice, the
         key will hash to either an existing key's location or an empty slot,
         so there is potential to corrupt the table in the sense that a
         previously inserted value for an unrelated, valid key will be cleared.)

Arguments:

    Table - Supplies a pointer to the table for which the key is to be deleted.

    Key - Supplies the key to delete.

    PreviousValue - Optionally supplies a pointer that will receive the previous
        value at the relevant table location prior to this deletion.  If no
        prior insertion, the previous value is guaranteed to be 0.

Return Value:

    S_OK in all normal operating conditions.  E_FAIL may be returned in some
    cases when passed a key not in the original input set.  The PreviousValue
    parameter, if non-NULL, will be cleared in this case.

--*/
{
    ULONG Index;
    ULONG Existing;
    HRESULT Result;

    //
    // Obtain the index for this key.
    //

    Result = Table-&gt;Vtbl-&gt;Index(Table, Key, &amp;Index);

    if (FAILED(Result)) {

        //
        // Clear the caller's pointer if applicable and return error.
        //

        if (ARGUMENT_PRESENT(PreviousValue)) {
            *PreviousValue = 0;
        }

        return E_FAIL;
    }

    //
    // Get the existing value.
    //

    Existing = Table-&gt;Values[Index];

    //
    // Clear the value.
    //

    Table-&gt;Values[Index] = 0;

    //
    // Update the caller's pointer if applicable.
    //

    if (ARGUMENT_PRESENT(PreviousValue)) {
        *PreviousValue = Existing;
    }

    return S_OK;
}</code></pre>
<pre class="code content-table-functions-addref"><code class="language-c">_Use_decl_annotations_
ULONG
PerfectHashTableAddRef(
    PPERFECT_HASH_TABLE Table
    )
/*++

Routine Description:

    Increments the reference count for a perfect hash table.

Arguments:

    Table - Supplies a pointer to the table for which the reference count
        is to be incremented.

Return Value:

    The new reference count.

--*/
{
    return InterlockedIncrement(&amp;Table-&gt;ReferenceCount);
}</code></pre>
<pre class="code content-table-functions-release"><code class="language-c">_Use_decl_annotations_
ULONG
PerfectHashTableRelease(
    PPERFECT_HASH_TABLE Table
    )
/*++

Routine Description:

    Decrements the reference count associated with a perfect hash table.  If
    this is the last reference, the table is destroyed.

Arguments:

    Table - Supplies a pointer to the table for which the reference count
        is to be decremented.

Return Value:

    The new reference count.

--*/
{
    ULONG Count = InterlockedDecrement(&amp;Table-&gt;ReferenceCount);
    PPERFECT_HASH_TABLE TablePointer = Table;

    if (Count &gt; 0) {
        return Count;
    }

    DestroyPerfectHashTable(&amp;TablePointer, NULL);

    return Count;
}</code></pre>
                    </div>
                </div>

                <p>

                    I prefer this COM-style vtbl approach to the cmph project's approach, which
                    uses giant switch statements to select appropriate backends, e.g.:

                </p>

<pre class="code"><code class="language-c">
cmph_t *cmph_new(cmph_config_t *mph)
{
	cmph_t *mphf = NULL;
	double c = mph-&gt;c;

	DEBUGP("Creating mph with algorithm %s\n", cmph_names[mph-&gt;algo]);
	switch (mph-&gt;algo)
	{
		case CMPH_CHM:
			DEBUGP("Creating chm hash\n");
			mphf = chm_new(mph, c);
			break;
		case CMPH_BMZ: /* included - Fabiano */
			DEBUGP("Creating bmz hash\n");
			mphf = bmz_new(mph, c);
			break;
		case CMPH_BMZ8: /* included - Fabiano */
			DEBUGP("Creating bmz8 hash\n");
			mphf = bmz8_new(mph, c);
			break;
		case CMPH_BRZ: /* included - Fabiano */
			DEBUGP("Creating brz hash\n");
			if (c &gt;= 2.0) brz_config_set_algo(mph, CMPH_FCH);
			else brz_config_set_algo(mph, CMPH_BMZ8);
			mphf = brz_new(mph, c);
			break;
		case CMPH_FCH: /* included - Fabiano */
			DEBUGP("Creating fch hash\n");
			mphf = fch_new(mph, c);
			break;
		case CMPH_BDZ: /* included - Fabiano */
			DEBUGP("Creating bdz hash\n");
			mphf = bdz_new(mph, c);
			break;
		case CMPH_BDZ_PH: /* included - Fabiano */
			DEBUGP("Creating bdz_ph hash\n");
			mphf = bdz_ph_new(mph, c);
			break;
		case CMPH_CHD_PH: /* included - Fabiano */
			DEBUGP("Creating chd_ph hash\n");
			mphf = chd_ph_new(mph, c);
			break;
		case CMPH_CHD: /* included - Fabiano */
			DEBUGP("Creating chd hash\n");
			mphf = chd_new(mph, c);
			break;
		default:
			assert(0);
	}
	return mphf;
}

int cmph_dump(cmph_t *mphf, FILE *f)
{
	switch (mphf-&gt;algo)
	{
		case CMPH_CHM:
			return chm_dump(mphf, f);
		case CMPH_BMZ: /* included - Fabiano */
			return bmz_dump(mphf, f);
		case CMPH_BMZ8: /* included - Fabiano */
			return bmz8_dump(mphf, f);
		case CMPH_BRZ: /* included - Fabiano */
			return brz_dump(mphf, f);
		case CMPH_FCH: /* included - Fabiano */
			return fch_dump(mphf, f);
		case CMPH_BDZ: /* included - Fabiano */
			return bdz_dump(mphf, f);
		case CMPH_BDZ_PH: /* included - Fabiano */
			return bdz_ph_dump(mphf, f);
		case CMPH_CHD_PH: /* included - Fabiano */
			return chd_ph_dump(mphf, f);
		case CMPH_CHD: /* included - Fabiano */
			return chd_dump(mphf, f);
		default:
			assert(0);
	}
	assert(0);
	return 0;
}
</code></pre>

                <p>

                    The <code>Index()</code> routine is algorithm-specific, and forms the backbone of
                    the perfect hash table functionality: the ability to take a key and return a
                    unique index that can be used to offset into an array of data.

                </p>

                <p>

                    Here's what the <code>
                    <a
                    href="https://github.com/tpn/tracer/blob/db04ecfbd9162c838c4d747d745b10d786890cd3/PerfectHashTable/Chm_01.c#L3291">Index()</a></code>
                    routine looks like for our CHM algorithm implementation.  Note that it too
                    leverages the COM interface for driving the hash and masking routines.

                </p>

<pre class="code"><code class="language-c">_Use_decl_annotations_
HRESULT
PerfectHashTableIndexImplChm01(
    PPERFECT_HASH_TABLE Table,
    ULONG Key,
    PULONG Index
    )
/*++

Routine Description:

    Looks up given key in a perfect hash table and returns its index.

    N.B. If Key did not appear in the original set the hash table was created
         from, the behavior of this routine is undefined.  (In practice, the
         key will hash to either an existing key's location or an empty slot,
         so there is potential for returning a non-unique index.)

Arguments:

    Table - Supplies a pointer to the table for which the key lookup is to be
        performed.

    Key - Supplies the key to look up.

    Index - Receives the index associated with this key.  The index will be
        between 0 and NumberOfKeys-1, and can be safely used to offset directly
        into an appropriately sized array (e.g. Table-&gt;Values[]).

Return Value:

    S_OK on success, E_FAIL if the underlying hash function returned a failure.
    This will happen if the two hash values for a key happen to be identical.
    It shouldn't happen once a perfect graph has been created (i.e. it only
    happens when attempting to solve the graph).  The Index parameter will
    be cleared in the case of E_FAIL.

--*/
{
    ULONG Masked;
    ULONG Vertex1;
    ULONG Vertex2;
    ULONG MaskedLow;
    ULONG MaskedHigh;
    PULONG Assigned;
    ULONGLONG Combined;
    ULARGE_INTEGER Hash;

    //
    // Hash the incoming key into the 64-bit representation, which is two
    // 32-bit ULONGs in disguise, each one driven by a separate seed value.
    //

    if (FAILED(Table-&gt;Vtbl-&gt;Hash(Table, Key, &amp;Hash.QuadPart))) {
        goto Error;
    }

    //
    // Mask each hash value such that it falls within the confines of the
    // number of vertices.  That is, make sure the value is between 0 and
    // Table-&gt;NumberOfVertices-1.
    //

    if (FAILED(Table-&gt;Vtbl-&gt;MaskHash(Table, Hash.LowPart, &amp;MaskedLow))) {
        goto Error;
    }

    if (FAILED(Table-&gt;Vtbl-&gt;MaskHash(Table, Hash.HighPart, &amp;MaskedHigh))) {
        goto Error;
    }

    //
    // Obtain the corresponding vertex values for the masked high and low hash
    // values.  These are derived from the "assigned" array that we construct
    // during the creation routine's assignment step (GraphAssign()).
    //

    Assigned = Table-&gt;Data;

    Vertex1 = Assigned[MaskedLow];
    Vertex2 = Assigned[MaskedHigh];

    //
    // Combine the two values, then perform the index masking operation, such
    // that our final index into the array falls within the confines of the
    // number of edges, or keys, in the table.  That is, make sure the index
    // value is between 0 and Table-&gt;Keys-&gt;NumberOfElements-1.
    //

    Combined = (ULONGLONG)Vertex1 + (ULONGLONG)Vertex2;

    if (FAILED(Table-&gt;Vtbl-&gt;MaskIndex(Table, Combined, &amp;Masked))) {
        goto Error;
    }

    //
    // Update the caller's pointer and return success.  The resulting index
    // value represents the array offset index for this given key in the
    // underlying table, and is guaranteed to be unique amongst the original
    // keys in the input set.
    //

    *Index = Masked;

    return S_OK;

Error:

    //
    // Clear the caller's pointer and return failure.  We should only hit this
    // point if the caller supplies a key that both: a) wasn't in the original
    // input set, and b) happens to result in a hash value where both the high
    // part and low part are identical, which is rare, but not impossible.
    //

    *Index = 0;

    return E_FAIL;
}
</code></pre>

                <p>

                    This routine lives in our
                    <a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/Chm_01.c">Chm_01.c</a>
                    file, which is our only algorithm backend at the moment.  This file, together
                    with its counterpart
                    <a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/Chm_01.h">Chm_01.h</a>
                    header, features all of the algorithm-specific structures and routines related
                    to the implementation.  It is here we define the graph structures specific to
                    the CHM algorithm: <code>GRAPH_DIMENSIONS</code>, <code>GRAPH_INFO</code>, and
                    <code>GRAPH</code>.

                </p>

                <div class="tab-box language box-chm01-structs">
                    <ul class="tabs">
                        <li data-content="content-chm01-structs-graph_dimensions">GRAPH_DIMENSIONS</li>
                        <li data-content="content-chm01-structs-graph_info">GRAPH_INFO</li>
                        <li data-content="content-chm01-structs-graph">GRAPH</li>
                    </ul>
                    <div class="content">
<pre class="code content-chm01-structs-graph_dimensions"><code class="language-c">//
// Define the primary dimensions governing the graph size.
//

typedef struct _GRAPH_DIMENSIONS {

    //
    // Number of edges in the graph.  This corresponds to the number of keys
    // in our input set.  If modulus masking is active, the number of keys and
    // the number of edges will be identical.  Otherwise, the number of edges
    // will be the number of keys rounded up to a power of 2.
    //

    ULONG NumberOfEdges;

    //
    // Total number of edges in the graph.  This will be twice the size of the
    // NumberOfEdges value above, due to the quirky way the underlying r-graph
    // algorithm captures two hash values in the same list and offsets the
    // second set after the first, e.g.:
    //
    //      Edge2 = Edge1 + Graph-&gt;NumberOfEdges;
    //

    ULONG TotalNumberOfEdges;

    //
    // Number of vertices in the graph.  This will vary based on the masking
    // type.  It is doubled every time a graph resize event is encountered.
    //

    ULONG NumberOfVertices;

    //
    // The number of edges in the graph, rounded up to a power of 2, and then
    // shifted the appropriate amount to extract the exponent part for 2^n.
    //

    BYTE NumberOfEdgesPowerOf2Exponent;

    //
    // As above, but rounded up to the next power of 2 first.
    //

    BYTE NumberOfEdgesNextPowerOf2Exponent;

    //
    // The same exponent logic applied to the number of vertices as per the
    // NumberOfVertices field above.
    //

    BYTE NumberOfVerticesPowerOf2Exponent;

    //
    // And again for the next value.
    //

    BYTE NumberOfVerticesNextPowerOf2Exponent;

} GRAPH_DIMENSIONS;
C_ASSERT(sizeof(GRAPH_DIMENSIONS) == 16);
typedef GRAPH_DIMENSIONS *PGRAPH_DIMENSIONS;</code></pre>
<pre class="code content-chm01-structs-graph_info"><code class="language-c">//
// Define various memory offsets associated with a given graph structure.
// This allows parallel worker threads to reset their local GRAPH instance
// back to the initial state each time they want to try a new random seed.
//

typedef struct _GRAPH_INFO {

    //
    // Number of pages consumed by the entire graph and all backing arrays.
    //

    ULONG NumberOfPagesPerGraph;

    //
    // Page size (e.g. 4096, 2MB).
    //

    ULONG PageSize;

    //
    // Total number of graphs created.  This will match the maximum concurrency
    // level of the upstream context.
    //

    ULONG NumberOfGraphs;

    //
    // Number of RTL_BITMAP structures used by the graph.
    //

    USHORT NumberOfBitmaps;

    //
    // Size of the GRAPH structure.
    //

    USHORT SizeOfGraphStruct;

    //
    // System allocation granularity.  We align the memory map for the on-disk
    // structure using this value initially.
    //

    ULONG AllocationGranularity;

    //
    // If a masking type other than modulus is active, the AbsoluteEdge() needs
    // a way to mask edge values that exceed the number of edges in the table.
    // It does this via EdgeMask, which is initialized to the number of edges
    // (which will be power-of-2 sized for non-modulus masking), minus 1, such
    // that all lower bits will be set.
    //

    ULONG EdgeMask;

    //
    // Also capture the mask required to isolate vertices.
    //

    ULONG VertexMask;

    //
    // Graph dimensions.  This information is duplicated in the graph due to
    // it being accessed frequently.
    //

    GRAPH_DIMENSIONS Dimensions;

    //
    // Pointer to the owning context.
    //

    PPERFECT_HASH_TABLE_CONTEXT Context;

    //
    // Base address of the entire graph allocation.
    //

    union {
        PVOID BaseAddress;
        struct _GRAPH *FirstGraph;
    };

    //
    // Array sizes.
    //

    ULONGLONG EdgesSizeInBytes;
    ULONGLONG NextSizeInBytes;
    ULONGLONG FirstSizeInBytes;
    ULONGLONG PrevSizeInBytes;
    ULONGLONG AssignedSizeInBytes;
    ULONGLONG ValuesSizeInBytes;

    //
    // Deleted edges bitmap buffer size.
    //

    ULONGLONG DeletedEdgesBitmapBufferSizeInBytes;

    //
    // Visited vertices bitmap buffer size.
    //

    ULONGLONG VisitedVerticesBitmapBufferSizeInBytes;

    //
    // Assigned bitmap buffer size.
    //

    ULONGLONG AssignedBitmapBufferSizeInBytes;

    //
    // Index bitmap buffer size.
    //

    ULONGLONG IndexBitmapBufferSizeInBytes;

    //
    // The allocation size of the graph, including structure size and all
    // array and bitmap buffer sizes.
    //

    ULONGLONG AllocSize;

    //
    // Allocation size rounded up to the nearest page size multiple.
    //

    ULONGLONG FinalSize;

} GRAPH_INFO;
typedef GRAPH_INFO *PGRAPH_INFO;</pre></code>
<pre class="code content-chm01-structs-graph"><code class="language-c">//
// Define the graph structure.  This represents an r-graph, or a hypergraph,
// or an r-partite 2-uniform graph, or any other seemingly unlimited number
// of names floating around in academia for what appears to be exactly the
// same thing.
//

typedef struct _Struct_size_bytes_(SizeOfStruct) _GRAPH {

    //
    // List entry used to push the graph onto the context's work list.
    //

    SLIST_ENTRY ListEntry;

    //
    // Edge and vertex masks that can be used when non-modulus masking is in
    // place.  Both of these values are duplicated from the info structure as
    // they are accessed frequently.
    //
    //

    ULONG EdgeMask;
    ULONG VertexMask;

    //
    // Duplicate the mask type, as well, as this directs AbsoluteEdge()'s
    // decision to use the two masks above.
    //

    PERFECT_HASH_TABLE_MASK_FUNCTION_ID MaskFunctionId;

    //
    // Duplicate the number of keys, as this is also frequently referenced.
    //

    ULONG NumberOfKeys;

    //
    // Structure size, in bytes.
    //

    _Field_range_(== , sizeof(struct _GRAPH)) ULONG SizeOfStruct;

    //
    // Graph flags.
    //

    GRAPH_FLAGS Flags;

    //
    // Pointer to the info structure describing various sizes.
    //

    PGRAPH_INFO Info;

    //
    // Graph attempt.  This ID is derived from an interlocked increment against
    // Context-&gt;Attempts, and represents the attempt number across all threads.
    //

    ULONGLONG Attempt;

    //
    // A localized attempt number that reflects the number of attempts made
    // by just this thread.
    //

    ULONG ThreadAttempt;

    //
    // Thread ID of the thread that owns us.  Each callback thread is provided
    // a single graph, and will attempt to solve the perfect hash table until
    // told otherwise.  Thus, there's a 1:1 relationship between graph instance
    // and owning thread.
    //

    ULONG ThreadId;

    //
    // Counter that is incremented each time we delete an edge during the
    // acyclic graph detection stage.
    //

    ULONG DeletedEdgeCount;

    //
    // Counter that is incremented each time we visit a vertex during the
    // assignment stage.
    //

    ULONG VisitedVerticesCount;

    //
    // Capture collisions during assignment step.
    //

    ULONG Collisions;

    //
    // Inline the GRAPH_DIMENSIONS structure.  This is available from the
    // GRAPH_INFO structure, however, it's accessed frequently, so we inline
    // it to avoid the extra level of indirection.
    //

    union {

        struct {
            ULONG NumberOfEdges;
            ULONG TotalNumberOfEdges;
            ULONG NumberOfVertices;
            BYTE NumberOfEdgesPowerOf2Exponent;
            BYTE NumberOfEdgesNextPowerOf2Exponent;
            BYTE NumberOfVerticesPowerOf2Exponent;
            BYTE NumberOfVerticesNextPowerOf2Exponent;
        };

        GRAPH_DIMENSIONS Dimensions;
    };

    //
    // Duplicate the context pointer.  (This is also available from Info.)
    //

    PPERFECT_HASH_TABLE_CONTEXT Context;

    //
    // Edges array.  The number of elements in this array is governed by the
    // TotalNumberOfEdges field, and will be twice the number of edges.
    //

    PEDGE Edges;

    //
    // Array of the "next" edge array, as per the referenced papers.  The number
    // of elements in this array is also governed by TotalNumberOfEdges.
    //

    PEDGE Next;

    //
    // Array of vertices.  Number of elements is governed by the
    // NumberOfVertices field.
    //

    PVERTEX First;

    //
    // The original CHM paper in 1996 references a "prev" array to "facilitate
    // fast deletion".  However, the chmp project appears to have switched to
    // using bitmaps.  Let's reserve a slot for the "prev" array anyway.
    //

    PVERTEX Prev;

    //
    // Array of assigned vertices.  Number of elements is governed by the
    // NumberOfVertices field.
    //

    PVERTEX Assigned;

    //
    // Array of values indexed by the offsets in the Assigned array.  This
    // essentially allows us to simulate a loaded table that supports the
    // Insert(), Index() and Lookup() routines as part of graph validation.
    //

    PULONG Values;

    //
    // Bitmap used to capture deleted edges as part of the acyclic detection
    // stage.  The SizeOfBitMap will reflect TotalNumberOfEdges.
    //

    RTL_BITMAP DeletedEdges;

    //
    // Bitmap used to capture vertices visited as part of the assignment stage.
    // The SizeOfBitMap will reflect NumberOfVertices.
    //

    RTL_BITMAP VisitedVertices;

    //
    // Bitmap used to test the correctness of the Assigned array.
    //

    RTL_BITMAP AssignedBitmap;

    //
    // Bitmap used to track indices during the assignment step.
    //

    RTL_BITMAP IndexBitmap;

    //
    // Capture the seeds used for each hash function employed by the graph.
    //

    ULONG NumberOfSeeds;

    struct {
        union {
            struct {
                union {
                    ULONG Seed1;
                    ULONG FirstSeed;
                };
                ULONG Seed2;
            };
            ULARGE_INTEGER Seeds12;
        };
        union {
            struct {
                ULONG Seed3;
                union {
                    ULONG Seed4;
                    ULONG LastSeed;
                };
            };
            ULARGE_INTEGER Seeds34;
        };
    };

} GRAPH;
typedef GRAPH *PGRAPH;</code></pre>
                    </div>
                </div>

                <p>

                    In general, the structures and functions defined in our
                    <a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTablePrivate.h">PerfectHashTablePrivate.h</a>
                    file are algorithm agnostic.  That is, they don't deal with the notion of a
                    graph, as that's an implementation detail of the CHM algorithm.

                </p>

                <a class="xref" name="code-walkthrough"></a>
                <h1>Code Walkthrough</h1>

                <p>

                    Let's examine the code by walking through the behavior of the
                    <a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/SelfTestPerfectHashTable.c">
                    SelfTestPerfectHashTable()</a> routine.

                </p>

                <a class="xref" name="test-data"></a>
                <h2>Test Data</h2>

                <p>

                    To generate some test data, you have two options.  If you have Python and NumPy
                    installed, you can generate a bunch of linear and random key files via the
                    <a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/data/generate.py">generate.py</a>
                    file that lives in the <code>data</code> subdirectory of the
                    <code>PerfectHashTable</code> component.  Alternatively, you can check out a
                    small git repository that houses some existing sample test data.

                </p>

                <h3>Python Generated</h3>

                <p>

                    The generate.py file and its output follows.  It will generate linear and random
                    arrays of given sizes, saving a .txt representation of the values, a .keys
                    representation of the binary data (which is the actual file we load as part of
                    perfect hash table creation), and, if matplotlib is installed, a .png plot of
                    the data, which allows a quick sanity check that the value distribution is what
                    we expect.

                </p>

                <small>

                    (Note: the random routine creates a double-sized array, then calls
                    <code>np.unique()</code> against it to ensure all the key values are unique,
                    then isolates the <code>[:size]</code> portion we're actually interested in.
                    One side effect of calling <code>np.unique()</code> is that our resulting array
                    is sorted.  We don't stipulate whether key files are required to be sorted at
                    the moment, as it makes no difference to the underlying perfect hash table
                    algorithm we're using.  i.e. we don't suffer the sort of pathological worst-case
                    performance issues some data structures exhibit when inserting data in sorted
                    order.  Nevertheless, if you look at the random files compared to the linear
                    files, they're usually quite similar, given everything is sorted.)

                </small>

                <br/>

                <div class="tab-box language box-generate">
                    <ul class="tabs">
                        <li data-content="content-generate-generate">generate.py</li>
                        <li data-content="content-generate-output">Output</li>
                    </ul>
                    <div class="content">
<pre class="code content-generate-generate"><code class="language-python">
from __future__ import print_function

import numpy as np

try:

    import matplotlib.pyplot as plt

    # Turn off interactive mode to disable plots being displayed
    # prior to saving them to disk.
    plt.ioff()

    def save_array_plot_to_png_file(filename, a):
        plt.plot(a)
        plt.savefig(filename)
        print("Generated %s." % filename)

except ImportError:

    def save_array_plot_to_png_file(filename, a):
        pass

def save_array_to_text_file(filename, a):
    with open(filename, 'wb') as f:
        for i in a:
            f.write(str(i).zfill(9).encode('ascii'))
            f.write(b'\n')
    print("Generated %s." % filename)

def save_array_to_binary_file(filename, a):
    fp = np.memmap(filename, dtype='uint32', mode='w+', shape=a.shape)
    fp[:] = a[:]
    del fp
    print("Generated %s." % filename)

def save_array(prefix, a):
    l = len(a)
    png_filename = '%s-%d.png' % (prefix, l)
    text_filename = '%s-%d.txt' % (prefix, l)
    binary_filename = '%s-%d.keys' % (prefix, l)
    save_array_plot_to_png_file(png_filename, a)
    save_array_to_text_file(text_filename, a)
    save_array_to_binary_file(binary_filename, a)

def gen_random_unique_array(size):
    a = np.random.randint(0, (1 &lt;&lt; 32)-1, size * 2, dtype='uint32')
    a = np.unique(a)[:size]
    return a if len(a) == size else None

def gen_linear_array(size):
    a = np.linspace(0, size, num=size, dtype='uint32')
    return a

sizes = (
    2000, 4000, 4050, 5000, 10000, 15000, 17000, 25000, 31000, 33000, 50000,
    63000, 65500, 75000, 100000, 121000, 125000, 150000, 200000, 225000, 245000,
    255000, 265000, 389161, 472374,
)

functions = (
    ('linear', gen_linear_array),
    ('random', gen_random_unique_array),
)

def main():
    for (name, func) in functions:
        for size in sizes:
            a = func(size)
            if a is None:
                continue
            save_array(name, a)

if __name__ == '__main__':
    main()
</code></pre>
<pre class="code content-generate-output"><code class="language-nasm"> (py35) C:\Users\Trent\Home\src\tracer\PerfectHashTable\data&gt;python generate.py
Generated linear-2000.png.
Generated linear-2000.txt.
Generated linear-2000.keys.
Generated linear-4000.png.
Generated linear-4000.txt.
Generated linear-4000.keys.
Generated linear-4050.png.
Generated linear-4050.txt.
Generated linear-4050.keys.
Generated linear-5000.png.
Generated linear-5000.txt.
Generated linear-5000.keys.
Generated linear-10000.png.
Generated linear-10000.txt.
Generated linear-10000.keys.
Generated linear-15000.png.
Generated linear-15000.txt.
Generated linear-15000.keys.
Generated linear-17000.png.
Generated linear-17000.txt.
Generated linear-17000.keys.
Generated linear-25000.png.
Generated linear-25000.txt.
Generated linear-25000.keys.
Generated linear-31000.png.
Generated linear-31000.txt.
Generated linear-31000.keys.
Generated linear-33000.png.
Generated linear-33000.txt.
Generated linear-33000.keys.
Generated linear-50000.png.
Generated linear-50000.txt.
Generated linear-50000.keys.
Generated linear-63000.png.
Generated linear-63000.txt.
Generated linear-63000.keys.
Generated linear-65500.png.
Generated linear-65500.txt.
Generated linear-65500.keys.
Generated linear-75000.png.
Generated linear-75000.txt.
Generated linear-75000.keys.
Generated linear-100000.png.
Generated linear-100000.txt.
Generated linear-100000.keys.
Generated linear-121000.png.
Generated linear-121000.txt.
Generated linear-121000.keys.
Generated linear-125000.png.
Generated linear-125000.txt.
Generated linear-125000.keys.
Generated linear-150000.png.
Generated linear-150000.txt.
Generated linear-150000.keys.
Generated linear-200000.png.
Generated linear-200000.txt.
Generated linear-200000.keys.
Generated linear-225000.png.
Generated linear-225000.txt.
Generated linear-225000.keys.
Generated linear-245000.png.
Generated linear-245000.txt.
Generated linear-245000.keys.
Generated linear-255000.png.
Generated linear-255000.txt.
Generated linear-255000.keys.
Generated linear-265000.png.
Generated linear-265000.txt.
Generated linear-265000.keys.
Generated linear-389161.png.
Generated linear-389161.txt.
Generated linear-389161.keys.
Generated linear-472374.png.
Generated linear-472374.txt.
Generated linear-472374.keys.
Generated random-2000.png.
Generated random-2000.txt.
Generated random-2000.keys.
Generated random-4000.png.
Generated random-4000.txt.
Generated random-4000.keys.
Generated random-4050.png.
Generated random-4050.txt.
Generated random-4050.keys.
Generated random-5000.png.
Generated random-5000.txt.
Generated random-5000.keys.
Generated random-10000.png.
Generated random-10000.txt.
Generated random-10000.keys.
Generated random-15000.png.
Generated random-15000.txt.
Generated random-15000.keys.
Generated random-17000.png.
Generated random-17000.txt.
Generated random-17000.keys.
Generated random-25000.png.
Generated random-25000.txt.
Generated random-25000.keys.
Generated random-31000.png.
Generated random-31000.txt.
Generated random-31000.keys.
Generated random-33000.png.
Generated random-33000.txt.
Generated random-33000.keys.
Generated random-50000.png.
Generated random-50000.txt.
Generated random-50000.keys.
Generated random-63000.png.
Generated random-63000.txt.
Generated random-63000.keys.
Generated random-65500.png.
Generated random-65500.txt.
Generated random-65500.keys.
Generated random-75000.png.
Generated random-75000.txt.
Generated random-75000.keys.
Generated random-100000.png.
Generated random-100000.txt.
Generated random-100000.keys.
Generated random-121000.png.
Generated random-121000.txt.
Generated random-121000.keys.
Generated random-125000.png.
Generated random-125000.txt.
Generated random-125000.keys.
Generated random-150000.png.
Generated random-150000.txt.
Generated random-150000.keys.
Generated random-200000.png.
Generated random-200000.txt.
Generated random-200000.keys.
Generated random-225000.png.
Generated random-225000.txt.
Generated random-225000.keys.
Generated random-245000.png.
Generated random-245000.txt.
Generated random-245000.keys.
Generated random-255000.png.
Generated random-255000.txt.
Generated random-255000.keys.
Generated random-265000.png.
Generated random-265000.txt.
Generated random-265000.keys.
Generated random-389161.png.
Generated random-389161.txt.
Generated random-389161.keys.
Generated random-472374.png.
Generated random-472374.txt.
Generated random-472374.keys.

</code></pre>
                    </div>
                </div>

                <h3>Git Clone</h3>

                <p>

                    If you don't have Python and NumPy installed or you can't get the
                    <code>generate.py</code> to work, you can clone a small git repository
                    named <a href="https://github.com/tpn/perfecthash">perfecthash</a>, which
                    contains a <code>data</code> directory that has a test file in it named
                    <code>mshtml-37209.keys</code>:

                    <hr/>
                    <pre>
                    C:\Users\Trent\Home\src&gt; git clone https://github.com/tpn/perfecthash
                    ...
                    C:\Users\Trent\Home\src&gt; cd perfecthash\data
                    C:\Users\Trent\Home\src\perfecthash\data&gt; dir
                    ...

                    </pre>
                    <hr/>

                </p>

                <a class="xref" name="running-self-test"></a>
                <h2>Running the Self-Test</h2>

                <p>

                    If you clone the <a href="https://github.com/tpn/tracer">tracer</a> project
                    and open
                    <a href="https://github.com/tpn/tracer/tree/master/PerfectHashTable.sln">PerfectHashTable.sln</a>
                    in Visual Studio 2017, you should be able to build the project from scratch.
                    Selecting the Debug build configuration will make the code easier to step
                    through if you'd like to follow along with an interactive debugging session.

                </p>

                <p>

                    Let's run the debug build of the self-test program against the data directory we
                    prepared earlier.  (I'll use the <code>perfecthash\data</code> directory for now
                    as it only has two key files in it, <code>mshtml-10.keys</code> and
                    <code>mshtml-37209.keys</code>.)  It's worth noting up-front how
                    <strong>not</strong> user friendly the<code>PerfectHashTableSelfTest.exe</code>
                    program is.  It's the bare minimum command line wrapper around the
                    <a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/SelfTestPerfectHashTable.c">
                    SelfTestPerfectHashTable()</a> routine.  It takes five mandatory parameters:
                    the test directory containing the *.keys files you wish to process, the
                    algorithm ID, the hash function ID, the mask function ID, and the maximum
                    concurrency (specifying 0 will use all cores).  (You can optionally add a
                    dummy character as the final parameter which will print a little <code>Press
                    any key to continue.</code> message and then wait for a keypress before
                    exiting &mdash; this is useful when debugging via Visual Studio and you want the
                    console window to stay open so you can review results.)  Usage:

                    <hr/>
                    <pre>C:\Users\Trent\Home\src\tracer&gt;x64\Debug\PerfectHashTableSelfTest.exe
Usage: PerfectHashTableSelfTest.exe &lt;TestDataDirectory (must be fully-qualified)&gt;
                                    &lt;AlgorithmId&gt;
                                    &lt;HashFunctionId&gt;
                                    &lt;MaskFunctionId&gt;
                                    &lt;MaximumConcurrency (0-ncpu)&gt;
                                    [PauseBeforeExit (can be any character)]
E.g.: PerfectHashTableSelfTest.exe C:\Users\Trent\Home\src\perfecthash\data 1 1 2 0
                    </pre>
                    <hr/>
                </p>

                <p>

                    Let's try run it against our <code>perfecthash\data</code> directory.  We'll use
                    the CHM algorithm (1... the only option), the CRC32-Rotate hash function (1),
                    the AND-based masking function (2), and a max concurrency of 0, which will
                    default to all cores, which will be 4 on this Surface Book.

                    <hr/>
                    <pre>S:\tracer&gt;x64\Debug\PerfectHashTableSelfTest.exe S:\perfecthash\data 1 1 2 0

    Starting perfect hash self-test for directory: S:\perfecthash\data.
    Processing key file: mshtml-10.keys
    Successfully created perfect hash table: S:\perfecthash\data\mshtml-10.pht1.
    Successfully loaded perfect hash table: S:\perfecthash\data\mshtml-10.pht1.
    Algorithm: Chm01 (1).
    Hash Function: Crc32Rotate (1).
    Mask Function: And (2).
    Successfully tested perfect hash table.
    Concurrency: 4.
    Number of attempts: 1.
    Number of failed attempts: 0.
    Number of solutions found: 1.
    Number of keys: 10.
    Number of table elements (vertices): 32.
    Seed 1: 1086980845.
    Seed 2: 3416976708.
    Seed 3: 2208417421.
    Seed 4: 3947037297.
    Cycles to solve: 178412.
    Cycles to verify: 3924.
    Cycles to prepare file: 821965.
    Cycles to save file: 9093112.
    Microseconds to solve: 63.
    Microseconds to verify: 1.
    Microseconds to prepare file: 292.
    Microseconds to save file: 3238.

    Processing key file: mshtml-37209.keys
    Successfully created perfect hash table: S:\perfecthash\data\mshtml-37209.pht1.
    Successfully loaded perfect hash table: S:\perfecthash\data\mshtml-37209.pht1.
    Algorithm: Chm01 (1).
    Hash Function: Crc32Rotate (1).
    Mask Function: And (2).
    Successfully tested perfect hash table.
    Concurrency: 4.
    Number of attempts: 3.
    Number of failed attempts: 0.
    Number of solutions found: 3.
    Number of keys: 37209.
    Number of table elements (vertices): 131072.
    Seed 1: 43757427.
    Seed 2: 283337092.
    Seed 3: 1819527900.
    Seed 4: 1437745965.
    Cycles to solve: 71649060.
    Cycles to verify: 6385313.
    Cycles to prepare file: 41221291.
    Cycles to save file: 51229166.
    Microseconds to solve: 25516.
    Microseconds to verify: 2274.
    Microseconds to prepare file: 14680.
    Microseconds to save file: 18244.

</pre>
                    <hr/>
                </p>

                <p>

                    Your output should look similar to the output above.  There will be two new
                    files, <code>mshtml-10.pht1</code> and <code>mshtml-37209.pht1</code> in that
                    <code>perfecthash\data</code> directory.  The .pht1 file is the array of
                    "assigned" values we use as part of index construction for the CHM algorithm.
                    When the output says <em>Successfully loaded perfect hash table ...</em>, it
                    is referring to the .pht1 files.

                </p>

                <p>

                    The metadata for the perfect hash table is stored in an NTFS stream named
                    <code>:Info</code> that is attached to the .pht1 file.  We can view this
                    via the <code>Get-Item -Path mshtml-37209.pht1 -Stream *</code> PowerShell
                    command:

                    <hr/>
                    <pre>PS S:\perfecthash\data&gt; Get-Item -Path mshtml-37209.pht1 -Stream *

    PSPath        : Microsoft.PowerShell.Core\FileSystem::S:\perfecthash\data\mshtml-37209.pht1::$DATA
    PSParentPath  : Microsoft.PowerShell.Core\FileSystem::S:\perfecthash\data
    PSChildName   : mshtml-37209.pht1::$DATA
    PSDrive       : S
    PSProvider    : Microsoft.PowerShell.Core\FileSystem
    PSIsContainer : False
    FileName      : S:\perfecthash\data\mshtml-37209.pht1
    Stream        : :$DATA
    Length        : 524288

    PSPath        : Microsoft.PowerShell.Core\FileSystem::S:\perfecthash\data\mshtml-37209.pht1:Info
    PSParentPath  : Microsoft.PowerShell.Core\FileSystem::S:\perfecthash\data
    PSChildName   : mshtml-37209.pht1:Info
    PSDrive       : S
    PSProvider    : Microsoft.PowerShell.Core\FileSystem
    PSIsContainer : False
    FileName      : S:\perfecthash\data\mshtml-37209.pht1
    Stream        : Info
    Length        : 256
</pre>
                    <hr/>

                </p>

                <p>

                    You can see the normal file data in the first stream (the default file stream)
                    named <code>$DATA</code>.  This is reported as length 524,288 bytes.  If we
                    divide this by 4 (the <code>sizeof(ULONG)</code>), we get 131,072 &mdash; which
                    corresponds to the number of vertices reported for the final table in the
                    output:

                    <hr/>
                    <pre>...
Number of table elements (vertices): 131072.
...
</pre><hr/>

                </p>

                <a class="xref" name="the-info-stream"></a>
                <h3>The <code>:Info</code> Stream</h3>

                <p>

                    Following that is our custom <code>:Info</code> NTFS stream of length 256 bytes.
                    As mentioned earlier, all of our file I/O is done through memory maps.  During
                    the creation step, the <code>:Info</code> stream is created and mapped at a base
                    address accessible through <code>Table-&gt;InfoStreamBaseAddress</code> (we'll
                    discuss the <code>Table</code> structure soon).  In our CHM implementation
                    routine, we literally cast the base address to an <em>on-disk</em> structure
                    named <code>GRAPH_INFO_ON_DISK</code>, which is required to embed a common
                    header structure named <code>TABLE_INFO_ON_DISK_HEADER</code> as its first
                    member.

                </p>

                <p>

                    Let's look at these two header structures, as well as some initialization and
                    finalization code in the CHM implementation that depicts how we work with them.
                    The initialization code is taken from the
                    <a href="https://github.com/tpn/tracer/blob/49df7b95dc499c56423af178dfd687b786aaa610/PerfectHashTable/Chm_01.c#L711">
                    CreatePerfectHashTableImplChm01</a> routine, and the finalization code is taken
                    from the
                    <a href="https://github.com/tpn/tracer/blob/49df7b95dc499c56423af178dfd687b786aaa610/PerfectHashTable/Chm_01.c#L1470">
                    FileWorkCallbackChm01</a>.

                </p>

                <div class="tab-box language box-ondisk">
                    <ul class="tabs">
                        <li data-content="content-ondisk-graph-struct">GRAPH_INFO_ON_DISK</li>
                        <li data-content="content-ondisk-header-struct">TABLE_INFO_ON_DISK_HEADER</li>
                        <li data-content="content-ondisk-chm01-initialization">Initialization</li>
                        <li data-content="content-ondisk-chm01-finalization">Finalization</li>
                    </ul>
                    <div class="content">
<pre class="code content-ondisk-graph-struct"><code class="language-c">//
// Define an on-disk representation of the graph's information.  This is stored
// in the NTFS stream extending from the backing file named :Info.  It is
// responsible for storing information about the on-disk mapping such that it
// can be reloaded from disk and used as a perfect hash table.  The structure
// must always embed the TABLE_INFO_ON_DISK_HEADER structure such that the
// generic loader routine can access on-disk versions saved by different algos
// in order to extract the algorithm ID and determine a suitable loader func to
// use.
//

typedef struct _Struct_size_bytes_(Header.SizeOfStruct) _GRAPH_INFO_ON_DISK {

    //
    // Include the required header.
    //

    TABLE_INFO_ON_DISK_HEADER Header;

    //
    // Additional information we capture is mostly just for informational
    // and debugging purposes.
    //

    //
    // Inline the GRAPH_DIMENSIONS structure.
    //

    union {

        struct {
            ULONG NumberOfEdges;
            ULONG TotalNumberOfEdges;
            ULONG NumberOfVertices;
            BYTE NumberOfEdgesPowerOf2Exponent;
            BYTE NumberOfEdgesNextPowerOf2Exponent;
            BYTE NumberOfVerticesPowerOf2Exponent;
            BYTE NumberOfVerticesNextPowerOf2Exponent;
        };

        GRAPH_DIMENSIONS Dimensions;
    };

} GRAPH_INFO_ON_DISK;
C_ASSERT(sizeof(GRAPH_INFO_ON_DISK) &lt;= PAGE_SIZE);
typedef GRAPH_INFO_ON_DISK *PGRAPH_INFO_ON_DISK;</code></pre>
<pre class="code content-ondisk-header-struct"><code class="language-c">//
// Metadata about a perfect hash table is stored in an NTFS stream named :Info
// that is tacked onto the end of the perfect hash table's file name.  Define
// a structure, TABLE_INFO_ON_DISK_HEADER, that literally represents the on-disk
// layout of this metadata.  Each algorithm implementation must write out an
// info record that conforms with this common header.  They are free to extend
// it with additional details.
//

typedef union _TABLE_INFO_ON_DISK_HEADER_FLAGS {

    struct {

        //
        // Unused bits.
        //

        ULONG Unused:32;

    };

    LONG AsLong;
    ULONG AsULong;

} TABLE_INFO_ON_DISK_HEADER_FLAGS;
C_ASSERT(sizeof(TABLE_INFO_ON_DISK_HEADER_FLAGS) == sizeof(ULONG));

typedef struct _Struct_size_bytes_(SizeOfStruct) _TABLE_INFO_ON_DISK_HEADER {

    //
    // A magic value used to identify the structure.
    //

    ULARGE_INTEGER Magic;

    //
    // Size of the structure, in bytes.
    //
    // N.B. We don't annotate this with a _Field_range_ SAL annotation as the
    //      value will vary depending on which parameters were used to create
    //      the table.
    //

    ULONG SizeOfStruct;

    //
    // Flags.
    //

    TABLE_INFO_ON_DISK_HEADER_FLAGS Flags;

    //
    // Algorithm that was used.
    //

    PERFECT_HASH_TABLE_ALGORITHM_ID AlgorithmId;

    //
    // Hash function that was used.
    //

    PERFECT_HASH_TABLE_HASH_FUNCTION_ID HashFunctionId;

    //
    // Masking type.
    //

    PERFECT_HASH_TABLE_MASK_FUNCTION_ID MaskFunctionId;

    //
    // Size of an individual key element, in bytes.
    //

    ULONG KeySizeInBytes;

    //
    // The concurrency level used to generate the hash.
    //

    ULONG Concurrency;

    //
    // Pad out to 8 bytes.
    //

    ULONG Padding;

    //
    // Number of keys in the input set.  This is used to size an appropriate
    // array for storing values.
    //

    ULARGE_INTEGER NumberOfKeys;

    //
    // Final number of elements in the underlying table.  This will vary
    // depending on how the graph was created.  If modulus masking is in use,
    // this will reflect the number of keys (unless a custom table size was
    // requested during creation).  Otherwise, this will be the number of keys
    // rounded up to the next power of 2.  (That is, take the number of keys,
    // round up to a power of 2, then round that up to the next power of 2.)
    //

    ULARGE_INTEGER NumberOfTableElements;

    //
    // Capture the hash and index details required by MaskHash(), MaskIndex()
    // and Index() routines.
    //

    ULONG HashSize;
    ULONG IndexSize;

    ULONG HashShift;
    ULONG IndexShift;

    ULONG HashMask;
    ULONG IndexMask;

    ULONG HashFold;
    ULONG IndexFold;

    ULONG HashModulus;
    ULONG IndexModulus;

    //
    // Seed data.
    //

    ULONG NumberOfSeeds;

    union {
        ULONG Seed1;
        ULONG FirstSeed;
    };

    ULONG Seed2;
    ULONG Seed3;

    union {
        ULONG Seed4;
        ULONG LastSeed;
    };

    //
    // Capture statistics about the perfect hash table solution that can be
    // useful during analysis and performance comparisons.
    //

    //
    // Number of attempts at solving the solution.
    //

    ULONGLONG NumberOfAttempts;

    //
    // Number of failed attempts at solving the solution.
    //

    ULONGLONG NumberOfFailedAttempts;

    //
    // If solutions are being sought in parallel, more than one thread may
    // find a solution before it detects that someone else has already found
    // a solution (in which case, it stops solving and returns from the pool
    // callback).  This counter measures the number of solutions that were
    // found in parallel.  It corresponds to the Context-&gt;FinishedCount value.
    //
    // With a good hashing function and large concurrency value, this value
    // may often be relatively large.  E.g. with a concurrency level of 12, it
    // would not be surprising to see 12 attempts reported, and 10 solutions
    // found.  (Meaning that our concurrency level was a tad unnecessary, or
    // our hash function is unnecessarily good (which usually means expensive).)
    //
    // N.B. Finding multiple solutions in parallel is harmless, if not a little
    //      wasteful of CPU time.  The threads can detect if they are the first
    //      ones to find a solution prior to continuing with the assignment
    //      step, such that the assignment can be avoided if another thread has
    //      beaten them to that point.  They also check at regular intervals
    /       during graph solving, and will do a fast-path exit as soon as they
    //      detect another thread has found a solution.
    //

    ULONGLONG NumberOfSolutionsFound;

    //
    // If a solution can't be found within a configurable threshold, a "table
    // resize" event will be generated.  This results in doubling the number
    // of vertices being used for the backing table and trying the solution
    // again.  The following field captures how many times this occurred.
    //

    ULONGLONG NumberOfTableResizeEvents;

    //
    // This counter captures the sum of all prior attempts at solving the
    // solution before giving up and resizing the table.  It excludes the
    // attempts made by the winning table size (captured by NumberOfAttempts).
    // It will be zero if no resize events occurred.  We don't keep a separate
    // failed counter here, as the resize event implies all attempts failed.
    //

    ULONGLONG TotalNumberOfAttemptsWithSmallerTableSizes;

    //
    // The following counter captures the initial table size that was attempted
    // in order to solve the solution.  It will differ from the final table size
    // if there were resize events.  As we simply double the size of the table
    // on each resize event, we can extrapolate the different table sizes that
    // were tried prior to finding a winning one by looking at the initial size
    // attempted and the number of resize events.
    //

    ULONGLONG InitialTableSize;

    //
    // The following counter captures the closest we came to solving the graph
    // in previous attempts before a resize event occurred.  This is calculated
    // by taking the number of edges and subtracting the value of the context's
    // HighestDeletedEdgesCount counter.  The value represents the additional
    // number of 1 degree edges we needed to delete in order to obtain an
    // acyclic graph.  A very low number indicates that we came very close to
    // solving it as there were very few hash collisions with the seed values
    // we picked.  A very high number indicates we had no chance and there were
    // collisions galore.
    //

    ULONGLONG ClosestWeCameToSolvingGraphWithSmallerTableSizes;

    //
    // Number of cycles it took to solve the solution for the winning thread.
    // (This does not factor in the total cycle time consumed by all threads.)
    //

    ULARGE_INTEGER SolveCycles;

    //
    // Number of microseconds taken to solve the solution.
    //

    ULARGE_INTEGER SolveMicroseconds;

    //
    // Number of cycles taken to verify the solution.
    //

    ULARGE_INTEGER VerifyCycles;

    //
    // Number of microseconds taken to verify the solution.
    //

    ULARGE_INTEGER VerifyMicroseconds;

    //
    // Number of cycles taken to prepare the file.
    //

    ULARGE_INTEGER PrepareFileCycles;

    //
    // Number of microseconds taken to prepare the file.
    //

    ULARGE_INTEGER PrepareFileMicroseconds;

    //
    // Number of cycles taken to save the file.
    //

    ULARGE_INTEGER SaveFileCycles;

    //
    // Number of microseconds taken to save the file.
    //

    ULARGE_INTEGER SaveFileMicroseconds;

} TABLE_INFO_ON_DISK_HEADER;
typedef TABLE_INFO_ON_DISK_HEADER *PTABLE_INFO_ON_DISK_HEADER;</code></pre>
<pre class="code content-ondisk-chm01-initialization"><code class="language-c">    //
    // Save the on-disk representation of the graph information.  This is a
    // smaller subset of data needed in order to load a previously-solved
    // graph as a perfect hash table.  The data resides in an NTFS stream named
    // :Info off the main perfect hash table file.  It will have been mapped for
    // us already at Table-&gt;InfoStreamBaseAddress.
    //

    OnDiskInfo = (PGRAPH_INFO_ON_DISK)Table-&gt;InfoStreamBaseAddress;
    ASSERT(OnDiskInfo);
    OnDiskHeader = &amp;OnDiskInfo-&gt;Header;
    OnDiskHeader-&gt;Magic.LowPart = TABLE_INFO_ON_DISK_MAGIC_LOWPART;
    OnDiskHeader-&gt;Magic.HighPart = TABLE_INFO_ON_DISK_MAGIC_HIGHPART;
    OnDiskHeader-&gt;SizeOfStruct = sizeof(*OnDiskInfo);
    OnDiskHeader-&gt;Flags.AsULong = 0;
    OnDiskHeader-&gt;Concurrency = Context-&gt;MaximumConcurrency;
    OnDiskHeader-&gt;AlgorithmId = Context-&gt;AlgorithmId;
    OnDiskHeader-&gt;MaskFunctionId = Context-&gt;MaskFunctionId;
    OnDiskHeader-&gt;HashFunctionId = Context-&gt;HashFunctionId;
    OnDiskHeader-&gt;KeySizeInBytes = sizeof(ULONG);
    OnDiskHeader-&gt;HashSize = Table-&gt;HashSize;
    OnDiskHeader-&gt;IndexSize = Table-&gt;IndexSize;
    OnDiskHeader-&gt;HashShift = Table-&gt;HashShift;
    OnDiskHeader-&gt;IndexShift = Table-&gt;IndexShift;
    OnDiskHeader-&gt;HashMask = Table-&gt;HashMask;
    OnDiskHeader-&gt;IndexMask = Table-&gt;IndexMask;
    OnDiskHeader-&gt;HashFold = Table-&gt;HashFold;
    OnDiskHeader-&gt;IndexFold = Table-&gt;IndexFold;
    OnDiskHeader-&gt;HashModulus = Table-&gt;HashModulus;
    OnDiskHeader-&gt;IndexModulus = Table-&gt;IndexModulus;
    OnDiskHeader-&gt;NumberOfKeys.QuadPart = (
        Table-&gt;Keys-&gt;NumberOfElements.QuadPart
    );
    OnDiskHeader-&gt;NumberOfSeeds = ((
        FIELD_OFFSET(GRAPH, LastSeed) -
        FIELD_OFFSET(GRAPH, FirstSeed)
    ) / sizeof(ULONG)) + 1;

    //
    // This will change based on masking type and whether or not the caller
    // has provided a value for NumberOfTableElements.  For now, keep it as
    // the number of vertices.
    //

    OnDiskHeader-&gt;NumberOfTableElements.QuadPart = (
        NumberOfVertices.QuadPart
    );

    CopyMemory(&amp;OnDiskInfo-&gt;Dimensions, Dim, sizeof(*Dim));</code></pre>
<pre class="code content-ondisk-chm01-finalization"><code class="language-c">        case FileWorkSaveId: {

            PULONG Dest;
            PULONG Source;
            PGRAPH Graph;
            ULONG WaitResult;
            BOOLEAN Success;
            ULONGLONG SizeInBytes;
            LARGE_INTEGER EndOfFile;
            PPERFECT_HASH_TABLE Table;
            PTABLE_INFO_ON_DISK_HEADER Header;

            //
            // Indicate the save event has completed upon return of this
            // callback.
            //

            SetOnReturnEvent = SavedEvent;

            //
            // Initialize aliases.
            //

            Table = Context-&gt;Table;
            Dest = (PULONG)Table-&gt;BaseAddress;
            Graph = (PGRAPH)Context-&gt;SolvedContext;
            Source = Graph-&gt;Assigned;
            Header = Table-&gt;Header;

            SizeInBytes = (
                Header-&gt;NumberOfTableElements.QuadPart *
                Header-&gt;KeySizeInBytes
            );

            //
            // The graph has been solved.  Copy the array of assigned values
            // to the mapped area we prepared earlier (above).
            //

            CopyMemory(Dest, Source, SizeInBytes);

            //
            // Save the seed values used by this graph.  (Everything else in
            // the on-disk info representation was saved earlier.)
            //

            Header-&gt;Seed1 = Graph-&gt;Seed1;
            Header-&gt;Seed2 = Graph-&gt;Seed2;
            Header-&gt;Seed3 = Graph-&gt;Seed3;
            Header-&gt;Seed4 = Graph-&gt;Seed4;

            //
            // Kick off a flush file buffers now before we wait on the verified
            // event.  The flush will be a blocking call.  The wait on verified
            // will be blocking if the event isn't signaled.  So, we may as well
            // get some useful blocking work done, before potentially going into
            // another wait state where we're not doing anything useful.
            //

            ASSERT(FlushFileBuffers(Table-&gt;FileHandle));

            //
            // Stop the save file timer here, after flushing the file buffers,
            // but before we potentially wait on the verified state.
            //

            CONTEXT_END_TIMERS(SaveFile);

            //
            // Wait on the verification complete event.  This is done in the
            // main thread straight after it dispatches our file work callback
            // (that ended up here).  We need to block on this event as we want
            // to save the timings for verification to the header.
            //

            WaitResult = WaitForSingleObject(Context-&gt;VerifiedEvent, INFINITE);
            ASSERT(WaitResult == WAIT_OBJECT_0);

            //
            // When we mapped the array in the work item above, we used a size
            // that was aligned with the system allocation granularity.  We now
            // want to set the end of file explicitly to the exact size of the
            // underlying array.  To do this, we unmap the view, delete the
            // section, set the file pointer to where we want, set the end of
            // file (which will apply the file pointer position as EOF), then
            // close the file handle.
            //

            ASSERT(UnmapViewOfFile(Table-&gt;BaseAddress));
            Table-&gt;BaseAddress = NULL;

            ASSERT(CloseHandle(Table-&gt;MappingHandle));
            Table-&gt;MappingHandle = NULL;

            EndOfFile.QuadPart = SizeInBytes;

            Success = SetFilePointerEx(Table-&gt;FileHandle,
                                       EndOfFile,
                                       NULL,
                                       FILE_BEGIN);

            ASSERT(Success);

            ASSERT(SetEndOfFile(Table-&gt;FileHandle));

            ASSERT(CloseHandle(Table-&gt;FileHandle));
            Table-&gt;FileHandle = NULL;

            //
            // Stop the save file timers, then copy all the timer values into
            // the header (before closing the :Info stream).
            //

            CONTEXT_SAVE_TIMERS_TO_HEADER(Solve);
            CONTEXT_SAVE_TIMERS_TO_HEADER(Verify);
            CONTEXT_SAVE_TIMERS_TO_HEADER(PrepareFile);
            CONTEXT_SAVE_TIMERS_TO_HEADER(SaveFile);

            //
            // Save the number of attempts and number of finished solutions.
            //

            Header-&gt;NumberOfAttempts = Context-&gt;Attempts;
            Header-&gt;NumberOfFailedAttempts = Context-&gt;FailedAttempts;
            Header-&gt;NumberOfSolutionsFound = Context-&gt;FinishedCount;

            //
            // Finalize the :Info stream the same way we handled the backing
            // file above; unmap, delete section, set file pointer, set eof,
            // close file.
            //

            ASSERT(UnmapViewOfFile(Table-&gt;InfoStreamBaseAddress));
            Table-&gt;InfoStreamBaseAddress = NULL;

            ASSERT(CloseHandle(Table-&gt;InfoStreamMappingHandle));
            Table-&gt;InfoStreamMappingHandle = NULL;

            //
            // The file size for the :Info stream will be the size of our
            // on-disk info structure.
            //

            EndOfFile.QuadPart = sizeof(*OnDiskInfo);

            Success = SetFilePointerEx(Table-&gt;InfoStreamFileHandle,
                                       EndOfFile,
                                       NULL,
                                       FILE_BEGIN);

            ASSERT(Success);

            ASSERT(SetEndOfFile(Table-&gt;InfoStreamFileHandle));

            ASSERT(CloseHandle(Table-&gt;InfoStreamFileHandle));
            Table-&gt;InfoStreamFileHandle = NULL;

            break;
        }</code></pre>
                    </div>
                </div>

                <p>

                    So, to summarize, the <code>:Info</code> NTFS stream is memory mapped and then
                    directly cast into a <code>GRAPH_INFO_ON_DISK</code> structure, which is
                    required to embed the <code>TABLE_INFO_ON_DISK_HEADER</code> structure as its
                    first element.  The
                    <a
                    href="https://github.com/tpn/tracer/blob/49df7b95dc499c56423af178dfd687b786aaa610/PerfectHashTable/LoadPerfectHashTable.c">
                    LoadPerfectHashTable()</a> routine is then able to memory map the same
                    <code>:Info</code> stream at a later point (or in a separate process), validate
                    the header semantics, extract the algorithm ID, then call the algorithm
                    implementation's custom loader routine.

                </p>

                <p>

                    This is how we satisfy the original off-line generation requirement.  (That is,
                    making sure the creation step persists something that can be loaded and used at
                    an arbitrary future time, in a different process, potentially on a different
                    machine.)

                </p>

                <a class="xref" name="SelfTestPerfectHashTable"></a>
                <h2>SelfTestPerfectHashTable</h2>

                <p>

                    Let's step back and take a look at the self test routine, as this exercises all
                    of the main public API routines, and serves as a good starting point.  I'll
                    provide two code samples; the first is a vastly simplified pseudo-code depiction
                    of the routine, sans all details other than the absolute bare minimum, the
                    second is the full routine.

                </p>

                <div class="tab-box language box-self-test">
                    <ul class="tabs">
                        <li data-content="content-self-test-pseudo">Pseudo</li>
                        <li data-content="content-self-test-full">Full</li>
                    </ul>
                    <div class="content">
<pre class="code content-self-test-pseudo"><code class="language-c">_Use_decl_annotations_
BOOLEAN
SelfTestPerfectHashTable(
    PRTL Rtl,
    PALLOCATOR Allocator,
    PPERFECT_HASH_TABLE_ANY_API AnyApi,
    PCUNICODE_STRING TestDataDirectory,
    PULONG MaximumConcurrency,
    PERFECT_HASH_TABLE_ALGORITHM_ID AlgorithmId,
    PERFECT_HASH_TABLE_HASH_FUNCTION_ID HashFunctionId,
    PERFECT_HASH_TABLE_MASK_FUNCTION_ID MaskFunctionId
    )
/*++

Routine Description:

    Performs a self-test of the entire PerfectHashTable component.

Arguments:

    Rtl - Supplies a pointer to an initialized RTL structure.

    Allocator - Supplies a pointer to an initialized ALLOCATOR structure that
        will be used for all memory allocations.

    AnyApi - Supplies a pointer to an initialized PERFECT_HASH_TABLE_ANY_API
        structure.  Note that this must be an instance of the extended API;
        this is verified by looking at the Api-&amp;SizeOfStruct field and ensuring
        it matches our expected size of the extended API structure.

    TestDataDirectory - Supplies a pointer to a UNICODE_STRING structure that
        represents a fully-qualified path of the test data directory.

    MaximumConcurrency - Optionally supplies a pointer to a variable that
        contains the desired maximum concurrency to be used for the underlying
        threadpool.  If NULL, or non-NULL but points to a value of 0, then the
        number of system processors will be used as a default value.

        N.B. This value is passed directly to SetThreadpoolThreadMinimum() and
             SetThreadpoolThreadMaximum().

    AlgorithmId - Supplies the algorithm to use.

    MaskFunctionId - Supplies the type of masking to use.

    HashFunctionId - Supplies the hash function to use.

Return Value:

    TRUE on success, FALSE on failure.

--*/
{

    //
    // Enumerate over all keys in the test data directory.
    //

    for (KeysPath in FindFiles(TestDataDirectory, "*.keys")) {

        //
        // Create a new perfect hash table context.
        //

        Api-&gt;CreatePerfectHashTableContext(Rtl,
                                           Allocator,
                                           MaximumConcurrency,
                                           &amp;Context);


        //
        // Load the keys file.
        //

        Api-&gt;LoadPerfectHashTableKeys(Rtl,
                                      Allocator,
                                      &amp;KeysPath,
                                      &amp;Keys);

        //
        // Keys were loaded successfully.  Construct the equivalent path name
        // for the backing perfect hash table when persisted to disk.  Although
        // this can be automated for us as part of CreatePerfectHashTable(),
        // having it backed by our memory simplifies things a little further
        // down the track when we want to load the table via the path but have
        // destroyed the original table that came from CreatePerfectHashTable().
        //

        CreateTablePathFromKeysPath(&amp;Keys, &amp;TablePath);

        //
        // We now have the fully-qualified path name of the backing perfect
        // hash table file living in TablePath.  Continue with creation of the
        // perfect hash table, using this path we've just created and the keys
        // that were loaded.
        //

        Api-&gt;CreatePerfectHashTable(Rtl,
                                    Allocator,
                                    Context,
                                    AlgorithmId,
                                    MaskFunctionId,
                                    HashFunctionId,
                                    NULL,
                                    Keys,
                                    &amp;TablePath);

        //
        // Load the perfect hash table we just created.
        //

        Api-&gt;LoadPerfectHashTable(Rtl,
                                     Allocator,
                                     Keys,
                                     &amp;TablePath,
                                     &amp;Table);

        //
        // Table was loaded successfully from disk.  Obtain the names of all
        // the enumeration IDs.  Currently these should always match the same
        // enums provided as input parameters to this routine.
        //

        Api-&gt;GetAlgorithmName(Table-&gt;AlgorithmId, &amp;AlgorithmName);

        Api-&gt;GetHashFunctionName(Table-&gt;HashFunctionId, &amp;HashFunctionName);

        Api-&gt;GetMaskFunctionName(Table-&gt;MaskFunctionId, &amp;MaskFunctionName);

        //
        // Test the table.  The TRUE parameter corresponds to the DebugBreakOnFailure
        // boolean parameter, indicating that we want an immediate __debugbreak() if
        // a failure is detected.
        //

        Api-&gt;TestPerfectHashTable(Table, TRUE);

        //
        // Dump some stats from the header.
        //

        DumpHeaderStats(Table-&gt;Header);

        //
        // Destroy the table, keys, and context.
        //

        Table-&gt;Vtbl-&gt;Release(Table);

        Api-&gt;DestroyPerfectHashTableKeys(&amp;Keys);

        Api-&gt;DestroyPerfectHashTableContext(&amp;Context, NULL);

    }
}</code></pre>
<pre class="code content-self-test-full"><code class="language-c">_Use_decl_annotations_
BOOLEAN
SelfTestPerfectHashTable(
    PRTL Rtl,
    PALLOCATOR Allocator,
    PPERFECT_HASH_TABLE_ANY_API AnyApi,
    PCUNICODE_STRING TestDataDirectory,
    PULONG MaximumConcurrency,
    PERFECT_HASH_TABLE_ALGORITHM_ID AlgorithmId,
    PERFECT_HASH_TABLE_HASH_FUNCTION_ID HashFunctionId,
    PERFECT_HASH_TABLE_MASK_FUNCTION_ID MaskFunctionId
    )
/*++

Routine Description:

    Performs a self-test of the entire PerfectHashTable component.

Arguments:

    Rtl - Supplies a pointer to an initialized RTL structure.

    Allocator - Supplies a pointer to an initialized ALLOCATOR structure that
        will be used for all memory allocations.

    AnyApi - Supplies a pointer to an initialized PERFECT_HASH_TABLE_ANY_API
        structure.  Note that this must be an instance of the extended API;
        this is verified by looking at the Api-&gt;SizeOfStruct field and ensuring
        it matches our expected size of the extended API structure.

    TestDataDirectory - Supplies a pointer to a UNICODE_STRING structure that
        represents a fully-qualified path of the test data directory.

    MaximumConcurrency - Optionally supplies a pointer to a variable that
        contains the desired maximum concurrency to be used for the underlying
        threadpool.  If NULL, or non-NULL but points to a value of 0, then the
        number of system processors will be used as a default value.

        N.B. This value is passed directly to SetThreadpoolThreadMinimum() and
             SetThreadpoolThreadMaximum().

    AlgorithmId - Supplies the algorithm to use.

    MaskFunctionId - Supplies the type of masking to use.

    HashFunctionId - Supplies the hash function to use.

Return Value:

    TRUE on success, FALSE on failure.

--*/
{
    PWSTR Dest;
    PWSTR Source;
    USHORT Length;
    USHORT BaseLength;
    USHORT NumberOfPages;
    BOOLEAN Success;
    BOOLEAN Failed;
    BOOLEAN IsProcessTerminating = FALSE;
    PWCHAR Buffer;
    PWCHAR BaseBuffer;
    PWCHAR WideOutput;
    PWCHAR WideOutputBuffer;
    HANDLE FindHandle = NULL;
    HANDLE WideOutputHandle;
    HANDLE ProcessHandle = NULL;
    ULONG Failures;
    ULONG BytesWritten;
    ULONG WideCharsWritten;
    ULONGLONG BufferSize;
    ULONGLONG WideOutputBufferSize;
    LONG_INTEGER AllocSize;
    LARGE_INTEGER BytesToWrite;
    LARGE_INTEGER WideCharsToWrite;
    WIN32_FIND_DATAW FindData;
    UNICODE_STRING SearchPath;
    UNICODE_STRING KeysPath;
    UNICODE_STRING TablePath;
    PPERFECT_HASH_TABLE Table;
    PPERFECT_HASH_TABLE_KEYS Keys;
    PTABLE_INFO_ON_DISK_HEADER Header;
    PPERFECT_HASH_TABLE_CONTEXT Context;
    PPERFECT_HASH_TABLE_API Api;
    PPERFECT_HASH_TABLE_API_EX ApiEx;
    PUNICODE_STRING AlgorithmName;
    PUNICODE_STRING HashFunctionName;
    PUNICODE_STRING MaskFunctionName;
    UNICODE_STRING Suffix = RTL_CONSTANT_STRING(L"*.keys");
    UNICODE_STRING TableSuffix = RTL_CONSTANT_STRING(L"pht1");

    //
    // Validate arguments.
    //

    if (!ARGUMENT_PRESENT(Rtl)) {
        return FALSE;
    }

    if (!ARGUMENT_PRESENT(Allocator)) {
        return FALSE;
    }

    if (!ARGUMENT_PRESENT(AnyApi)) {

        return FALSE;

    } else {

        Api = &amp;AnyApi-&gt;Api;

        if (Api-&gt;SizeOfStruct == sizeof(*ApiEx)) {

            ApiEx = &amp;AnyApi-&gt;ApiEx;

        } else {

            //
            // The API should be the extended version.  (Otherwise, how did
            // the caller even find this function?)
            //

            return FALSE;
        }

    }

    if (!ARGUMENT_PRESENT(TestDataDirectory)) {
        return FALSE;
    }

    if (!IsValidMinimumDirectoryUnicodeString(TestDataDirectory)) {
        return FALSE;
    }

    if (!IsValidPerfectHashTableAlgorithmId(AlgorithmId)) {

        return FALSE;

    } else {


    }

    //
    // Arguments have been validated, proceed.
    //

    //
    // Create a buffer we can use for stdout, using a very generous buffer size.
    //

    NumberOfPages = 10;
    Success = Rtl-&gt;CreateBuffer(Rtl,
                                &amp;ProcessHandle,
                                NumberOfPages,
                                NULL,
                                &amp;WideOutputBufferSize,
                                &amp;WideOutputBuffer);

    if (!Success) {
        return FALSE;
    }

    WideOutput = WideOutputBuffer;

    //
    // Create a buffer we can use for temporary path construction.  We want it
    // to be MAX_USHORT in size, so (1 &lt;&lt; 16) &gt;&gt; PAGE_SHIFT converts this into
    // the number of pages we need.
    //

    NumberOfPages = (1 &lt;&lt; 16) &gt;&gt; PAGE_SHIFT;
    Success = Rtl-&gt;CreateBuffer(Rtl,
                                &amp;ProcessHandle,
                                NumberOfPages,
                                NULL,
                                &amp;BufferSize,
                                &amp;BaseBuffer);

    if (!Success) {
        return FALSE;
    }

    Buffer = BaseBuffer;

    //
    // Get a reference to the stdout handle.
    //

    WideOutputHandle = GetStdHandle(STD_OUTPUT_HANDLE);
    ASSERT(WideOutputHandle);

    //
    // Calculate the size required for a new concatenated wide string buffer
    // that combines the test data directory with the "*.keys" suffix.  The
    // 2 * sizeof(*Dest) accounts for the joining slash and trailing NULL.
    //

    AllocSize.LongPart = TestDataDirectory-&gt;Length;
    AllocSize.LongPart += Suffix.Length + (2 * sizeof(*Dest));

    ASSERT(!AllocSize.HighPart);

    SearchPath.Buffer = (PWSTR)Buffer;

    if (!SearchPath.Buffer) {
        goto Error;
    }

    //
    // Copy incoming test data directory name.
    //

    Length = TestDataDirectory-&gt;Length;
    CopyMemory(SearchPath.Buffer,
               TestDataDirectory-&gt;Buffer,
               Length);

    //
    // Advance our Dest pointer to the end of the directory name, write a
    // slash, then copy the suffix over.
    //

    Dest = (PWSTR)RtlOffsetToPointer(SearchPath.Buffer, Length);
    *Dest++ = L'\\';
    CopyMemory(Dest, Suffix.Buffer, Suffix.Length);

    //
    // Wire up the search path length and maximum length variables.  The max
    // length will be our AllocSize, length will be this value minus 2 to
    // account for the trailing NULL.
    //

    SearchPath.MaximumLength = AllocSize.LowPart;
    SearchPath.Length = AllocSize.LowPart - sizeof(*Dest);
    ASSERT(SearchPath.Buffer[SearchPath.Length] == L'\0');

    //
    // Advance the buffer past this string allocation, up to the next 16-byte
    // boundary.
    //

    Buffer = (PWSTR)(
        RtlOffsetToPointer(
            Buffer,
            ALIGN_UP(SearchPath.MaximumLength, 16)
        )
    );

    WIDE_OUTPUT_RAW(WideOutput,
                    L"Starting perfect hash self-test for directory: ");
    WIDE_OUTPUT_UNICODE_STRING(WideOutput, TestDataDirectory);
    WIDE_OUTPUT_RAW(WideOutput, L".\n");
    WIDE_OUTPUT_FLUSH();

    //
    // Create a find handle for the &lt;test data&gt;\*.keys search pattern we
    // created.
    //

    FindHandle = FindFirstFileW(SearchPath.Buffer, &amp;FindData);

    if (!FindHandle || FindHandle == INVALID_HANDLE_VALUE) {

        ULONG LastError;

        //
        // Check to see if we failed because there were no files matching the
        // wildcard *.keys in the test directory.  In this case, GetLastError()
        // will report ERROR_FILE_NOT_FOUND.
        //

        LastError = GetLastError();

        if (LastError == ERROR_FILE_NOT_FOUND) {

            WIDE_OUTPUT_RAW(WideOutput,
                            L"No files matching pattern '*.keys' found in "
                            L"test data directory.\n");
            WIDE_OUTPUT_FLUSH();

            goto End;

        } else {

            //
            // We failed for some other reason.
            //

            WIDE_OUTPUT_RAW(WideOutput,
                            L"FindFirstFileW() failed with error code: ");
            WIDE_OUTPUT_INT(WideOutput, LastError);
            WIDE_OUTPUT_LF(WideOutput);
            WIDE_OUTPUT_FLUSH();

            goto Error;
        }
    }

    //
    // Initialize the fully-qualified keys path.
    //

    KeysPath.Buffer = Buffer;
    CopyMemory(KeysPath.Buffer, TestDataDirectory-&gt;Buffer, Length);

    //
    // Advance our Dest pointer to the end of the directory name, then write
    // a slash.
    //

    Dest = (PWSTR)RtlOffsetToPointer(KeysPath.Buffer, Length);
    *Dest++ = L'\\';

    //
    // Update the length to account for the slash we just wrote, then make a
    // copy of it in the variable BaseLength.
    //

    Length += sizeof(*Dest);
    BaseLength = Length;

    //
    // Zero the failure count and begin the main loop.
    //

    Failures = 0;

    do {

        //
        // Clear the failure flag at the top of every loop invocation.
        //

        Failed = FALSE;

        WIDE_OUTPUT_RAW(WideOutput, L"Processing key file: ");
        WIDE_OUTPUT_WCSTR(WideOutput, (PCWSZ)FindData.cFileName);
        WIDE_OUTPUT_LF(WideOutput);
        WIDE_OUTPUT_FLUSH();

        //
        // Create a new perfect hash table context.
        //

        Success = Api-&gt;CreatePerfectHashTableContext(Rtl,
                                                     Allocator,
                                                     MaximumConcurrency,
                                                     &amp;Context);

        if (!Success) {

            //
            // We can't do anything without a context.
            //

            WIDE_OUTPUT_RAW(WideOutput, L"Fatal: failed to create context.\n");
            WIDE_OUTPUT_FLUSH();
            Failures++;
            break;
        }

        //
        // Copy the filename over to the fully-qualified keys path.
        //

        Dest = (PWSTR)RtlOffsetToPointer(KeysPath.Buffer, BaseLength);
        Source = (PWSTR)FindData.cFileName;

        while (*Source) {
            *Dest++ = *Source++;
        }
        *Dest = L'\0';

        Length = (USHORT)RtlOffsetFromPointer(Dest, KeysPath.Buffer);
        KeysPath.Length = Length;
        KeysPath.MaximumLength = Length + sizeof(*Dest);
        ASSERT(KeysPath.Buffer[KeysPath.Length &gt;&gt; 1] == L'\0');
        ASSERT(&amp;KeysPath.Buffer[KeysPath.Length &gt;&gt; 1] == Dest);

        Success = Api-&gt;LoadPerfectHashTableKeys(Rtl,
                                                Allocator,
                                                &amp;KeysPath,
                                                &amp;Keys);

        if (!Success) {

            WIDE_OUTPUT_RAW(WideOutput, L"Failed to load keys for ");
            WIDE_OUTPUT_UNICODE_STRING(WideOutput, &amp;KeysPath);
            WIDE_OUTPUT_RAW(WideOutput, L".\n");
            WIDE_OUTPUT_FLUSH();

            Failures++;
            goto DestroyContext;
        }

        //
        // Keys were loaded successfully.  Construct the equivalent path name
        // for the backing perfect hash table when persisted to disk.  Although
        // this can be automated for us as part of CreatePerfectHashTable(),
        // having it backed by our memory simplifies things a little further
        // down the track when we want to load the table via the path but have
        // destroyed the original table that came from CreatePerfectHashTable().
        //

        //
        // Align the Dest pointer up to a 16-byte boundary.  (We add 1 to its
        // current value to advance it past the terminating NULL of the keys
        // path.)
        //

        Dest = (PWSTR)ALIGN_UP(Dest + 1, 16);

        //
        // We know the keys file ended with ".keys".  We're going to use the
        // identical name for the backing hash table file, except replace the
        // ".keys" extension at the end with ".pht1".  So, we can just copy the
        // lengths used for KeysPath, plus the entire buffer, then just copy the
        // new extension over the old one.  The 1 doesn't have any significance
        // other than it padding out the extension length such that it matches
        // the length of ".keys".  (Although it may act as a nice versioning
        // tool down the track.)
        //

        TablePath.Length = KeysPath.Length;
        TablePath.MaximumLength = KeysPath.MaximumLength;
        TablePath.Buffer = Dest;

        //
        // Copy the keys path over.
        //

        CopyMemory(Dest, KeysPath.Buffer, KeysPath.MaximumLength);

        //
        // Advance the Dest pointer to the end of the buffer, then retreat it
        // five characters, such that it's positioned on the 'k' of keys.
        //

        Dest += (KeysPath.MaximumLength &gt;&gt; 1) - 5;
        ASSERT(*Dest == L'k');
        ASSERT(*(Dest - 1) == L'.');

        //
        // Copy the "pht1" extension over "keys".
        //

        Source = TableSuffix.Buffer;
        while (*Source) {
            *Dest++ = *Source++;
        }
        *Dest = L'\0';

        //
        // Sanity check invariants.
        //

        ASSERT(TablePath.Buffer[TablePath.Length &gt;&gt; 1] == L'\0');
        ASSERT(&amp;TablePath.Buffer[TablePath.Length &gt;&gt; 1] == Dest);

        //
        // We now have the fully-qualified path name of the backing perfect
        // hash table file living in TablePath.  Continue with creation of the
        // perfect hash table, using this path we've just created and the keys
        // that were loaded.
        //

        Success = Api-&gt;CreatePerfectHashTable(Rtl,
                                              Allocator,
                                              Context,
                                              AlgorithmId,
                                              MaskFunctionId,
                                              HashFunctionId,
                                              NULL,
                                              Keys,
                                              &amp;TablePath);

        if (!Success) {

            WIDE_OUTPUT_RAW(WideOutput, L"Failed to create perfect hash "
                                        L"table for keys: ");
            WIDE_OUTPUT_UNICODE_STRING(WideOutput, &amp;KeysPath);
            WIDE_OUTPUT_RAW(WideOutput, L".\n");
            WIDE_OUTPUT_FLUSH();

            Failed = TRUE;
            Failures++;
            goto DestroyKeys;
        }

        WIDE_OUTPUT_RAW(WideOutput, L"Successfully created perfect "
                                    L"hash table: ");
        WIDE_OUTPUT_UNICODE_STRING(WideOutput, &amp;TablePath);
        WIDE_OUTPUT_RAW(WideOutput, L".\n");

        //
        // Load the perfect hash table we just created.
        //

        Success = Api-&gt;LoadPerfectHashTable(Rtl,
                                            Allocator,
                                            Keys,
                                            &amp;TablePath,
                                            &amp;Table);

        if (!Success) {

            WIDE_OUTPUT_RAW(WideOutput, L"Failed to load perfect hash table: ");
            WIDE_OUTPUT_UNICODE_STRING(WideOutput, &amp;TablePath);
            WIDE_OUTPUT_RAW(WideOutput, L".\n");
            WIDE_OUTPUT_FLUSH();

            Failures++;
            goto DestroyKeys;

        }

        //
        // Table was loaded successfully from disk.  Obtain the names of all
        // the enumeration IDs.  Currently these should always match the same
        // enums provided as input parameters to this routine.
        //
        // N.B. I'm being lazy with the ASSERT()s here instead of reporting the
        //      error properly like we do with other failures.
        //

        ASSERT(Api-&gt;GetAlgorithmName(Table-&gt;AlgorithmId, &amp;AlgorithmName));

        ASSERT(Api-&gt;GetHashFunctionName(Table-&gt;HashFunctionId,
                                        &amp;HashFunctionName));

        ASSERT(Api-&gt;GetMaskFunctionName(Table-&gt;MaskFunctionId,
                                        &amp;MaskFunctionName));


        WIDE_OUTPUT_RAW(WideOutput, L"Successfully loaded perfect "
                                    L"hash table: ");
        WIDE_OUTPUT_UNICODE_STRING(WideOutput, &amp;TablePath);
        WIDE_OUTPUT_RAW(WideOutput, L".\n");

        WIDE_OUTPUT_RAW(WideOutput, L"Algorithm: ");
        WIDE_OUTPUT_UNICODE_STRING(WideOutput, AlgorithmName);
        WIDE_OUTPUT_RAW(WideOutput, L" (");
        WIDE_OUTPUT_INT(WideOutput, Table-&gt;AlgorithmId);
        WIDE_OUTPUT_RAW(WideOutput, L").\n");

        WIDE_OUTPUT_RAW(WideOutput, L"Hash Function: ");
        WIDE_OUTPUT_UNICODE_STRING(WideOutput, HashFunctionName);
        WIDE_OUTPUT_RAW(WideOutput, L" (");
        WIDE_OUTPUT_INT(WideOutput, Table-&gt;HashFunctionId);
        WIDE_OUTPUT_RAW(WideOutput, L").\n");

        WIDE_OUTPUT_RAW(WideOutput, L"Mask Function: ");
        WIDE_OUTPUT_UNICODE_STRING(WideOutput, MaskFunctionName);
        WIDE_OUTPUT_RAW(WideOutput, L" (");
        WIDE_OUTPUT_INT(WideOutput, Table-&gt;MaskFunctionId);
        WIDE_OUTPUT_RAW(WideOutput, L").\n");

        WIDE_OUTPUT_FLUSH();

        //
        // Test the table.
        //

        Success = Api-&gt;TestPerfectHashTable(Table, TRUE);

        if (!Success) {

            WIDE_OUTPUT_RAW(WideOutput, L"Test failed for perfect hash table "
                                        L"loaded from disk: ");
            WIDE_OUTPUT_UNICODE_STRING(WideOutput, &amp;TablePath);
            WIDE_OUTPUT_RAW(WideOutput, L".\n");
            WIDE_OUTPUT_FLUSH();

            Failures++;
            Failed = TRUE;
            goto DestroyTable;
        }

        WIDE_OUTPUT_RAW(WideOutput, L"Successfully tested perfect hash "
                                    L"table.\n");

        //
        // Initialize header alias.
        //

        Header = Table-&gt;Header;

        //
        // Define some helper macros here for dumping stats.
        //

#define STATS_INT(String, Name)                               \
        WIDE_OUTPUT_RAW(WideOutput, String);                  \
        WIDE_OUTPUT_INT(WideOutput, Table-&gt;Header-&gt;##Name##); \
        WIDE_OUTPUT_RAW(WideOutput, L".\n")

#define STATS_QUAD(String, Name)                                       \
        WIDE_OUTPUT_RAW(WideOutput, String);                           \
        WIDE_OUTPUT_INT(WideOutput, Table-&gt;Header-&gt;##Name##.QuadPart); \
        WIDE_OUTPUT_RAW(WideOutput, L".\n")

        if (Header-&gt;NumberOfTableResizeEvents &gt; 0) {

            STATS_INT(L"Number of table resize events: ",
                      NumberOfTableResizeEvents);

            STATS_INT(L"Total number of attempts with smaller table sizes: ",
                      TotalNumberOfAttemptsWithSmallerTableSizes);

            STATS_INT(L"First table size attempted: ",
                      InitialTableSize);

            STATS_INT(L"Closest we came to solving the graph in previous "
                      L"attempts by number of deleted edges away: ",
                      ClosestWeCameToSolvingGraphWithSmallerTableSizes);

        }

        STATS_INT(L"Concurrency: ", Concurrency);
        STATS_INT(L"Number of attempts: ", NumberOfAttempts);
        STATS_INT(L"Number of failed attempts: ", NumberOfFailedAttempts);
        STATS_INT(L"Number of solutions found: ", NumberOfSolutionsFound);

        STATS_QUAD(L"Number of keys: ", NumberOfKeys);
        STATS_QUAD(L"Number of table elements (vertices): ",
                   NumberOfTableElements);

        STATS_INT(L"Seed 1: ", Seed1);
        STATS_INT(L"Seed 2: ", Seed2);
        STATS_INT(L"Seed 3: ", Seed3);
        STATS_INT(L"Seed 4: ", Seed4);


        STATS_QUAD(L"Cycles to solve: ", SolveCycles);
        STATS_QUAD(L"Cycles to verify: ", VerifyCycles);
        STATS_QUAD(L"Cycles to prepare file: ", PrepareFileCycles);
        STATS_QUAD(L"Cycles to save file: ", SaveFileCycles);

        STATS_QUAD(L"Microseconds to solve: ", SolveMicroseconds);
        STATS_QUAD(L"Microseconds to verify: ", VerifyMicroseconds);
        STATS_QUAD(L"Microseconds to prepare file: ", PrepareFileMicroseconds);
        STATS_QUAD(L"Microseconds to save file: ", SaveFileMicroseconds);


        WIDE_OUTPUT_RAW(WideOutput, L"\n\n");
        WIDE_OUTPUT_FLUSH();

        //
        // Destroy the table.
        //

DestroyTable:

        Table-&gt;Vtbl-&gt;Release(Table);

DestroyKeys:

        Success = Api-&gt;DestroyPerfectHashTableKeys(&amp;Keys);
        if (!Success) {

            WIDE_OUTPUT_RAW(WideOutput, L"Failed to destroy keys for ");
            WIDE_OUTPUT_UNICODE_STRING(WideOutput, &amp;KeysPath);
            WIDE_OUTPUT_RAW(WideOutput, L".\n");
            WIDE_OUTPUT_FLUSH();

            Failures++;
        }

DestroyContext:

        Success = Api-&gt;DestroyPerfectHashTableContext(&amp;Context, NULL);
        if (!Success) {

            //
            // Failure to destroy a context is a fatal error that we can't
            // recover from.  Bomb out now.
            //

            WIDE_OUTPUT_RAW(WideOutput, L"Fatal: failed to destroy context.\n");
            WIDE_OUTPUT_FLUSH();

            Failures++;
            break;
        }

    } while (FindNextFile(FindHandle, &amp;FindData));

    //
    // Self test complete!
    //

    if (!Failures) {
        Success = TRUE;
        goto End;
    }

    //
    // Intentional follow-on to Error.
    //

Error:

    Success = FALSE;

    //
    // Intentional follow-on to End.
    //

End:

    //
    // We can't do much if any of these routines error out, hence the NOTHINGs.
    //

    if (WideOutputBuffer) {
        if (!Rtl-&gt;DestroyBuffer(Rtl, ProcessHandle, &amp;WideOutputBuffer)) {
            NOTHING;
        }
        WideOutput = NULL;
    }

    if (BaseBuffer) {
        if (!Rtl-&gt;DestroyBuffer(Rtl, ProcessHandle, &amp;BaseBuffer)) {
            NOTHING;
        }
        Buffer = NULL;
    }

    if (FindHandle) {
        if (!FindClose(FindHandle)) {
            NOTHING;
        }
        FindHandle = NULL;
    }

    return Success;
}
</code></pre>
                    </div>
                </div>

                <p>

                    The self-test routine creates a context, loads a key file, creates a perfect
                    hash table using the context from the key file, tests the perfect hash table,
                    then destroys it, the keys, and the context.  Let's take a look at each routine
                    and any corresponding data structures involved.

                </p>

                <a class="xref" name="context-creation"></a>
                <h2>Context Creation</h2>

                <p>

                    This routine is responsible for creating a
                    <code>PERFECT_HASH_TABLE_CONTEXT</code> structure, which we use to encapsulate
                    all of the details regarding the threadpool machinery we provide to the backend
                    algorithm implementations such that solutions can be sought in parallel.  The
                    context is passed to the <code>CreatePerfectHashTable()</code> routine (along
                    with the keys we load in the next step).

                </p>

                <a class="xref" name="PERFECT_HASH_TABLE_CONTEXT"></a>
                <h3>PERFECT_HASH_TABLE_CONTEXT</h3>

                <p>

                    The public header gets an opaque structure for the context.  We don't need to
                    expose any internal details of the structure to consumers, other than providing
                    with an opaque pointer they can subsequently pass to the creation routine, and
                    then to the <code>DestroyPerfectHashTableContext()</code> routine once they're
                    finished creating perfect hash tables.

                </p>

                <p>

                    The structure is defined in the private header
                    <a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/PerfectHashTablePrivate.h">PerfectHashTablePrivate.h</a>
                    and looks like this:

                </p>

<pre class="code"><code class="language-c">//
// Define a runtime context to encapsulate threadpool resources.  This is
// passed to CreatePerfectHashTable() and allows for algorithms to search for
// perfect hash solutions in parallel.
//

typedef union _PERFECT_HASH_TABLE_CONTEXT_FLAGS {
    struct {
        ULONG Unused:32;
    };
    LONG AsLong;
    ULONG AsULong;
} PERFECT_HASH_TABLE_CONTEXT_FLAGS;
C_ASSERT(sizeof(PERFECT_HASH_TABLE_CONTEXT_FLAGS) == sizeof(ULONG));
typedef PERFECT_HASH_TABLE_CONTEXT_FLAGS *PPERFECT_HASH_TABLE_CONTEXT_FLAGS;

typedef struct _Struct_size_bytes_(SizeOfStruct) _PERFECT_HASH_TABLE_CONTEXT {

    //
    // Size of the structure, in bytes.
    //

    _Field_range_(==, sizeof(struct _PERFECT_HASH_TABLE_CONTEXT))
        ULONG SizeOfStruct;

    //
    // Flags.
    //

    PERFECT_HASH_TABLE_CONTEXT_FLAGS Flags;

    //
    // The algorithm in use.
    //

    PERFECT_HASH_TABLE_ALGORITHM_ID AlgorithmId;

    //
    // The masking type in use.
    //

    PERFECT_HASH_TABLE_MASK_FUNCTION_ID MaskFunctionId;

    //
    // The hash function in use.
    //

    PERFECT_HASH_TABLE_HASH_FUNCTION_ID HashFunctionId;

    //
    // Pointer to an initialized RTL structure.
    //

    PRTL Rtl;

    //
    // Pointer to an initialized allocator.
    //

    PALLOCATOR Allocator;

    //
    // Pointer to the API structure in use.
    //

    PPERFECT_HASH_TABLE_ANY_API AnyApi;

    //
    // Pointer to the active perfect hash table.
    //

    struct _PERFECT_HASH_TABLE *Table;

    //
    // The highest number of deleted edges count encountered by a worker thread.
    // This is useful when debugging a poorly performing hash/mask combo that is
    // failing to find a solution.
    //

    volatile ULONG HighestDeletedEdgesCount;

    //
    // The number of attempts we'll make at trying to solve the graph before
    // giving up and resizing with a larger underlying table.
    //

    ULONG ResizeTableThreshold;

    //
    // Limit on how many times a resize will be kicked off.
    //

    ULONG ResizeLimit;

    //
    // Define the events used to communicate various internal state changes
    // between the CreatePerfectHashTable() function and the algorithm-specific
    // creation routine.
    //
    // N.B. All of these events are created with the manual reset flag set to
    //      TRUE, such that they stay signalled even after they have satisfied
    //      a wait.
    //

    //
    // A global "shutdown" event handle that threads can query to determine
    // whether or not they should continue processing at various internal
    // checkpoints.
    //

    union {
        HANDLE ShutdownEvent;
        PVOID FirstEvent;
    };

    //
    // This event will be set if an algorithm was successful in finding a
    // perfect hash.  Either it or the FailedEvent will be set; never both.
    //

    HANDLE SucceededEvent;

    //
    // This event will be set if an algorithm failed to find a perfect hash
    // solution.  This may be due to the algorithm exhausting all possible
    // options, hitting a time limit, or potentially as a result of being
    // forcibly terminated or some other internal error.  It will never be
    // set if SucceededEvent is also set.
    //

    HANDLE FailedEvent;

    //
    // The following event is required to be set by an algorithm's creation
    // routine upon completion (regardless of success or failure).  This event
    // is waited upon by the CreatePerfectHashTable() function, and thus, is
    // critical in synchronizing the execution of parallel perfect hash solution
    // finding.
    //

    HANDLE CompletedEvent;

    //
    // The following event is set when a worker thread detects that the number
    // of attempts has exceeded a specified threshold, and that the main thread
    // should cancel the current attempts and try again with a larger vertex
    // table size.
    //

    HANDLE TryLargerTableSizeEvent;

    //
    // The following event is set when a worker thread has completed preparing
    // the underlying backing file in order for the solved graph to be persisted
    // to disk.
    //

    HANDLE PreparedFileEvent;

    //
    // The following event is set by the main thread when it has completed
    // verification of the solved graph.  It is used to signal to the save
    // file worker that verification has finished such that cycle counts can
    // be captured in order to calculate the number of cycles and microseconds
    // it took to verify the graph.
    //

    HANDLE VerifiedEvent;

    //
    // The following event is set when a worker thread has completed saving the
    // solved graph to disk.
    //

    union {
        HANDLE SavedFileEvent;
        PVOID LastEvent;
    };

    //
    // N.B. All events are created as named events, using the random object
    //      name generation helper Rtl-&gt;CreateRandomObjectNames().  This will
    //      fill out an array of PUNICODE_STRING pointers.  The next field
    //      points to the first element of that array.  Subsequent fields
    //      capture various book-keeping items about the random object names
    //      allocation (provided by the Rtl routine).
    //

    PUNICODE_STRING ObjectNames;
    PPUNICODE_STRING ObjectNamesPointerArray;
    PWSTR ObjectNamesWideBuffer;
    ULONG SizeOfObjectNamesWideBuffer;
    ULONG NumberOfObjects;

    //
    // Number of attempts made by the algorithm to find a solution.
    //

    volatile ULONGLONG Attempts;

    //
    // Counters used for capturing performance information.  We capture both a
    // cycle count, using __rdtsc(), plus a "performance counter" count, via
    // QueryPerformanceCounter().  The former provides a finer resolution, but
    // can't be used to calculate elapsed microseconds due to turbo boost and
    // variable frequencies.  The latter provides a coarser resolution, but
    // can be used to convert into elapsed microseconds (via the frequency,
    // also captured below).
    //

    LARGE_INTEGER Frequency;

    //
    // Capture the time required to solve the perfect hash table.  This is not
    // a sum of all cycles consumed by all worker threads; it is the cycles
    // consumed between the "main" thread (i.e. the CreatePerfectHashTable()
    // impl routine (CreatePerfectHashTableImplChm01())) dispatching parallel
    // work to the threadpool, and a solution being found.
    //

    ULARGE_INTEGER SolveStartCycles;
    LARGE_INTEGER SolveStartCounter;

    ULARGE_INTEGER SolveEndCycles;
    LARGE_INTEGER SolveEndCounter;

    ULARGE_INTEGER SolveElapsedCycles;
    ULARGE_INTEGER SolveElapsedMicroseconds;

    //
    // Capture the time required to verify the solution.  This involves walking
    // the entire key set, applying the perfect hash function to derive an index
    // into the Assigned array, and verifying that we only saw each index value
    // at most once.
    //
    // This is a reasonably good measure of the combined performance of the
    // chosen hash and mask algorithm, with lower cycles and counter values
    // indicating better performance.
    //

    ULARGE_INTEGER VerifyStartCycles;
    LARGE_INTEGER VerifyStartCounter;

    ULARGE_INTEGER VerifyEndCycles;
    LARGE_INTEGER VerifyEndCounter;

    ULARGE_INTEGER VerifyElapsedCycles;
    ULARGE_INTEGER VerifyElapsedMicroseconds;

    //
    // Capture the time required to prepare the backing .pht1 file in the file
    // work threadpool.
    //

    ULARGE_INTEGER PrepareFileStartCycles;
    LARGE_INTEGER PrepareFileStartCounter;

    ULARGE_INTEGER PrepareFileEndCycles;
    LARGE_INTEGER PrepareFileEndCounter;

    ULARGE_INTEGER PrepareFileElapsedCycles;
    ULARGE_INTEGER PrepareFileElapsedMicroseconds;

    //
    // Capture the time required to save the final Assigned array to the backing
    // file prepared in an earlier step.  This is also dispatched to the file
    // work thread pool, and consists of a memory copy from the assigned array
    // of the graph to the base address of the backing file's memory map, then
    // flushing the map, unmapping it, closing the section, and closing the
    // file.
    //

    ULARGE_INTEGER SaveFileStartCycles;
    LARGE_INTEGER SaveFileStartCounter;

    ULARGE_INTEGER SaveFileEndCycles;
    LARGE_INTEGER SaveFileEndCounter;

    ULARGE_INTEGER SaveFileElapsedCycles;
    ULARGE_INTEGER SaveFileElapsedMicroseconds;

    //
    // Number of failed attempts at solving the graph across all threads.
    //

    volatile ULONGLONG FailedAttempts;

    //
    // The main threadpool callback environment, used for solving perfect hash
    // solutions in parallel.
    //

    TP_CALLBACK_ENVIRON MainCallbackEnv;
    PTP_CLEANUP_GROUP MainCleanupGroup;
    PTP_POOL MainThreadpool;
    PTP_WORK MainWork;
    SLIST_HEADER MainWorkListHead;
    ULONG MinimumConcurrency;
    ULONG MaximumConcurrency;

    //
    // The algorithm is responsible for registering an appropriate callback
    // for main thread work items in this next field.
    //

    PPERFECT_HASH_TABLE_MAIN_WORK_CALLBACK MainWorkCallback;

    //
    // A threadpool for offloading file operations.
    //

    TP_CALLBACK_ENVIRON FileCallbackEnv;
    PTP_CLEANUP_GROUP FileCleanupGroup;
    PTP_POOL FileThreadpool;
    PTP_WORK FileWork;
    SLIST_HEADER FileWorkListHead;

    //
    // Provide a means for file work callbacks to indicate an error back to
    // the creation routine by incrementing the following counter.
    //

    volatile ULONG FileWorkErrors;
    volatile ULONG FileWorkLastError;

    //
    // The algorithm is responsible for registering an appropriate callback
    // for file work threadpool work items in this next field.
    //

    PPERFECT_HASH_TABLE_FILE_WORK_CALLBACK FileWorkCallback;

    //
    // If a threadpool worker thread finds a perfect hash solution, it will
    // enqueue a "Finished!"-type work item to a separate threadpool, captured
    // by the following callback environment.  This allows for a separate
    // threadpool worker to schedule the cancellation of other in-progress
    // and outstanding perfect hash solution attempts without deadlocking.
    //
    // This threadpool environment is serviced by a single thread.
    //
    // N.B. This cleanup only refers to the main graph solving thread pool.
    //      The file threadpool is managed by the implicit lifetime of the
    //      algorithm's creation routine (e.g. CreatePerfectHashTableImplChm01).
    //

    TP_CALLBACK_ENVIRON FinishedCallbackEnv;
    PTP_POOL FinishedThreadpool;
    PTP_WORK FinishedWork;
    SLIST_HEADER FinishedWorkListHead;

    //
    // If a worker thread successfully finds a perfect hash solution, it will
    // push its solution to the FinishedListHead above, then submit a finished
    // work item via SubmitThreadpoolWork(Context-&gt;FinishedWork).
    //
    // This callback will be processed by the finished group above, and provides
    // a means for that thread to set the ShutdownEvent and cancel outstanding
    // main work callbacks.
    //
    // N.B. Although we only need one solution, we don't prevent multiple
    //      successful solutions from being pushed to the FinishedListHead.
    //      Whatever the first solution is that the finished callback pops
    //      off that list is the solution that wins.
    //

    volatile ULONGLONG FinishedCount;

    //
    // Similar to the Finished group above, provide an Error group that also
    // consists of a single thread.  If a main threadpool worker thread runs
    // into a fatal error that requires termination of all in-progress and
    // outstanding threadpool work items, it can just dispatch a work item
    // to this particular pool (e.g. SubmitThreadpoolWork(Context-&gt;ErrorWork)).
    //
    // There is no ErrorListHead as no error information is captured that needs
    // communicating back to a central location.
    //

    TP_CALLBACK_ENVIRON ErrorCallbackEnv;
    PTP_POOL ErrorThreadpool;
    PTP_WORK ErrorWork;

    //
    // An opaque pointer that can be used by the algorithm to stash additional
    // context.
    //

    PVOID AlgorithmContext;

    //
    // An opaque pointer that can be used by the hash function to stash
    // additional context.
    //

    PVOID HashFunctionContext;

    //
    // An opaque pointer to the winning solution (i.e. the solved graph).
    //

    PVOID SolvedContext;

} PERFECT_HASH_TABLE_CONTEXT;
typedef PERFECT_HASH_TABLE_CONTEXT *PPERFECT_HASH_TABLE_CONTEXT;

//
// Define helper macros for marking start/end points for the context's
// cycle/counter fields.  When starting, we put __rdtsc() last, and when
// stopping we put it first, as its resolution is more sensitive than the
// QueryPerformanceCounter() routine.
//

#define CONTEXT_START_TIMERS(Name)                           \
    QueryPerformanceCounter(&amp;Context-&gt;##Name##StartCounter); \
    Context-&gt;##Name##StartCycles.QuadPart = __rdtsc()

#define CONTEXT_END_TIMERS(Name)                              \
    Context-&gt;##Name##EndCycles.QuadPart = __rdtsc();          \
    QueryPerformanceCounter(&amp;Context-&gt;##Name##EndCounter);    \
    Context-&gt;##Name##ElapsedCycles.QuadPart = (               \
        Context-&gt;##Name##EndCycles.QuadPart -                 \
        Context-&gt;##Name##StartCycles.QuadPart                 \
    );                                                        \
    Context-&gt;##Name##ElapsedMicroseconds.QuadPart = (         \
        Context-&gt;##Name##EndCounter.QuadPart -                \
        Context-&gt;##Name##StartCounter.QuadPart                \
    );                                                        \
    Context-&gt;##Name##ElapsedMicroseconds.QuadPart *= 1000000; \
    Context-&gt;##Name##ElapsedMicroseconds.QuadPart /= (        \
        Context-&gt;Frequency.QuadPart                           \
    )

#define CONTEXT_SAVE_TIMERS_TO_HEADER(Name)                                    \
    Header-&gt;##Name##Cycles.QuadPart = Context-&gt;##Name##ElapsedCycles.QuadPart; \
    Header-&gt;##Name##Microseconds.QuadPart = (                                  \
        Context-&gt;##Name##ElapsedMicroseconds.QuadPart                          \
    )</code></pre>

                <a class="xref" name="CreatePerfectHashTableContext"></a>
                <h3>CreatePerfectHashTableContext()</h3>

                <p>

                    The creation routine is defined in
                    <a href="https://github.com/tpn/tracer/blob/master/PerfectHashTable/CreatePerfectHashTableContext.c">CreatePerfectHashTableContext.c</a>.
                    Pseudo and full code samples follow.

                </p>

                <div class="tab-box language box-create-context">
                    <ul class="tabs">
                        <li data-content="content-create-context-pseudo">Pseudo</li>
                        <li data-content="content-create-context-full">Full</li>
                    </ul>
                    <div class="content">
<pre class="code content-create-context-pseudo"><code class="language-c">_Use_decl_annotations_
BOOLEAN
CreatePerfectHashTableContext(
    PRTL Rtl,
    PALLOCATOR Allocator,
    PULONG MaximumConcurrencyPointer,
    PPERFECT_HASH_TABLE_CONTEXT *ContextPointer
    )
/*++

Routine Description:

    Creates and initializes a PERFECT_HASH_TABLE_CONTEXT structure, which
    creates a main threadpool with a maximum of threads indicated by the
    MaximumConcurrency parameter, if applicable.

Arguments:

    Rtl - Supplies a pointer to an initialized RTL structure.

    Allocator - Supplies a pointer to an initialized ALLOCATOR structure that
        will be used for all memory allocations.

    AnyApi - Supplies a pointer to the active API structure in use.

    MaximumConcurrency - Optionally supplies a pointer to a variable that
        contains the desired maximum concurrency to be used for the underlying
        threadpool.  If NULL, or non-NULL but points to a value of 0, then the
        number of system processors will be used as a default value.

        N.B. This value is passed directly to SetThreadpoolThreadMinimum() and
             SetThreadpoolThreadMaximum().

    ContextPointer - Supplies the address of a variable that receives the
        address of the newly created PERFECT_HASH_TABLE_CONTEXT structure on
        success, NULL on failure.

Return Value:

    TRUE on success, FALSE on failure.

--*/
{

    ValidateArguments();

    //
    // Calculate allocation size required by the structure.
    //

    CalculateAllocationSize(&amp;AllocSize);

    //
    // Allocate it.
    //

    Context = AllocateContext(AllocSize);

    //
    // Create the random object names for our underlying events.
    //

    Success = Rtl-&gt;CreateRandomObjectNames(Rtl,
                                           Allocator,
                                           Allocator,
                                           NumberOfContextObjectPrefixes,
                                           64,
                                           NULL,
                                           Context-&gt;ObjectNamesPointerArray,
                                           Prefixes,
                                           &amp;SizeOfNamesWideBuffer,
                                           &amp;NamesWideBuffer);


    //
    // Create named events.
    //

    for (Index = 0; Index &lt; NumberOfEvents; Index++, Event++, Name++) {

        //
        // We want all of our events to be manual reset, such that they stay
        // signaled even after they've satisfied a wait.
        //

        BOOLEAN ManualReset = TRUE;

        *Event = Rtl-&gt;CreateEventW(NULL,
                                   ManualReset,
                                   FALSE,
                                   Name-&gt;Buffer);

    }

    //
    // Create our threadpools: main work, file work, finished, error.
    //

    CreateMainWorkThreadpoolResources(Context);

    CreateFileWorkThreadpoolResources(Context);

    CreateFinishedWorkThreadpoolResources(Context);

    CreateErrorWorkThreadpoolResources(Context);

    *ContextPointer = Context;

    return TRUE;
}</code></pre>
<pre class="code content-create-context-full"><code class="language-c">_Use_decl_annotations_
BOOLEAN
CreatePerfectHashTableContext(
    PRTL Rtl,
    PALLOCATOR Allocator,
    PULONG MaximumConcurrencyPointer,
    PPERFECT_HASH_TABLE_CONTEXT *ContextPointer
    )
/*++

Routine Description:

    Creates and initializes a PERFECT_HASH_TABLE_CONTEXT structure, which
    creates a main threadpool with a maximum of threads indicated by the
    MaximumConcurrency parameter, if applicable.

Arguments:

    Rtl - Supplies a pointer to an initialized RTL structure.

    Allocator - Supplies a pointer to an initialized ALLOCATOR structure that
        will be used for all memory allocations.

    AnyApi - Supplies a pointer to the active API structure in use.

    MaximumConcurrency - Optionally supplies a pointer to a variable that
        contains the desired maximum concurrency to be used for the underlying
        threadpool.  If NULL, or non-NULL but points to a value of 0, then the
        number of system processors will be used as a default value.

        N.B. This value is passed directly to SetThreadpoolThreadMinimum() and
             SetThreadpoolThreadMaximum().

    ContextPointer - Supplies the address of a variable that receives the
        address of the newly created PERFECT_HASH_TABLE_CONTEXT structure on
        success, NULL on failure.

Return Value:

    TRUE on success, FALSE on failure.

--*/
{
    BYTE Index;
    BYTE NumberOfEvents;
    ULONG LastError;
    PHANDLE Event;
    BOOLEAN Success;
    PBYTE Buffer;
    PBYTE ExpectedBuffer;
    ULONG MaximumConcurrency;
    ULONG NumberOfProcessors;
    ULONG SizeOfNamesWideBuffer;
    PWSTR NamesWideBuffer;
    PTP_POOL Threadpool;
    ULARGE_INTEGER AllocSize;
    ULARGE_INTEGER ObjectNameArraySize;
    ULARGE_INTEGER ObjectNamePointersArraySize;
    PUNICODE_STRING Name;
    PPUNICODE_STRING Names;
    PPUNICODE_STRING Prefixes;
    PPERFECT_HASH_TABLE_CONTEXT Context = NULL;

    //
    // Validate arguments.
    //

    if (!ARGUMENT_PRESENT(Rtl)) {
        return FALSE;
    }

    if (!ARGUMENT_PRESENT(Allocator)) {
        return FALSE;
    }

    if (!ARGUMENT_PRESENT(ContextPointer)) {
        return FALSE;
    }

    //
    // Default the maximum concurrency to 0 if a NULL pointer was provided.
    //

    if (ARGUMENT_PRESENT(MaximumConcurrencyPointer)) {

        MaximumConcurrency = *MaximumConcurrencyPointer;

    } else {

        MaximumConcurrency = 0;

    }

    //
    // Argument validation complete.  Clear the caller's pointer up-front and
    // continue with creation.
    //

    *ContextPointer = NULL;

    //
    // Calculate the size required by the array of UNICODE_STRING structures
    // that trail the context, then the array of addresses to those structures.
    //

    ObjectNameArraySize.QuadPart = (
        (NumberOfContextObjectPrefixes * sizeof(UNICODE_STRING))
    );

    ObjectNamePointersArraySize.QuadPart = (
        (NumberOfContextObjectPrefixes * sizeof(PUNICODE_STRING))
    );

    ASSERT(!ObjectNameArraySize.HighPart);
    ASSERT(!ObjectNamePointersArraySize.HighPart);

    //
    // Calculate allocation size required by the structure.
    //

    AllocSize.QuadPart = (

        //
        // Account for the size of the context structure itself.
        //

        sizeof(PERFECT_HASH_TABLE_CONTEXT) +

        //
        // Account for the object name overhead.
        //

        ObjectNameArraySize.QuadPart +
        ObjectNamePointersArraySize.QuadPart

    );

    //
    // Sanity check we haven't overflowed.
    //

    ASSERT(!AllocSize.HighPart);

    //
    // Allocate space for the context.
    //

    Context = (PPERFECT_HASH_TABLE_CONTEXT)(
        Allocator-&gt;Calloc(Allocator-&gt;Context,
                          1,
                          AllocSize.LowPart)
    );

    if (!Context) {
        return FALSE;
    }

    //
    // Allocation was successful, continue with initialization.
    //

    Context-&gt;SizeOfStruct = sizeof(*Context);
    Context-&gt;Rtl = Rtl;
    Context-&gt;Allocator = Allocator;
    Context-&gt;Flags.AsULong = 0;

    //
    // The context structure will be trailed by an array of UNICODE_STRING
    // structures that will be filled in by Rtl-&gt;CreateRandomObjectNames().
    // This is then followed by an array of PUNICODE_STRING pointers, with
    // each one initialized to point to the corresponding offset into the
    // first array.  This is a bit quirky, but it's required by the Rtl
    // method (which allows for prefixes to be ignored for certain objects
    // if desired).
    //

    Buffer = (PBYTE)Context;
    Buffer += sizeof(*Context);
    Context-&gt;ObjectNames = (PUNICODE_STRING)Buffer;

    Buffer += ObjectNameArraySize.LowPart;
    Context-&gt;ObjectNamesPointerArray = (PPUNICODE_STRING)Buffer;

    Buffer += ObjectNamePointersArraySize.LowPart;

    //
    // If our pointer arithmetic was correct, Buffer should match the base
    // address of the context plus the total allocation size at this point.
    // Assert this invariant now.
    //

    ExpectedBuffer = RtlOffsetToPointer(Context, AllocSize.LowPart);
    ASSERT(Buffer == ExpectedBuffer);

    //
    // Wire up the pointer array to the object names.
    //

    Names = Context-&gt;ObjectNamesPointerArray;

    for (Index = 0; Index &lt; NumberOfContextObjectPrefixes; Index++) {
        Names[Index] = Context-&gt;ObjectNames + Index;
    }

    //
    // Create the random object names for our underlying events.
    //

    Prefixes = (PPUNICODE_STRING)&amp;ContextObjectPrefixes;

    Success = Rtl-&gt;CreateRandomObjectNames(Rtl,
                                           Allocator,
                                           Allocator,
                                           NumberOfContextObjectPrefixes,
                                           64,
                                           NULL,
                                           Context-&gt;ObjectNamesPointerArray,
                                           Prefixes,
                                           &amp;SizeOfNamesWideBuffer,
                                           &amp;NamesWideBuffer);

    if (!Success) {
        goto Error;
    }

    //
    // Wire up the wide buffer pointer and containing size.
    //

    Context-&gt;ObjectNamesWideBuffer = NamesWideBuffer;
    Context-&gt;SizeOfObjectNamesWideBuffer = SizeOfNamesWideBuffer;
    Context-&gt;NumberOfObjects = NumberOfContextObjectPrefixes;


    //
    // Initialize the event pointer to the first handle, and the name pointer
    // to the first UNICODE_STRING pointer.  Obtain the number of events.
    //

    Event = (PHANDLE)&amp;Context-&gt;FirstEvent;
    Name = &amp;Context-&gt;ObjectNames[0];
    NumberOfEvents = GetNumberOfContextEvents(Context);

    for (Index = 0; Index &lt; NumberOfEvents; Index++, Event++, Name++) {

        //
        // We want all of our events to be manual reset, such that they stay
        // signaled even after they've satisfied a wait.
        //

        BOOLEAN ManualReset = TRUE;

        *Event = Rtl-&gt;CreateEventW(NULL,
                                   ManualReset,
                                   FALSE,
                                   Name-&gt;Buffer);

        LastError = GetLastError();

        if (!*Event || LastError == ERROR_ALREADY_EXISTS) {

            //
            // As the event names are random, a last error that indicates the
            // name already exists is evident of a pretty serious problem.
            // Treat this as a fatal.
            //

            goto Error;
        }
    }

    //
    // If the maximum concurrency is 0, default to the number of processors.
    //

    NumberOfProcessors = GetMaximumProcessorCount(ALL_PROCESSOR_GROUPS);

    if (MaximumConcurrency == 0) {
        MaximumConcurrency = NumberOfProcessors;
    }

    Context-&gt;MinimumConcurrency = MaximumConcurrency;
    Context-&gt;MaximumConcurrency = MaximumConcurrency;

    //
    // Create the Main threadpool structures.  This threadpool creates a fixed
    // number of threads equal to the maximum concurrency specified by the user
    // (e.g. min threads is set to the same value as max threads).
    //

    Threadpool = Context-&gt;MainThreadpool = CreateThreadpool(NULL);
    if (!Threadpool) {
        goto Error;
    }

    if (!SetThreadpoolThreadMinimum(Threadpool, MaximumConcurrency)) {
        goto Error;
    }

    SetThreadpoolThreadMaximum(Threadpool, MaximumConcurrency);

    //
    // Initialize the Main threadpool environment, set its priority to
    // low, then associate it with the Main threadpool.
    //

    InitializeThreadpoolEnvironment(&amp;Context-&gt;MainCallbackEnv);
    SetThreadpoolCallbackPriority(&amp;Context-&gt;MainCallbackEnv,
                                  TP_CALLBACK_PRIORITY_LOW);
    SetThreadpoolCallbackPool(&amp;Context-&gt;MainCallbackEnv,
                              Context-&gt;MainThreadpool);

    //
    // Create a cleanup group for the Main threadpool and register it.
    //

    Context-&gt;MainCleanupGroup = CreateThreadpoolCleanupGroup();
    if (!Context-&gt;MainCleanupGroup) {
        goto Error;
    }

    SetThreadpoolCallbackCleanupGroup(&amp;Context-&gt;MainCallbackEnv,
                                      Context-&gt;MainCleanupGroup,
                                      CleanupCallback);

    //
    // Create a work object for the Main threadpool.
    //

    Context-&gt;MainWork = CreateThreadpoolWork(MainWorkCallback,
                                             Context,
                                             &amp;Context-&gt;MainCallbackEnv);

    if (!Context-&gt;MainWork) {
        goto Error;
    }

    //
    // Initialize the main work list head.
    //

    InitializeSListHead(&amp;Context-&gt;MainWorkListHead);

    //
    // Create the File threadpool structures.  We currently use the default
    // number of system threads for this threadpool.  We don't have to clamp
    // it at the moment as we don't bulk-enqueue work items (that can cause
    // the threadpool machinery to think more threads need to be created).
    //

    Threadpool = Context-&gt;FileThreadpool = CreateThreadpool(NULL);
    if (!Threadpool) {
        goto Error;
    }

    //
    // Initialize the File threadpool environment and associate it with the
    // File threadpool.
    //

    InitializeThreadpoolEnvironment(&amp;Context-&gt;FileCallbackEnv);
    SetThreadpoolCallbackPool(&amp;Context-&gt;FileCallbackEnv,
                              Context-&gt;FileThreadpool);

    //
    // Create a cleanup group for the File threadpool and register it.
    //

    Context-&gt;FileCleanupGroup = CreateThreadpoolCleanupGroup();
    if (!Context-&gt;FileCleanupGroup) {
        goto Error;
    }

    SetThreadpoolCallbackCleanupGroup(&amp;Context-&gt;FileCallbackEnv,
                                      Context-&gt;FileCleanupGroup,
                                      CleanupCallback);

    //
    // Create a work object for the File threadpool.
    //

    Context-&gt;FileWork = CreateThreadpoolWork(FileWorkCallback,
                                             Context,
                                             &amp;Context-&gt;FileCallbackEnv);

    if (!Context-&gt;FileWork) {
        goto Error;
    }

    //
    // Initialize the main work list head.
    //

    InitializeSListHead(&amp;Context-&gt;FileWorkListHead);

    //
    // Create the Finished and Error threadpools and associated resources.
    // These are slightly easier as we only have 1 thread maximum for each
    // pool and no cleanup group is necessary.
    //

    Context-&gt;FinishedThreadpool = CreateThreadpool(NULL);
    if (!Context-&gt;FinishedThreadpool) {
        goto Error;
    }

    if (!SetThreadpoolThreadMinimum(Context-&gt;FinishedThreadpool, 1)) {
        goto Error;
    }

    SetThreadpoolThreadMaximum(Context-&gt;FinishedThreadpool, 1);

    Context-&gt;FinishedWork = CreateThreadpoolWork(FinishedWorkCallback,
                                                 Context,
                                                 &amp;Context-&gt;FinishedCallbackEnv);
    if (!Context-&gt;FinishedWork) {
        goto Error;
    }

    //
    // Initialize the finished list head.
    //

    InitializeSListHead(&amp;Context-&gt;FinishedWorkListHead);

    //
    // Create the Error threadpool.
    //

    Context-&gt;ErrorThreadpool = CreateThreadpool(NULL);
    if (!Context-&gt;ErrorThreadpool) {
        goto Error;
    }

    if (!SetThreadpoolThreadMinimum(Context-&gt;ErrorThreadpool, 1)) {
        goto Error;
    }

    SetThreadpoolThreadMaximum(Context-&gt;ErrorThreadpool, 1);

    Context-&gt;ErrorWork = CreateThreadpoolWork(ErrorWorkCallback,
                                              Context,
                                              &amp;Context-&gt;ErrorCallbackEnv);
    if (!Context-&gt;ErrorWork) {
        goto Error;
    }


    //
    // We're done!  Jump to the end of the routine to finish up.
    //

    Success = TRUE;
    goto End;

Error:

    Success = FALSE;

    //
    // Call the destroy routine on the context if it is non-NULL.
    //

    if (Context) {

        if (!DestroyPerfectHashTableContext(&amp;Context, NULL)) {

            //
            // There's nothing we can do here.
            //

            NOTHING;
        }

        //
        // N.B. DestroyPerfectHashTableContext() should clear the Context
        //      pointer.  Assert that invariant now.
        //

        ASSERT(Context == NULL);
    }

    //
    // Intentional follow-on to End.
    //

End:

    //
    // Update the caller's pointer and return.
    //
    // N.B. Context could be NULL here, which is fine.
    //

    *ContextPointer = Context;

    return Success;
}
</code></pre>
                    </div>
                </div>

                <p>

                    The <code>Rtl-&gt;CreateRandomObjectNames()</code> function warrants a little
                    extra explanation.  Its role can best be appreciated when viewing the named
                    event handles created for the context.  The following screenshot was taken
                    with Process Hacker 2, which has a convenient means for interacting with a
                    process's named events:

                    <picture>
                        <source srcset="Events.png"/>
                        <img width="1018px" height="1126px" srcset="Events.png"/>
                    </picture>

                </p>

                <p>

                    Being able to select an event and set, reset or pulse it can be very useful
                    during development and debugging, especially in a mulithreaded environment
                    where the events will typically have one or more threads waiting on them at
                    various points.

                </p>

                <p>

                    The <a
                    href="https://github.com/tpn/tracer/blob/49df7b95dc499c56423af178dfd687b786aaa610/Rtl/Rtl.c#L3693">
                    <code>CreateRandomObjectNames()</code></a> routine, when given an array of
                    object name prefixes, will create names suitable for passing directly to any of
                    the NT routines that allow naming of resources (events, sections, etc).  It
                    appends a configurable amount of Base64-encoded random data to each name,
                    ensuring uniqueness across the entire machine.

                </p>

                <a class="xref" name="key-loading"></a>
                <h2>Key Loading</h2>

                <p>

                    The key loader routine is one of our more simple routines.  It memory maps the
                    given .keys file such that it can be accessed as a linear 1D array of
                    <code>ULONG</code> values by the creation routines down the track.  It produces
                    an instance of a <code>PERFECT_HASH_TABLE_KEYS</code> structure, for which an
                    opaque pointer is returned to the caller.

                </p>

                <a class="xref" name="PERFECT_HASH_TABLE_KEYS"></a>
                <h3>PERFECT_HASH_TABLE_KEYS</h3>

<pre class="code"><code class="language-c">//
// Cap the maximum key set size we're willing to process.
//

#define MAXIMUM_NUMBER_OF_KEYS 500000

//
// Define the PERFECT_HASH_TABLE_KEYS_FLAGS structure.
//

typedef union _PERFECT_HASH_TABLE_FLAGS_KEYS {
    struct _Struct_size_bytes_(sizeof(ULONG)) {

        //
        // Unused bits.
        //

        ULONG Unused:32;
    };

    LONG AsLong;
    ULONG AsULong;
} PERFECT_HASH_TABLE_KEYS_FLAGS;
C_ASSERT(sizeof(PERFECT_HASH_TABLE_KEYS_FLAGS) == sizeof(ULONG));
typedef PERFECT_HASH_TABLE_KEYS_FLAGS *PPERFECT_HASH_TABLE_KEYS_FLAGS;

//
// Define the PERFECT_HASH_TABLE_KEYS structure.
//

typedef struct _Struct_size_bytes_(SizeOfStruct) _PERFECT_HASH_TABLE_KEYS {

    //
    // Reserve a slot for a vtable.  Currently unused.
    //

    PPVOID Vtbl;

    //
    // Size of the structure, in bytes.
    //

    _Field_range_(==, sizeof(struct _PERFECT_HASH_TABLE_KEYS))
        ULONG SizeOfStruct;

    //
    // Flags.
    //

    PERFECT_HASH_TABLE_KEYS_FLAGS Flags;

    //
    // Pointer to an initialized RTL structure.
    //

    PRTL Rtl;

    //
    // Pointer to an initialized ALLOCATOR structure.
    //

    PALLOCATOR Allocator;

    //
    // Pointer to the API structure in use.
    //

    PPERFECT_HASH_TABLE_ANY_API AnyApi;

    //
    // Number of keys in the mapping.
    //

    ULARGE_INTEGER NumberOfElements;

    //
    // Handle to the underlying keys file.
    //

    HANDLE FileHandle;

    //
    // Handle to the memory mapping for the keys file.
    //

    HANDLE MappingHandle;

    //
    // Base address of the memory map.
    //

    union {
        PVOID BaseAddress;
        PULONG Keys;
    };

    //
    // Fully-qualified, NULL-terminated path of the source keys file.
    //

    UNICODE_STRING Path;

} PERFECT_HASH_TABLE_KEYS;
typedef PERFECT_HASH_TABLE_KEYS *PPERFECT_HASH_TABLE_KEYS;
</code></pre>

                <a class="xref" name="LoadPerfectHashTableKeys"></a>
                <h2>LoadPerfectHashTableKeys</h2>

                <div class="tab-box language box-load-keys">
                    <ul class="tabs">
                        <li data-content="content-load-keys-pseudo">Pseudo</li>
                        <li data-content="content-load-keys-full">Full</li>
                    </ul>
                    <div class="content">
<pre class="code content-load-keys-pseudo"><code class="language-c">_Use_decl_annotations_
BOOLEAN
LoadPerfectHashTableKeys(
    PRTL Rtl,
    PALLOCATOR Allocator,
    PCUNICODE_STRING Path,
    PPERFECT_HASH_TABLE_KEYS *KeysPointer
    )
/*++

Routine Description:

    Loads a keys file from the file system and returns a PERFECT_HASH_TABLE_KEYS
    structure.

Arguments:

    Rtl - Supplies a pointer to an initialized RTL structure.

    Allocator - Supplies a pointer to an initialized ALLOCATOR structure that
        will be used for al memory allocations.

    Path - Supplies a pointer to a UNICODE_STRING structure that represents
        a fully-qualified path of the keys to use for the perfect hash table.

        N.B. Path must be NULL-terminated, which is not normally required for
             UNICODE_STRING structures.  Howver, the underlying buffer is passed
             to CreateFileW(), which requires a NULL-terminated wstr.

    KeysPointers - Supplies the address of a variable that will receive the
        address of the newly created PERFECT_HASH_TABLE_KEYS structure if the
        routine is successful, or NULL if the routine fails.

Return Value:

    TRUE on success, FALSE on failure.

--*/
{

    ValidateArguments();

    //
    // Open the file, create a file mapping, then map it into memory.
    //

    FileHandle = Rtl-&gt;CreateFileW(
        Path-&gt;Buffer,
        GENERIC_READ,
        FILE_SHARE_READ | FILE_SHARE_WRITE | FILE_SHARE_DELETE,
        NULL,
        OPEN_EXISTING,
        FILE_FLAG_SEQUENTIAL_SCAN | FILE_FLAG_OVERLAPPED,
        NULL
    );

    //
    // Verify file details such as size.
    //

    VerifyFileDetails();

    //
    // Create the file mapping.
    //

    MappingHandle = CreateFileMappingW(FileHandle,
                                       NULL,
                                       PAGE_READONLY,
                                       FileInfo.EndOfFile.HighPart,
                                       FileInfo.EndOfFile.LowPart,
                                       NULL);

    //
    // Successfully created a file mapping.  Now map it into memory.
    //

    BaseAddress = MapViewOfFile(MappingHandle,
                                FILE_MAP_READ,
                                0,
                                0,
                                FileInfo.EndOfFile.LowPart);

    //
    // The file has been mapped successfully.  Calculate the size required for
    // the keys structure and a copy of the Path's underlying unicode string
    // buffer.
    //

    CalculateAllocSize(&amp;AllocSize);

    //
    // Allocate the structure.
    //

    Keys = AllocKeys(AllocSize);

    //
    // Initialize fields then duplicate the keys path.
    //

    InitializeFields(Keys);
    CopyKeysPath(Keys, Path);

    *KeysPointer = Keys;

    return Success;
}</code></pre>
<pre class="code content-load-keys-full"><code class="language-c">_Use_decl_annotations_
BOOLEAN
LoadPerfectHashTableKeys(
    PRTL Rtl,
    PALLOCATOR Allocator,
    PCUNICODE_STRING Path,
    PPERFECT_HASH_TABLE_KEYS *KeysPointer
    )
/*++

Routine Description:

    Loads a keys file from the file system and returns a PERFECT_HASH_TABLE_KEYS
    structure.

Arguments:

    Rtl - Supplies a pointer to an initialized RTL structure.

    Allocator - Supplies a pointer to an initialized ALLOCATOR structure that
        will be used for al memory allocations.

    Path - Supplies a pointer to a UNICODE_STRING structure that represents
        a fully-qualified path of the keys to use for the perfect hash table.

        N.B. Path must be NULL-terminated, which is not normally required for
             UNICODE_STRING structures.  Howver, the underlying buffer is passed
             to CreateFileW(), which requires a NULL-terminated wstr.

    KeysPointers - Supplies the address of a variable that will receive the
        address of the newly created PERFECT_HASH_TABLE_KEYS structure if the
        routine is successful, or NULL if the routine fails.

Return Value:

    TRUE on success, FALSE on failure.

--*/
{
    BOOLEAN Success;
    PVOID BaseAddress = NULL;
    HANDLE FileHandle = NULL;
    HANDLE MappingHandle = NULL;
    LARGE_INTEGER AllocSize;
    LARGE_INTEGER NumberOfElements;
    FILE_STANDARD_INFO FileInfo;
    PPERFECT_HASH_TABLE_KEYS Keys = NULL;

    //
    // Validate arguments.
    //

    if (!ARGUMENT_PRESENT(Rtl)) {
        return FALSE;
    }

    if (!ARGUMENT_PRESENT(Allocator)) {
        return FALSE;
    }

    if (!ARGUMENT_PRESENT(KeysPointer)) {
        return FALSE;
    }

    if (!ARGUMENT_PRESENT(Path)) {
        return FALSE;
    }

    if (!IsValidMinimumDirectoryNullTerminatedUnicodeString(Path)) {
        return FALSE;
    }

    //
    // Clear the caller's pointer up-front.
    //

    *KeysPointer = NULL;

    //
    // Open the file, create a file mapping, then map it into memory.
    //

    FileHandle = Rtl-&gt;CreateFileW(
        Path-&gt;Buffer,
        GENERIC_READ,
        FILE_SHARE_READ | FILE_SHARE_WRITE | FILE_SHARE_DELETE,
        NULL,
        OPEN_EXISTING,
        FILE_FLAG_SEQUENTIAL_SCAN | FILE_FLAG_OVERLAPPED,
        NULL
    );

    if (!FileHandle || FileHandle == INVALID_HANDLE_VALUE) {
        return FALSE;
    }

    //
    // N.B. Error handling should 'goto Error' from this point onward now that
    //      we have resources that may need to be cleaned up.
    //

    Success = GetFileInformationByHandleEx(
        FileHandle,
        (FILE_INFO_BY_HANDLE_CLASS)FileStandardInfo,
        &amp;FileInfo,
        sizeof(FileInfo)
    );

    if (!Success) {
        goto Error;
    }

    //
    // Make sure the file is a multiple of our key size.
    //

    if (FileInfo.EndOfFile.QuadPart % 4ULL) {
        goto Error;
    }

    //
    // The number of elements in the key file can be ascertained by right
    // shifting by 2.
    //

    NumberOfElements.QuadPart = FileInfo.EndOfFile.QuadPart &gt;&gt; 2;

    //
    // Sanity check the number of elements.  There shouldn't be more than
    // MAX_ULONG.
    //

    ASSERT(!NumberOfElements.HighPart);

    //
    // Create the file mapping.
    //

    MappingHandle = CreateFileMappingW(FileHandle,
                                       NULL,
                                       PAGE_READONLY,
                                       FileInfo.EndOfFile.HighPart,
                                       FileInfo.EndOfFile.LowPart,
                                       NULL);

    if (!MappingHandle || MappingHandle == INVALID_HANDLE_VALUE) {
        goto Error;
    }

    //
    // Successfully created a file mapping.  Now map it into memory.
    //

    BaseAddress = MapViewOfFile(MappingHandle,
                                FILE_MAP_READ,
                                0,
                                0,
                                FileInfo.EndOfFile.LowPart);

    if (!BaseAddress) {
        goto Error;
    }

    //
    // The file has been mapped successfully.  Calculate the size required for
    // the keys structure and a copy of the Path's underlying unicode string
    // buffer.
    //

    AllocSize.QuadPart = (

        //
        // Account for the keys structure size.
        //

        sizeof(*Keys) +

        //
        // Account for the length of the UNICODE_STRING buffer and terminating
        // NULL.
        //

        Path-&gt;Length + sizeof(Path-&gt;Buffer[0])

    );

    //
    // Sanity check our size.
    //

    ASSERT(!AllocSize.HighPart);

    //
    // Proceed with allocation.
    //

    Keys = (PPERFECT_HASH_TABLE_KEYS)(
        Allocator-&gt;Calloc(Allocator-&gt;Context,
                          1,
                          AllocSize.LowPart)
    );

    if (!Keys) {
        goto Error;
    }

    //
    // Fill out the main structure details.
    //

    Keys-&gt;SizeOfStruct = sizeof(*Keys);
    Keys-&gt;Rtl = Rtl;
    Keys-&gt;Allocator = Allocator;
    Keys-&gt;FileHandle = FileHandle;
    Keys-&gt;MappingHandle = MappingHandle;
    Keys-&gt;BaseAddress = BaseAddress;
    Keys-&gt;NumberOfElements.QuadPart = NumberOfElements.QuadPart;

    //
    // Initialize the path length variables, point the buffer at the space after
    // our structure, then copy the string over and NULL-terminate it.
    //

    Keys-&gt;Path.Length = Path-&gt;Length;
    Keys-&gt;Path.MaximumLength = Path-&gt;Length + sizeof(Path-&gt;Buffer[0]);
    Keys-&gt;Path.Buffer = (PWSTR)RtlOffsetToPointer(Keys, sizeof(*Keys));
    CopyMemory(Keys-&gt;Path.Buffer, Path-&gt;Buffer, Path-&gt;Length);
    Keys-&gt;Path.Buffer[Path-&gt;Length &gt;&gt; 1] = L'\0';

    //
    // We've completed initialization, indicate success and jump to the end.
    //

    Success = TRUE;

    goto End;

Error:

    Success = FALSE;

    //
    // Clean up any resources we may have allocated.
    //

    if (BaseAddress) {
        UnmapViewOfFile(BaseAddress);
        BaseAddress = NULL;
    }

    if (MappingHandle) {
        CloseHandle(MappingHandle);
        MappingHandle = NULL;
    }

    if (FileHandle) {
        CloseHandle(FileHandle);
        FileHandle = NULL;
    }

    if (Keys) {
        Allocator-&gt;FreePointer(Allocator-&gt;Context, &amp;Keys);
    }

    //
    // Intentional follow-on to End.
    //

End:

    //
    // Update the caller's pointer and return.
    //
    // N.B. Keys could be NULL here, which is fine.
    //

    *KeysPointer = Keys;

    return Success;
}</code></pre>
                    </div>
                </div>

                <p>

                    With a context and keys structure in hand, we're ready to try create a perfect
                    hash table.

                </p>

                <a class="xref" name="perfect-hash-table-creation"></a>
                <h2>Perfect Hash Table Creation</h2>

                <p>

                    Table creation, if successful, does not return an opaque pointer to a structure
                    that can be subsequently interacted with by other routines &mdash; unlike the
                    context creation and key loading routines we've examined up to now.

                </p>

                <p>

                    Instead, it writes out the <code>.pht1</code> perfect hash table file to disk,
                    such that it can be loaded (via the filename) in a subsequent call to the
                    <code>LoadPerfectHashTable()</code> routine.  Now, that being said, both the
                    create and load routines use the same C structure for the table:
                    <code>PERFECT_HASH_TABLE</code>.  The public definition of this structure, as we
                    saw earlier, was simply a wrapper around a vtbl pointer.  The private definition
                    in PerfectHashTablePrivate.h, still adheres to the vtbl interface, but extends
                    it with all the additional data we need.

                </p>

                <p>

                    Let's take a look at the table structure first, then examine the creation routine.

                </p>

                <a class="xref" name="PERFECT_HASH_TABLE"></a>
                <h3><code>PERFECT_HASH_TABLE</code></h3>

<pre class="code"><code class="language-c">//
// Define the PERFECT_HASH_TABLE_FLAGS structure.
//

typedef union _PERFECT_HASH_TABLE_FLAGS {
    struct _Struct_size_bytes_(sizeof(ULONG)) {

        //
        // When set, indicates the table came from CreatePerfectHashTable().
        //
        // Invariant:
        //
        //  - If Created == TRUE:
        //      Assert Loaded == FALSE
        //

        ULONG Created:1;

        //
        // When set, indicates the table came from LoadPerfectHashTable().
        //
        // Invariant:
        //
        //  - If Loaded == TRUE:
        //      Assert Created == FALSE
        //

        ULONG Loaded:1;

        //
        // Unused bits.
        //

        ULONG Unused:30;
    };

    LONG AsLong;
    ULONG AsULong;
} PERFECT_HASH_TABLE_FLAGS;
C_ASSERT(sizeof(PERFECT_HASH_TABLE_FLAGS) == sizeof(ULONG));
typedef PERFECT_HASH_TABLE_FLAGS *PPERFECT_HASH_TABLE_FLAGS;

//
// Define the PERFECT_HASH_TABLE structure.
//

typedef struct _Struct_size_bytes_(SizeOfStruct) _PERFECT_HASH_TABLE {

    //
    // Our extended vtbl slot comes first, COM-style.
    //

    struct _PERFECT_HASH_TABLE_VTBL_EX *Vtbl;

    //
    // Size of the structure, in bytes.
    //

    _Field_range_(==, sizeof(struct _PERFECT_HASH_TABLE)) ULONG SizeOfStruct;

    //
    // Flags.
    //

    PERFECT_HASH_TABLE_FLAGS Flags;

    //
    // Generic singly-linked list entry.
    //

    SLIST_ENTRY ListEntry;

    //
    // Pointer to an initialized RTL structure.
    //

    PRTL Rtl;

    //
    // Pointer to an initialized ALLOCATOR structure.
    //

    PALLOCATOR Allocator;

    //
    // Reference count.  Affected by AddRef() and Release().
    //

    volatile ULONG ReferenceCount;

    //
    // Capture the number of elements in the underlying perfect hash table.
    // This refers to the number of vertices for the CHM algorithm, or can
    // mean the rounded-up power-of-2 size.  The masking implementations need
    // an agnostic way to access this value, which is why it is provided here
    // at the table level (despite being obtainable from things like the number
    // of vertices or Keys-&gt;NumberOfElements).
    //

    ULONG HashSize;
    ULONG IndexSize;

    //
    // Similarly, provide a convenient way to access the table "shift" amount
    // if a shifting mask routine is active.  This value is the number of
    // trailing zeros of the Size above for tables whose size is a power of 2.
    // It is not used if modulus masking is active.
    //

    ULONG HashShift;
    ULONG IndexShift;

    //
    // Mask.
    //

    ULONG HashMask;
    ULONG IndexMask;

    //
    // The following value represents how many times we need to XOR the high
    // part of a word with the low part of a word -- where word is being used
    // in the general computer word sense (i.e. not a 2-byte short) -- such
    // that the final value is within the bounds of the table mask.  It is
    // also the value of log2(Table-&gt;Shift).
    //

    ULONG HashFold;
    ULONG IndexFold;

    //
    // If modulus masking is active, this represents the modulus that will be
    // used for masking, e.g. Input %= Table-&gt;Modulus.
    //

    ULONG HashModulus;
    ULONG IndexModulus;

    //
    // If a caller provided the number of table elements as a parameter to the
    // CreatePerfectHashTable() function, that value will be captured here.  It
    // overrides the default sizing heuristics.  (If non-zero, it will be at
    // least equal to or greater than the number of keys.)
    //

    ULARGE_INTEGER RequestedNumberOfTableElements;

    //
    // The algorithm in use.
    //

    PERFECT_HASH_TABLE_ALGORITHM_ID AlgorithmId;

    //
    // The masking type in use.
    //

    PERFECT_HASH_TABLE_MASK_FUNCTION_ID MaskFunctionId;

    //
    // The hash function in use.
    //

    PERFECT_HASH_TABLE_HASH_FUNCTION_ID HashFunctionId;

    //
    // Pointer to the keys corresponding to this perfect hash table.  May be
    // NULL.
    //

    PPERFECT_HASH_TABLE_KEYS Keys;

    //
    // Pointer to the PERFECT_HASH_TABLE_CONTEXT structure in use.
    //

    PPERFECT_HASH_TABLE_CONTEXT Context;

    //
    // Handle to the backing file.
    //

    HANDLE FileHandle;

    //
    // Handle to the memory mapping for the backing file.
    //

    HANDLE MappingHandle;

    //
    // Base address of the memory map for the backing file.
    //

    union {
        PVOID BaseAddress;
        PULONG Data;
    };

    //
    // Fully-qualified, NULL-terminated path of the backing file.  The path is
    // automatically derived from the keys file.
    //

    UNICODE_STRING Path;

    //
    // Capture the mapping size of the underlying array, which will be aligned
    // up to a system allocation granularity.
    //

    ULARGE_INTEGER MappingSizeInBytes;

    //
    // Handle to the info stream backing file.
    //

    HANDLE InfoStreamFileHandle;

    //
    // Handle to the memory mapping for the backing file.
    //

    HANDLE InfoStreamMappingHandle;

    //
    // Base address of the memory map for the :Info stream.
    //

    union {
        PVOID InfoStreamBaseAddress;
        struct _TABLE_INFO_ON_DISK_HEADER *Header;
    };

    //
    // Fully-qualified, NULL-terminated path of the :Info stream associated with
    // the path above.
    //

    UNICODE_STRING InfoStreamPath;

    //
    // Capture the mapping size and actual structure size for the :Info stream.
    //

    ULARGE_INTEGER InfoMappingSizeInBytes;
    ULARGE_INTEGER InfoActualStructureSizeInBytes;

    //
    // If a table is loaded successfully, an array will be allocated for storing
    // values (as part of the Insert()/Lookup() API), the base address for which
    // is captured by the next field.
    //

    union {
        PVOID ValuesBaseAddress;
        PULONG Values;
    };

    //
    // During creation, a large bitmap is created to cover the entire range of
    // possible ULONG keys.  This is used to ensure no duplicate keys appear in
    // the input key set, and also assists in debugging.
    //

    RTL_BITMAP KeysBitmap;

} PERFECT_HASH_TABLE;
typedef PERFECT_HASH_TABLE *PPERFECT_HASH_TABLE;</code></pre>

                <a class="xref" name="CreatePerfectHashTable"></a>
                <h3>CreatePerfectHashTable()</h3>

                <p>

                    The creation routine is the first point where we dispatch to algorithm-specific
                    implementation routines.  <em>(Work in progress... pseudo version not written
                    yet.)</em>

                </p>

                <div class="tab-box language box-create-table">
                    <ul class="tabs">
                        <!--<li data-content="content-create-table-pseudo">Pseudo</li>-->
                        <li data-content="content-create-table-full">Full</li>
                    </ul>
                    <div class="content">
<!--
<pre class="code content-create-table-pseudo"><code class="language-c">_Use_decl_annotations_
BOOLEAN
CreatePerfectHashTable(
    PRTL Rtl,
    PALLOCATOR Allocator,
    PPERFECT_HASH_TABLE_CONTEXT Context,
    PERFECT_HASH_TABLE_ALGORITHM_ID AlgorithmId,
    PERFECT_HASH_TABLE_MASK_FUNCTION_ID MaskFunctionId,
    PERFECT_HASH_TABLE_HASH_FUNCTION_ID HashFunctionId,
    PULARGE_INTEGER NumberOfTableElementsPointer,
    PPERFECT_HASH_TABLE_KEYS Keys,
    PCUNICODE_STRING HashTablePath
    )
/*++

Routine Description:

    Creates and initializes a PERFECT_HASH_TABLE structure from a given set
    of keys, using the requested algorithm.

Arguments:

    Rtl - Supplies a pointer to an initialized RTL structure.

    Allocator - Supplies a pointer to an initialized ALLOCATOR structure that
        will be used for all memory allocations.

    Context - Supplies a pointer to an initialized PERFECT_HASH_TABLE_CONTEXT
        structure that can be used by the underlying algorithm in order to
        search for perfect hash solutions in parallel.

    AlgorithmId - Supplies the algorithm to use.

    MaskFunctionId - Supplies the type of masking to use.  The algorithm and hash
        function must both support the requested masking type.

    HashFunctionId - Supplies the hash function to use.

    NumberOfTableElementsPointer - Optionally supplies a pointer to a
        ULARGE_INTEGER structure that, if non-zero, indicates the number of
        elements to assume when sizing the hash table.  If a non-NULL pointer
        is supplied, it will receive the final number of elements in the table
        if a solution could be found.

        N.B. If this value is non-zero, it must be equal to or greater than
             the number of keys indicated by the Keys parameter.  (It should be
             at least 2.09 times the number of keys; the higher the value, the
             larger the hash table, the faster a perfect hash solution will be
             found.)

    Keys - Supplies a pointer to a PERFECT_HASH_TABLE_KEYS structure obtained
        from LoadPerfectHashTableKeys().

    HashTablePath - Optionally supplies a pointer to a UNICODE_STRING structure
        that represents the fully-qualified, NULL-terminated path of the backing
        file used to save the hash table.  If NULL, the file name of the keys
        file will be used, with ".pht1" appended to it.

Return Value:

    TRUE on success, FALSE on failure.

    If TRUE, the table will be persisted at the path described by for the
    HashTablePath parameter above.  This can be subsequently interacted with
    once loaded via LoadPerfectHashTable().

-*/
{

    ValidateArguments();

    CalculateAllocSize(&amp;AllocSize);

    //
    // Allocate space for the structure and backing paths.
    //

    Table = AllocateTable(&amp;AllocSize);


    //
    // Allocation was successful, continue with initialization.
    //

    Table-&gt;SizeOfStruct = sizeof(*Table);
    Table-&gt;Rtl = Rtl;
    Table-&gt;Allocator = Allocator;
    Table-&gt;Flags.AsULong = 0;
    Table-&gt;Keys = Keys;
    Table-&gt;Context = Context;
    Context-&gt;Table = Table;

    //
    // Our main enumeration IDs get replicated in both structures.
    //

    Table-&gt;AlgorithmId = Context-&gt;AlgorithmId = AlgorithmId;
    Table-&gt;MaskFunctionId = Context-&gt;MaskFunctionId = MaskFunctionId;
    Table-&gt;HashFunctionId = Context-&gt;HashFunctionId = HashFunctionId;

    //
    // Carve out the backing memory structures for the unicode string buffers
    // for the path names.
    //

    Buffer = RtlOffsetToPointer(Table, sizeof(*Table));
    Table-&gt;Path.Buffer = (PWSTR)Buffer;
    CopyMemory(Table-&gt;Path.Buffer, PathBuffer, IncomingPathBufferSizeInBytes);

    if (!UsingKeysPath) {

        //
        // Inherit the lengths provided by the input parameter string.
        //

        Table-&gt;Path.Length = HashTablePath-&gt;Length;
        Table-&gt;Path.MaximumLength = HashTablePath-&gt;MaximumLength;

    } else {

        //
        // Replace the ".keys" suffix with ".pht1".
        //

        Dest = Table-&gt;Path.Buffer;
        Dest += (Keys-&gt;Path.MaximumLength &gt;&gt; 1) - 5ULL;

        ASSERT(*Dest == L'k');
        ASSERT(*(Dest - 1) == L'.');

        Source = Suffix.Buffer;

        while (*Source) {
            *Dest++ = *Source++;
        }

        *Dest = L'\0';

        //
        // We can use the Keys-&gt;Path lengths directly.
        //

        Table-&gt;Path.Length = Keys-&gt;Path.Length;
        Table-&gt;Path.MaximumLength = Keys-&gt;Path.MaximumLength;
    }

    //
    // Advance past the aligned path buffer size such that we're positioned at
    // the start of the info stream buffer.
    //

    Buffer += AlignedPathBufferSize.LongPart;
    Table-&gt;InfoStreamPath.Buffer = (PWSTR)Buffer;
    Table-&gt;InfoStreamPath.MaximumLength = InfoStreamPathBufferSize.LowPart;
    Table-&gt;InfoStreamPath.Length = (
        Table-&gt;InfoStreamPath.MaximumLength -
        sizeof(Table-&gt;InfoStreamPath.Buffer[0])
    );

    //
    // Advance the buffer to the vtbl interface area and initialize it.
    //

    Buffer += AlignedInfoStreamPathBufferSize.LongPart;
    Vtbl = (PPERFECT_HASH_TABLE_VTBL_EX)Buffer;
    InitializeExtendedVtbl(Table, Vtbl);

    //
    // Copy the full path into the info stream buffer.
    //

    CopyMemory(Table-&gt;InfoStreamPath.Buffer,
               Table-&gt;Path.Buffer,
               Table-&gt;Path.Length);

    Dest = Table-&gt;InfoStreamPath.Buffer;
    Dest += (Table-&gt;Path.Length &gt;&gt; 1);
    ASSERT(*Dest == L'\0');

    //
    // Copy the :Info suffix over.
    //

    Source = InfoStreamSuffix.Buffer;

    while (*Source) {
        *Dest++ = *Source++;
    }

    *Dest = L'\0';

    //
    // We've finished initializing our two unicode string buffers for the
    // backing file and it's :Info counterpart.  Now, let's open file handles
    // to them.
    //

    //
    // Open the file handle for the backing hash table store.
    //

    ShareMode = (
        FILE_SHARE_READ  |
        FILE_SHARE_WRITE |
        FILE_SHARE_DELETE
    );

    DesiredAccess = (
        GENERIC_READ |
        GENERIC_WRITE
    );

    FlagsAndAttributes = FILE_FLAG_OVERLAPPED;

    FileHandle = Rtl-&gt;CreateFileW(Table-&gt;Path.Buffer,
                                  DesiredAccess,
                                  ShareMode,
                                  NULL,
                                  OPEN_ALWAYS,
                                  FlagsAndAttributes,
                                  NULL);

    LastError = GetLastError();

    Table-&gt;FileHandle = FileHandle;

    if (!FileHandle || FileHandle == INVALID_HANDLE_VALUE) {

        //
        // Failed to open the file successfully.
        //

        goto Error;

    } else if (LastError == ERROR_ALREADY_EXISTS) {

        //
        // The file was opened successfully, but it already existed.  Clear the
        // local last error variable then truncate the file.
        //

        LastError = ERROR_SUCCESS;

        Result = SetFilePointer(FileHandle, 0, NULL, FILE_BEGIN);
        if (Result == INVALID_SET_FILE_POINTER) {
            LastError = GetLastError();
            goto Error;
        }

        Success = SetEndOfFile(FileHandle);
        if (!Success) {
            LastError = GetLastError();
            goto Error;
        }

        //
        // We've successfully truncated the file.  The creation routine
        // implementation can now allocate the space required for it as part
        // of successful graph solving.
        //

    }

    //
    // The :Info stream is slightly different.  As it's a fixed size metadata
    // record, we can memory map an entire section up-front prior to calling
    // the algorithm implementation.  So, do that now.
    //

    FileHandle = Rtl-&gt;CreateFileW(Table-&gt;InfoStreamPath.Buffer,
                                  DesiredAccess,
                                  ShareMode,
                                  NULL,
                                  OPEN_ALWAYS,
                                  FlagsAndAttributes,
                                  NULL);

    Table-&gt;InfoStreamFileHandle = FileHandle;

    LastError = GetLastError();

    if (!FileHandle || FileHandle == INVALID_HANDLE_VALUE) {

        //
        // Failed to open the file successfully.
        //

        goto Error;

    } else if (LastError == ERROR_ALREADY_EXISTS) {

        //
        // The file was opened successfully, but it already existed.  Clear the
        // local last error variable then truncate the file.
        //

        LastError = ERROR_SUCCESS;

        Result = SetFilePointer(FileHandle, 0, NULL, FILE_BEGIN);
        if (Result == INVALID_SET_FILE_POINTER) {
            LastError = GetLastError();
            goto Error;
        }

        Success = SetEndOfFile(FileHandle);
        if (!Success) {
            LastError = GetLastError();
            goto Error;
        }

        //
        // We've successfully truncated the :Info file.
        //

    }

    //
    // Get the system allocation granularity, as we use this to govern the size
    // we request of the underlying file mapping.
    //

    GetSystemInfo(&amp;SystemInfo);

    InfoMappingSize = SystemInfo.dwAllocationGranularity;
    ASSERT(InfoMappingSize &gt;= PAGE_SIZE);

    //
    // Create a file mapping for the :Info stream.
    //

    MappingHandle = CreateFileMappingW(FileHandle,
                                       NULL,
                                       PAGE_READWRITE,
                                       0,
                                       InfoMappingSize,
                                       NULL);

    Table-&gt;InfoStreamMappingHandle = MappingHandle;
    Table-&gt;InfoMappingSizeInBytes.QuadPart = InfoMappingSize;

    if (!MappingHandle || MappingHandle == INVALID_HANDLE_VALUE) {
        goto Error;
    }

    //
    // We successfully created a file mapping.  Proceed with mapping it into
    // memory.
    //

    BaseAddress = MapViewOfFile(MappingHandle,
                                FILE_MAP_READ | FILE_MAP_WRITE,
                                0,
                                0,
                                InfoMappingSize);

    Table-&gt;InfoStreamBaseAddress = BaseAddress;

    if (!BaseAddress) {
        goto Error;
    }

    //
    // Set the number of table elements requested by the user (0 is a valid
    // value here).
    //

    Table-&gt;RequestedNumberOfTableElements.QuadPart = (
        NumberOfTableElements.QuadPart
    );

    //
    // Allocate a 512MB buffer for the keys bitmap.
    //

    KeysBitmapBufferSize = ((1ULL &lt;&lt; 32ULL) &gt;&gt; 3ULL);

    //
    // Try a large page allocation for the bitmap buffer.
    //

    ProcessHandle = GetCurrentProcess();

    BaseAddress = Rtl-&gt;TryLargePageVirtualAllocEx(ProcessHandle,
                                                  NULL,
                                                  KeysBitmapBufferSize,
                                                  MEM_COMMIT,
                                                  PAGE_READWRITE);

    Table-&gt;KeysBitmap.Buffer = (PULONG)BaseAddress;

    if (!BaseAddress) {

        //
        // Failed to create a bitmap buffer, abort.
        //

        LastError = GetLastError();
        goto Error;
    }

    //
    // Initialize the keys bitmap.
    //

    Table-&gt;KeysBitmap.SizeOfBitMap = (ULONG)-1;
    BitmapBuffer = (PLONGLONG)Table-&gt;KeysBitmap.Buffer;

    ASSERT(!Keys-&gt;NumberOfElements.HighPart);

    NumberOfKeys = Keys-&gt;NumberOfElements.LowPart;

    //
    // Loop through all the keys, obtain the bitmap bit representation, verify
    // that the bit hasn't been set yet, and set it.
    //

    for (Index = 0; Index &lt; NumberOfKeys; Index++) {

        Key = Keys-&gt;Keys[Index];
        Bit = Key + 1;

        ASSERT(!BitTestAndSet64(BitmapBuffer, Bit));

    }

    //
    // Count all bits set.  It should match the number of keys.
    //

    NumberOfSetBits = Rtl-&gt;RtlNumberOfSetBits(&amp;Table-&gt;KeysBitmap);
    ASSERT(NumberOfSetBits == NumberOfKeys);

    //
    // Common initialization is complete, dispatch remaining work to the
    // algorithm's creation routine.
    //

    Success = CreationRoutines[AlgorithmId](Table);
    if (!Success) {
        goto Error;
    }

    //
    // Update the caller's number of table elements pointer, if applicable.
    //

    if (ARGUMENT_PRESENT(NumberOfTableElementsPointer)) {
        NumberOfTableElementsPointer-&gt;QuadPart = Table-&gt;HashSize;
    }

    //
    // We're done!  Set the reference count to 1 and finish up.
    //

    Table-&gt;ReferenceCount = 1;
    goto End;

Error:

    Success = FALSE;

    //
    // Intentional follow-on to End.
    //

End:

    //
    // Call the destroy routine on the table if one is present.
    //
    // N.B. We currently always delete the table if it is created successfully
    //      so as to ensure the only way to use a table is by loading one from
    //      disk via LoadPerfectHashTable().
    //

    if (Table) {

        if (!DestroyPerfectHashTable(&amp;Table, NULL)) {

            //
            // There's nothing we can do here.
            //

            NOTHING;
        }

        //
        // N.B. DestroyPerfectHashTable() should clear the Table pointer.
        //      Assert that invariant now.
        //

        ASSERT(Table == NULL);
    }

    return Success;
}
</code></pre>
-->
<pre class="code content-create-table-full"><code class="language-c">
BOOLEAN
CreatePerfectHashTable(
    PRTL Rtl,
    PALLOCATOR Allocator,
    PPERFECT_HASH_TABLE_CONTEXT Context,
    PERFECT_HASH_TABLE_ALGORITHM_ID AlgorithmId,
    PERFECT_HASH_TABLE_MASK_FUNCTION_ID MaskFunctionId,
    PERFECT_HASH_TABLE_HASH_FUNCTION_ID HashFunctionId,
    PULARGE_INTEGER NumberOfTableElementsPointer,
    PPERFECT_HASH_TABLE_KEYS Keys,
    PCUNICODE_STRING HashTablePath
    )
/*++

Routine Description:

    Creates and initializes a PERFECT_HASH_TABLE structure from a given set
    of keys, using the requested algorithm.

Arguments:

    Rtl - Supplies a pointer to an initialized RTL structure.

    Allocator - Supplies a pointer to an initialized ALLOCATOR structure that
        will be used for all memory allocations.

    Context - Supplies a pointer to an initialized PERFECT_HASH_TABLE_CONTEXT
        structure that can be used by the underlying algorithm in order to
        search for perfect hash solutions in parallel.

    AlgorithmId - Supplies the algorithm to use.

    MaskFunctionId - Supplies the type of masking to use.  The algorithm and hash
        function must both support the requested masking type.

    HashFunctionId - Supplies the hash function to use.

    NumberOfTableElementsPointer - Optionally supplies a pointer to a
        ULARGE_INTEGER structure that, if non-zero, indicates the number of
        elements to assume when sizing the hash table.  If a non-NULL pointer
        is supplied, it will receive the final number of elements in the table
        if a solution could be found.

        N.B. If this value is non-zero, it must be equal to or greater than
             the number of keys indicated by the Keys parameter.  (It should be
             at least 2.09 times the number of keys; the higher the value, the
             larger the hash table, the faster a perfect hash solution will be
             found.)

    Keys - Supplies a pointer to a PERFECT_HASH_TABLE_KEYS structure obtained
        from LoadPerfectHashTableKeys().

    HashTablePath - Optionally supplies a pointer to a UNICODE_STRING structure
        that represents the fully-qualified, NULL-terminated path of the backing
        file used to save the hash table.  If NULL, the file name of the keys
        file will be used, with ".pht1" appended to it.

Return Value:

    TRUE on success, FALSE on failure.

    If TRUE, the table will be persisted at the path described by for the
    HashTablePath parameter above.  This can be subsequently interacted with
    once loaded via LoadPerfectHashTable().

--*/
{
    BOOLEAN Success;
    BOOLEAN UsingKeysPath;
    PWSTR Dest;
    PWSTR Source;
    PBYTE Buffer;
    PWSTR PathBuffer;
    ULONG Key;
    ULONG Index;
    ULONG Result;
    ULONGLONG Bit;
    ULONG ShareMode;
    ULONG LastError;
    ULONG NumberOfKeys;
    ULONG DesiredAccess;
    ULONG NumberOfSetBits;
    ULONG InfoMappingSize;
    ULONG FlagsAndAttributes;
    PLONGLONG BitmapBuffer;
    USHORT VtblExSize;
    PVOID BaseAddress;
    HANDLE FileHandle;
    HANDLE MappingHandle;
    HANDLE ProcessHandle;
    SYSTEM_INFO SystemInfo;
    ULARGE_INTEGER AllocSize;
    ULONG_INTEGER PathBufferSize;
    ULONGLONG KeysBitmapBufferSize;
    ULONG IncomingPathBufferSizeInBytes;
    ULONG_INTEGER AlignedPathBufferSize;
    ULONG_INTEGER InfoStreamPathBufferSize;
    ULONG_INTEGER AlignedInfoStreamPathBufferSize;
    ULARGE_INTEGER NumberOfTableElements;
    PPERFECT_HASH_TABLE_VTBL_EX Vtbl;
    PPERFECT_HASH_TABLE Table = NULL;
    UNICODE_STRING Suffix = RTL_CONSTANT_STRING(L".pht1");
    UNICODE_STRING InfoStreamSuffix = RTL_CONSTANT_STRING(L":Info");

    //
    // Validate arguments.
    //

    if (!ARGUMENT_PRESENT(Rtl)) {
        return FALSE;
    }

    if (!ARGUMENT_PRESENT(Allocator)) {
        return FALSE;
    }

    if (!ARGUMENT_PRESENT(Context)) {

        return FALSE;

    } else if (Context-&gt;Table) {

        //
        // We don't support a context being used more than once at the moment.
        // If it has been used before, Context-&gt;Table will have a value, and
        // thus, we need to error out.
        //

        return FALSE;
    }

    if (!ARGUMENT_PRESENT(Keys)) {

        return FALSE;

    } else {

        //
        // Ensure the number of keys is within our maximum tested limit.
        //

        if (Keys-&gt;NumberOfElements.QuadPart &gt; MAXIMUM_NUMBER_OF_KEYS) {

            return FALSE;

        }
    }

    if (!IsValidPerfectHashTableMaskFunctionId(MaskFunctionId)) {
        return FALSE;
    }

    if (ARGUMENT_PRESENT(NumberOfTableElementsPointer)) {

        //
        // If the number of table elements is non-zero, verify it is greater
        // than or equal to the number of keys present.
        //

        NumberOfTableElements.QuadPart = (
            NumberOfTableElementsPointer-&gt;QuadPart
        );

        if (NumberOfTableElements.QuadPart &gt; 0) {

            if (NumberOfTableElements.QuadPart &lt;
                Keys-&gt;NumberOfElements.QuadPart) {

                //
                // Requested table size is too small, abort.
                //

                return FALSE;
            }
        }
    } else {

        NumberOfTableElements.QuadPart = 0;

    }

    if (ARGUMENT_PRESENT(HashTablePath) &amp;&amp;
        !IsValidMinimumDirectoryNullTerminatedUnicodeString(HashTablePath)) {

        return FALSE;
    }

    if (!IsValidPerfectHashTableAlgorithmId(AlgorithmId)) {
        return FALSE;
    }

    if (!IsValidPerfectHashTableHashFunctionId(HashFunctionId)) {
        return FALSE;
    }

    //
    // Calculate the allocation size required for the structure, including the
    // memory required to take a copy of the backing file name path.
    //

    AllocSize.QuadPart = sizeof(*Table);

    if (ARGUMENT_PRESENT(HashTablePath)) {

        //
        // Use the length of the caller-provided path, plus a trailing NULL.
        //

        PathBufferSize.LongPart = (
            HashTablePath-&gt;Length +
            sizeof(HashTablePath-&gt;Buffer[0])
        );

        UsingKeysPath = FALSE;
        IncomingPathBufferSizeInBytes = HashTablePath-&gt;Length;
        PathBuffer = HashTablePath-&gt;Buffer;

    } else {

        //
        // No path has been provided by the caller, so we'll use the path of
        // the keys file with ".pht1" appended.  Perform a quick invariant check
        // first: maximum length should be 1 character (2 bytes) larger than
        // length.  (This is handled in LoadPerfectHashTableKeys().)
        //

        ASSERT(Keys-&gt;Path.Length + sizeof(Keys-&gt;Path.Buffer[0]) ==
               Keys-&gt;Path.MaximumLength);

        PathBufferSize.LongPart = (Keys-&gt;Path.MaximumLength + Suffix.Length);

        UsingKeysPath = TRUE;
        IncomingPathBufferSizeInBytes = Keys-&gt;Path.Length;
        PathBuffer = Keys-&gt;Path.Buffer;
    }

    //
    // Align the path buffer up to a 16 byte boundary.
    //

    AlignedPathBufferSize.LongPart = ALIGN_UP(PathBufferSize.LongPart, 16);

    //
    // Sanity check we haven't overflowed MAX_USHORT for the path buffer size.
    //

    ASSERT(!AlignedPathBufferSize.HighPart);

    //
    // Add the path buffer size to the structure allocation size, then check
    // we haven't overflowed MAX_ULONG.
    //

    AllocSize.QuadPart += AlignedPathBufferSize.LowPart;

    ASSERT(!AllocSize.HighPart);

    //
    // Calculate the size required by the :Info stream that will be created
    // for the on-disk metadata.  We derive this by adding the length of the
    // path to the length of the :Info suffix, plus an additional trailing NULL.
    //

    InfoStreamPathBufferSize.LongPart = (
        PathBufferSize.LowPart +
        InfoStreamSuffix.Length +
        sizeof(InfoStreamSuffix.Buffer[0])
    );

    //
    // Align the size up to a 16 byte boundary.
    //

    AlignedInfoStreamPathBufferSize.LongPart = (
        ALIGN_UP(
            InfoStreamPathBufferSize.LowPart,
            16
        )
    );

    //
    // Sanity check we haved overflowed MAX_USHORT.
    //

    ASSERT(!AlignedInfoStreamPathBufferSize.HighPart);

    //
    // Add the stream path size to the total size and perform a final overflow
    // check.
    //

    AllocSize.QuadPart += AlignedInfoStreamPathBufferSize.LowPart;

    ASSERT(!AllocSize.HighPart);

    //
    // Account for the vtbl interface size.
    //

    VtblExSize = GetVtblExSizeRoutines[AlgorithmId]();
    AllocSize.QuadPart += VtblExSize;

    ASSERT(!AllocSize.HighPart);

    //
    // Allocate space for the structure and backing paths.
    //

    Table = (PPERFECT_HASH_TABLE)(
        Allocator-&gt;Calloc(Allocator-&gt;Context,
                          1,
                          AllocSize.LowPart)
    );

    if (!Table) {
        return FALSE;
    }

    //
    // Allocation was successful, continue with initialization.
    //

    Table-&gt;SizeOfStruct = sizeof(*Table);
    Table-&gt;Rtl = Rtl;
    Table-&gt;Allocator = Allocator;
    Table-&gt;Flags.AsULong = 0;
    Table-&gt;Keys = Keys;
    Table-&gt;Context = Context;
    Context-&gt;Table = Table;

    //
    // Our main enumeration IDs get replicated in both structures.
    //

    Table-&gt;AlgorithmId = Context-&gt;AlgorithmId = AlgorithmId;
    Table-&gt;MaskFunctionId = Context-&gt;MaskFunctionId = MaskFunctionId;
    Table-&gt;HashFunctionId = Context-&gt;HashFunctionId = HashFunctionId;

    //
    // Carve out the backing memory structures for the unicode string buffers
    // for the path names.
    //

    Buffer = RtlOffsetToPointer(Table, sizeof(*Table));
    Table-&gt;Path.Buffer = (PWSTR)Buffer;
    CopyMemory(Table-&gt;Path.Buffer, PathBuffer, IncomingPathBufferSizeInBytes);

    if (!UsingKeysPath) {

        //
        // Inherit the lengths provided by the input parameter string.
        //

        Table-&gt;Path.Length = HashTablePath-&gt;Length;
        Table-&gt;Path.MaximumLength = HashTablePath-&gt;MaximumLength;

    } else {

        //
        // Replace the ".keys" suffix with ".pht1".
        //

        Dest = Table-&gt;Path.Buffer;
        Dest += (Keys-&gt;Path.MaximumLength &gt;&gt; 1) - 5ULL;

        ASSERT(*Dest == L'k');
        ASSERT(*(Dest - 1) == L'.');

        Source = Suffix.Buffer;

        while (*Source) {
            *Dest++ = *Source++;
        }

        *Dest = L'\0';

        //
        // We can use the Keys-&gt;Path lengths directly.
        //

        Table-&gt;Path.Length = Keys-&gt;Path.Length;
        Table-&gt;Path.MaximumLength = Keys-&gt;Path.MaximumLength;
    }

    //
    // Advance past the aligned path buffer size such that we're positioned at
    // the start of the info stream buffer.
    //

    Buffer += AlignedPathBufferSize.LongPart;
    Table-&gt;InfoStreamPath.Buffer = (PWSTR)Buffer;
    Table-&gt;InfoStreamPath.MaximumLength = InfoStreamPathBufferSize.LowPart;
    Table-&gt;InfoStreamPath.Length = (
        Table-&gt;InfoStreamPath.MaximumLength -
        sizeof(Table-&gt;InfoStreamPath.Buffer[0])
    );

    //
    // Advance the buffer to the vtbl interface area and initialize it.
    //

    Buffer += AlignedInfoStreamPathBufferSize.LongPart;
    Vtbl = (PPERFECT_HASH_TABLE_VTBL_EX)Buffer;
    InitializeExtendedVtbl(Table, Vtbl);

    //
    // Copy the full path into the info stream buffer.
    //

    CopyMemory(Table-&gt;InfoStreamPath.Buffer,
               Table-&gt;Path.Buffer,
               Table-&gt;Path.Length);

    Dest = Table-&gt;InfoStreamPath.Buffer;
    Dest += (Table-&gt;Path.Length &gt;&gt; 1);
    ASSERT(*Dest == L'\0');

    //
    // Copy the :Info suffix over.
    //

    Source = InfoStreamSuffix.Buffer;

    while (*Source) {
        *Dest++ = *Source++;
    }

    *Dest = L'\0';

    //
    // We've finished initializing our two unicode string buffers for the
    // backing file and it's :Info counterpart.  Now, let's open file handles
    // to them.
    //

    //
    // Open the file handle for the backing hash table store.
    //

    ShareMode = (
        FILE_SHARE_READ  |
        FILE_SHARE_WRITE |
        FILE_SHARE_DELETE
    );

    DesiredAccess = (
        GENERIC_READ |
        GENERIC_WRITE
    );

    FlagsAndAttributes = FILE_FLAG_OVERLAPPED;

    FileHandle = Rtl-&gt;CreateFileW(Table-&gt;Path.Buffer,
                                  DesiredAccess,
                                  ShareMode,
                                  NULL,
                                  OPEN_ALWAYS,
                                  FlagsAndAttributes,
                                  NULL);

    LastError = GetLastError();

    Table-&gt;FileHandle = FileHandle;

    if (!FileHandle || FileHandle == INVALID_HANDLE_VALUE) {

        //
        // Failed to open the file successfully.
        //

        goto Error;

    } else if (LastError == ERROR_ALREADY_EXISTS) {

        //
        // The file was opened successfully, but it already existed.  Clear the
        // local last error variable then truncate the file.
        //

        LastError = ERROR_SUCCESS;

        Result = SetFilePointer(FileHandle, 0, NULL, FILE_BEGIN);
        if (Result == INVALID_SET_FILE_POINTER) {
            LastError = GetLastError();
            goto Error;
        }

        Success = SetEndOfFile(FileHandle);
        if (!Success) {
            LastError = GetLastError();
            goto Error;
        }

        //
        // We've successfully truncated the file.  The creation routine
        // implementation can now allocate the space required for it as part
        // of successful graph solving.
        //

    }

    //
    // The :Info stream is slightly different.  As it's a fixed size metadata
    // record, we can memory map an entire section up-front prior to calling
    // the algorithm implementation.  So, do that now.
    //

    FileHandle = Rtl-&gt;CreateFileW(Table-&gt;InfoStreamPath.Buffer,
                                  DesiredAccess,
                                  ShareMode,
                                  NULL,
                                  OPEN_ALWAYS,
                                  FlagsAndAttributes,
                                  NULL);

    Table-&gt;InfoStreamFileHandle = FileHandle;

    LastError = GetLastError();

    if (!FileHandle || FileHandle == INVALID_HANDLE_VALUE) {

        //
        // Failed to open the file successfully.
        //

        goto Error;

    } else if (LastError == ERROR_ALREADY_EXISTS) {

        //
        // The file was opened successfully, but it already existed.  Clear the
        // local last error variable then truncate the file.
        //

        LastError = ERROR_SUCCESS;

        Result = SetFilePointer(FileHandle, 0, NULL, FILE_BEGIN);
        if (Result == INVALID_SET_FILE_POINTER) {
            LastError = GetLastError();
            goto Error;
        }

        Success = SetEndOfFile(FileHandle);
        if (!Success) {
            LastError = GetLastError();
            goto Error;
        }

        //
        // We've successfully truncated the :Info file.
        //

    }

    //
    // Get the system allocation granularity, as we use this to govern the size
    // we request of the underlying file mapping.
    //

    GetSystemInfo(&amp;SystemInfo);

    InfoMappingSize = SystemInfo.dwAllocationGranularity;
    ASSERT(InfoMappingSize &gt;= PAGE_SIZE);

    //
    // Create a file mapping for the :Info stream.
    //

    MappingHandle = CreateFileMappingW(FileHandle,
                                       NULL,
                                       PAGE_READWRITE,
                                       0,
                                       InfoMappingSize,
                                       NULL);

    Table-&gt;InfoStreamMappingHandle = MappingHandle;
    Table-&gt;InfoMappingSizeInBytes.QuadPart = InfoMappingSize;

    if (!MappingHandle || MappingHandle == INVALID_HANDLE_VALUE) {
        goto Error;
    }

    //
    // We successfully created a file mapping.  Proceed with mapping it into
    // memory.
    //

    BaseAddress = MapViewOfFile(MappingHandle,
                                FILE_MAP_READ | FILE_MAP_WRITE,
                                0,
                                0,
                                InfoMappingSize);

    Table-&gt;InfoStreamBaseAddress = BaseAddress;

    if (!BaseAddress) {
        goto Error;
    }

    //
    // Set the number of table elements requested by the user (0 is a valid
    // value here).
    //

    Table-&gt;RequestedNumberOfTableElements.QuadPart = (
        NumberOfTableElements.QuadPart
    );

    //
    // Allocate a 512MB buffer for the keys bitmap.
    //

    KeysBitmapBufferSize = ((1ULL &lt;&lt; 32ULL) &gt;&gt; 3ULL);

    //
    // Try a large page allocation for the bitmap buffer.
    //

    ProcessHandle = GetCurrentProcess();

    BaseAddress = Rtl-&gt;TryLargePageVirtualAllocEx(ProcessHandle,
                                                  NULL,
                                                  KeysBitmapBufferSize,
                                                  MEM_COMMIT,
                                                  PAGE_READWRITE);

    Table-&gt;KeysBitmap.Buffer = (PULONG)BaseAddress;

    if (!BaseAddress) {

        //
        // Failed to create a bitmap buffer, abort.
        //

        LastError = GetLastError();
        goto Error;
    }

    //
    // Initialize the keys bitmap.
    //

    Table-&gt;KeysBitmap.SizeOfBitMap = (ULONG)-1;
    BitmapBuffer = (PLONGLONG)Table-&gt;KeysBitmap.Buffer;

    ASSERT(!Keys-&gt;NumberOfElements.HighPart);

    NumberOfKeys = Keys-&gt;NumberOfElements.LowPart;

    //
    // Loop through all the keys, obtain the bitmap bit representation, verify
    // that the bit hasn't been set yet, and set it.
    //

    for (Index = 0; Index &lt; NumberOfKeys; Index++) {

        Key = Keys-&gt;Keys[Index];
        Bit = Key + 1;

        ASSERT(!BitTestAndSet64(BitmapBuffer, Bit));

    }

    //
    // Count all bits set.  It should match the number of keys.
    //

    NumberOfSetBits = Rtl-&gt;RtlNumberOfSetBits(&amp;Table-&gt;KeysBitmap);
    ASSERT(NumberOfSetBits == NumberOfKeys);

    //
    // Common initialization is complete, dispatch remaining work to the
    // algorithm's creation routine.
    //

    Success = CreationRoutines[AlgorithmId](Table);
    if (!Success) {
        goto Error;
    }

    //
    // Update the caller's number of table elements pointer, if applicable.
    //

    if (ARGUMENT_PRESENT(NumberOfTableElementsPointer)) {
        NumberOfTableElementsPointer-&gt;QuadPart = Table-&gt;HashSize;
    }

    //
    // We're done!  Set the reference count to 1 and finish up.
    //

    Table-&gt;ReferenceCount = 1;
    goto End;

Error:

    Success = FALSE;

    //
    // Intentional follow-on to End.
    //

End:

    //
    // Call the destroy routine on the table if one is present.
    //
    // N.B. We currently always delete the table if it is created successfully
    //      so as to ensure the only way to use a table is by loading one from
    //      disk via LoadPerfectHashTable().
    //

    if (Table) {

        if (!DestroyPerfectHashTable(&amp;Table, NULL)) {

            //
            // There's nothing we can do here.
            //

            NOTHING;
        }

        //
        // N.B. DestroyPerfectHashTable() should clear the Table pointer.
        //      Assert that invariant now.
        //

        ASSERT(Table == NULL);
    }

    return Success;
}
</code></pre>
                <p>

                </p>

                <hr/>

                <!--
                <h3>Contact</h3>
                <p>

                    Like the article?  Let me know!  E-mail: &#116;&#114;&#101;&#110;&#116;&#64;&#116;&#114;&#101;&#110;&#116;&#46;&#109;&#101;

                </p>
                -->

            </div>

        </section>

        <script type="text/javascript">
            // Google Analytics
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-24686252-1', 'auto');
            ga('send', 'pageview');
        </script>

        <section class="section section-footer">
            <div class="container">
                <small><small>
                    <p>
                        <a
                        href="https://github.com/tpn/website/blob/master/perfect-hash-table/index.html">
                        View this page's source on GitHub.</a>
                    </p>
                </small></small>
                <p>
                    <a href="https://twitter.com/trentnelson" class="twitter-follow-button" data-show-count="false">Follow @trentnelson</a>
                    <iframe src="https://ghbtns.com/github-btn.html?user=tpn&type=follow" frameborder="0" scrolling="0" width="170px" height="20px"></iframe>
                </p>
                </small>
            </div>
        </section>

        <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

    </body>
</html>
